{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ba47828",
   "metadata": {},
   "source": [
    "Banks are eager to retain as many active customers as possible. Naturally they are curious to know whether their client base needs are met or whether their clients plan to leave the company. If the bank suspects that their client would potentially lean toward another company, the bank can take measures to convince the client to stay (targeted marketing campaign, more personal attitude etc.).\n",
    "\n",
    "**Aim of this notebook is to find the most accurate and precise model** to predict, which clients (test data) will stay and which are hesitant and might plan to leave the company. We are using dataset of bank clients (10000 rows) with attributes specified below. Let's jump right into it! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e25a12b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-08T09:23:56.266216Z",
     "iopub.status.busy": "2021-06-08T09:23:56.265023Z",
     "iopub.status.idle": "2021-06-08T09:23:56.269513Z",
     "shell.execute_reply": "2021-06-08T09:23:56.268853Z"
    },
    "id": "lP6JLo1tGNBg",
    "papermill": {
     "duration": 0.066632,
     "end_time": "2021-06-08T09:23:56.269685",
     "exception": false,
     "start_time": "2021-06-08T09:23:56.203053",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Dataset has following attributes:**\n",
    "* Rownumber: Unique ID for every row\n",
    "* CustomerID: Unique ID for every client\n",
    "* Surname: Client's surname\n",
    "* CreditScore: Client's credit score\n",
    "* Geography: Country of client's origin\n",
    "* Gender: Client's gender\n",
    "* Age: Client's age\n",
    "* Tenure: Number of years for which the client has been with the bank\n",
    "* Balance: Client's balance on account\n",
    "* NumOfProducts: Number of client's products\n",
    "* HasCrCard: Flag whether client has credit card or not \n",
    "* IsActiveMember: Flag whether client is active member of bank or not \n",
    "* EstimatedSalary: Client's annual estimated salary in euros\n",
    "* **Exited: Target variable, flag, whether client left the bank or not**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charged-rhythm",
   "metadata": {
    "id": "gWZyYmS_UE_L",
    "papermill": {
     "duration": 0.057409,
     "end_time": "2021-06-08T09:23:56.385207",
     "exception": false,
     "start_time": "2021-06-08T09:23:56.327798",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mechanical-hypothetical",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-08T09:23:56.511749Z",
     "iopub.status.busy": "2021-06-08T09:23:56.510971Z",
     "iopub.status.idle": "2021-06-08T09:24:04.025893Z",
     "shell.execute_reply": "2021-06-08T09:24:04.025114Z",
     "shell.execute_reply.started": "2021-06-08T08:35:25.700252Z"
    },
    "papermill": {
     "duration": 7.583618,
     "end_time": "2021-06-08T09:24:04.026050",
     "exception": false,
     "start_time": "2021-06-08T09:23:56.442432",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=Warning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weighted-equilibrium",
   "metadata": {
    "id": "cKWAkFVGUU0Z",
    "papermill": {
     "duration": 0.058616,
     "end_time": "2021-06-08T09:24:04.142761",
     "exception": false,
     "start_time": "2021-06-08T09:24:04.084145",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "organizational-chassis",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-08T09:24:04.264294Z",
     "iopub.status.busy": "2021-06-08T09:24:04.263602Z",
     "iopub.status.idle": "2021-06-08T09:24:04.320137Z",
     "shell.execute_reply": "2021-06-08T09:24:04.319479Z",
     "shell.execute_reply.started": "2021-06-08T08:03:18.223035Z"
    },
    "papermill": {
     "duration": 0.120167,
     "end_time": "2021-06-08T09:24:04.320279",
     "exception": false,
     "start_time": "2021-06-08T09:24:04.200112",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Churn_Modelling.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-specialist",
   "metadata": {
    "papermill": {
     "duration": 0.057161,
     "end_time": "2021-06-08T09:24:04.433897",
     "exception": false,
     "start_time": "2021-06-08T09:24:04.376736",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "imperial-blake",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-08T09:24:04.563957Z",
     "iopub.status.busy": "2021-06-08T09:24:04.563244Z",
     "iopub.status.idle": "2021-06-08T09:24:04.589208Z",
     "shell.execute_reply": "2021-06-08T09:24:04.589733Z",
     "shell.execute_reply.started": "2021-06-08T08:03:18.302026Z"
    },
    "papermill": {
     "duration": 0.098937,
     "end_time": "2021-06-08T09:24:04.589908",
     "exception": false,
     "start_time": "2021-06-08T09:24:04.490971",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dutch-hands",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-08T09:24:04.710445Z",
     "iopub.status.busy": "2021-06-08T09:24:04.709719Z",
     "iopub.status.idle": "2021-06-08T09:24:04.714497Z",
     "shell.execute_reply": "2021-06-08T09:24:04.715027Z",
     "shell.execute_reply.started": "2021-06-08T08:03:18.429743Z"
    },
    "papermill": {
     "duration": 0.066675,
     "end_time": "2021-06-08T09:24:04.715201",
     "exception": false,
     "start_time": "2021-06-08T09:24:04.648526",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of rows and attributes\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfae5ba5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography',\n",
       "       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
       "       'IsActiveMember', 'EstimatedSalary', 'Exited'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#names of all present attributes in the dataset\n",
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "668ab0b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  int64  \n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#datatypes of all present attributes in the dataset\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9de44e3e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber          10000\n",
       "CustomerId         10000\n",
       "Surname             2932\n",
       "CreditScore          460\n",
       "Geography              3\n",
       "Gender                 2\n",
       "Age                   70\n",
       "Tenure                11\n",
       "Balance             6382\n",
       "NumOfProducts          4\n",
       "HasCrCard              2\n",
       "IsActiveMember         2\n",
       "EstimatedSalary     9999\n",
       "Exited                 2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of distinct elements in each attribute\n",
    "dataset.nunique(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dominant-slovak",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-08T09:24:04.834214Z",
     "iopub.status.busy": "2021-06-08T09:24:04.833236Z",
     "iopub.status.idle": "2021-06-08T09:24:04.935379Z",
     "shell.execute_reply": "2021-06-08T09:24:04.934493Z",
     "shell.execute_reply.started": "2021-06-08T08:03:18.481127Z"
    },
    "papermill": {
     "duration": 0.162654,
     "end_time": "2021-06-08T09:24:04.935541",
     "exception": false,
     "start_time": "2021-06-08T09:24:04.772887",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569094e+07</td>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>5.012800</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2886.89568</td>\n",
       "      <td>7.193619e+04</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.892174</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.556570e+07</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2500.75000</td>\n",
       "      <td>1.562853e+07</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569074e+07</td>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7500.25000</td>\n",
       "      <td>1.575323e+07</td>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.581569e+07</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RowNumber    CustomerId   CreditScore           Age        Tenure  \\\n",
       "count  10000.00000  1.000000e+04  10000.000000  10000.000000  10000.000000   \n",
       "mean    5000.50000  1.569094e+07    650.528800     38.921800      5.012800   \n",
       "std     2886.89568  7.193619e+04     96.653299     10.487806      2.892174   \n",
       "min        1.00000  1.556570e+07    350.000000     18.000000      0.000000   \n",
       "25%     2500.75000  1.562853e+07    584.000000     32.000000      3.000000   \n",
       "50%     5000.50000  1.569074e+07    652.000000     37.000000      5.000000   \n",
       "75%     7500.25000  1.575323e+07    718.000000     44.000000      7.000000   \n",
       "max    10000.00000  1.581569e+07    850.000000     92.000000     10.000000   \n",
       "\n",
       "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
       "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
       "mean    76485.889288       1.530200      0.70550        0.515100   \n",
       "std     62397.405202       0.581654      0.45584        0.499797   \n",
       "min         0.000000       1.000000      0.00000        0.000000   \n",
       "25%         0.000000       1.000000      0.00000        0.000000   \n",
       "50%     97198.540000       1.000000      1.00000        1.000000   \n",
       "75%    127644.240000       2.000000      1.00000        1.000000   \n",
       "max    250898.090000       4.000000      1.00000        1.000000   \n",
       "\n",
       "       EstimatedSalary        Exited  \n",
       "count     10000.000000  10000.000000  \n",
       "mean     100090.239881      0.203700  \n",
       "std       57510.492818      0.402769  \n",
       "min          11.580000      0.000000  \n",
       "25%       51002.110000      0.000000  \n",
       "50%      100193.915000      0.000000  \n",
       "75%      149388.247500      0.000000  \n",
       "max      199992.480000      1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#statistic metrics for continuous variables without scientific notation\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0fe347",
   "metadata": {},
   "source": [
    "# Cleaning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "coated-sapphire",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-08T09:24:05.065209Z",
     "iopub.status.busy": "2021-06-08T09:24:05.064500Z",
     "iopub.status.idle": "2021-06-08T09:24:05.069780Z",
     "shell.execute_reply": "2021-06-08T09:24:05.069201Z",
     "shell.execute_reply.started": "2021-06-08T08:03:18.841461Z"
    },
    "papermill": {
     "duration": 0.073374,
     "end_time": "2021-06-08T09:24:05.069938",
     "exception": false,
     "start_time": "2021-06-08T09:24:04.996564",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber          0\n",
       "CustomerId         0\n",
       "Surname            0\n",
       "CreditScore        0\n",
       "Geography          0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for missing values\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1641d8a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#drop redundant attributes\n",
    "dataset = dataset.drop(labels=['RowNumber', 'CustomerId', 'Surname'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02f7c866",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check, whether there are duplicate customers\n",
    "dataset.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-sewing",
   "metadata": {
    "papermill": {
     "duration": 0.058036,
     "end_time": "2021-06-08T09:24:05.187801",
     "exception": false,
     "start_time": "2021-06-08T09:24:05.129765",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Plotting Count for Qualities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "incident-ending",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-06-08T09:24:05.315792Z",
     "iopub.status.busy": "2021-06-08T09:24:05.315035Z",
     "iopub.status.idle": "2021-06-08T09:24:05.508157Z",
     "shell.execute_reply": "2021-06-08T09:24:05.507571Z",
     "shell.execute_reply.started": "2021-06-08T08:03:18.852563Z"
    },
    "papermill": {
     "duration": 0.262265,
     "end_time": "2021-06-08T09:24:05.508336",
     "exception": false,
     "start_time": "2021-06-08T09:24:05.246071",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtoAAAFzCAYAAAAAFa6IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAaD0lEQVR4nO3df6xf9Xkf8PcTO6FOE1YYhhGbDNZ5WQxbyLAs1khVF9rgbGvNqlE5UobVsrmipGurravZpqXdZA2p3bRQBSTWppitC/XSZnhVaEq9ZdkPFnJJWIkhFl5IwcPFDllXN62oYM/+uAf1O3PtXMP9+N7rvF7S0TnnOZ/P+T73H+fNyed7vtXdAQAAltbrlrsBAAA4FwnaAAAwgKANAAADCNoAADCAoA0AAAMI2gAAMMDa5W5glIsuuqgvv/zy5W4DAIBz2COPPPKV7l6/0LVzNmhffvnlmZubW+42AAA4h1XVb53qmqUjAAAwgKANAAADCNoAADCAoA0AAAMI2gAAMICgDQAAAwjaAAAwgKANAAADDA3aVfVjVXWwqr5QVR+tqm+qqgur6sGqenLaXzAz/raqOlxVh6rq+pn6NVX12HTtjqqqkX0DAMBrNSxoV9WGJH87yZbuvirJmiQ7kuxOcqC7NyU5MJ2nqjZP169Msi3JnVW1ZrrdXUl2Jdk0bdtG9Q0AAEth9NKRtUnWVdXaJG9M8myS7Un2Ttf3JrlhOt6e5L7ufqG7n0pyOMnWqro0yfnd/VB3d5J7Z+YAAMCKNCxod/f/SvIzSZ5OcjTJ/+nuX09ySXcfncYcTXLxNGVDkmdmbnFkqm2Yjk+uAwDAijVy6cgFmX9KfUWStyT55qp6/+mmLFDr09QX+sxdVTVXVXPHjx8/05YBAGDJrB147+9M8lR3H0+SqvqVJN+W5LmqurS7j07LQo5N448kuWxm/sbMLzU5Mh2fXH+F7r47yd1JsmXLlgXD+Nl0zY/fu9wtAKvEIz9903K3AMASG7lG++kk11bVG6e3hFyX5Ikk+5PsnMbsTHL/dLw/yY6qOq+qrsj8lx4fnpaXnKiqa6f73DQzBwAAVqRhT7S7+zNV9bEkn0vyYpLPZ/5p85uS7KuqmzMfxm+cxh+sqn1JHp/G39rdL023uyXJPUnWJXlg2gAAYMUauXQk3f3BJB88qfxC5p9uLzR+T5I9C9Tnkly15A0CAMAgfhkSAAAGELQBAGAAQRsAAAYQtAEAYABBGwAABhC0AQBgAEEbAAAGELQBAGAAQRsAAAYQtAEAYABBGwAABhC0AQBgAEEbAAAGELQBAGAAQRsAAAYQtAEAYABBGwAABhC0AQBgAEEbAAAGELQBAGAAQRsAAAYQtAEAYABBGwAABhC0AQBgAEEbAAAGELQBAGAAQRsAAAYQtAEAYABBGwAABhC0AQBggGFBu6reVlWPzmy/W1U/WlUXVtWDVfXktL9gZs5tVXW4qg5V1fUz9Wuq6rHp2h1VVaP6BgCApTAsaHf3oe6+uruvTnJNkt9P8vEku5Mc6O5NSQ5M56mqzUl2JLkyybYkd1bVmul2dyXZlWTTtG0b1TcAACyFs7V05Lok/7O7fyvJ9iR7p/reJDdMx9uT3NfdL3T3U0kOJ9laVZcmOb+7H+ruTnLvzBwAAFiRzlbQ3pHko9PxJd19NEmm/cVTfUOSZ2bmHJlqG6bjk+sAALBiDQ/aVfWGJN+T5N9+vaEL1Po09YU+a1dVzVXV3PHjx8+sUQAAWEJn44n2e5N8rrufm86fm5aDZNofm+pHklw2M29jkmen+sYF6q/Q3Xd395bu3rJ+/fol/BMAAODMnI2g/b780bKRJNmfZOd0vDPJ/TP1HVV1XlVdkfkvPT48LS85UVXXTm8buWlmDgAArEhrR968qt6Y5LuS/OBM+fYk+6rq5iRPJ7kxSbr7YFXtS/J4kheT3NrdL01zbklyT5J1SR6YNgAAWLGGBu3u/v0kf/yk2vOZfwvJQuP3JNmzQH0uyVUjegQAgBH8MiQAAAwgaAMAwACCNgAADCBoAwDAAII2AAAMIGgDAMAAgjYAAAwgaAMAwACCNgAADCBoAwDAAII2AAAMIGgDAMAAgjYAAAwgaAMAwACCNgAADCBoAwDAAII2AAAMIGgDAMAAgjYAAAwgaAMAwACCNgAADCBoAwDAAII2AAAMIGgDAMAAgjYAAAwgaAMAwACCNgAADCBoAwDAAII2AAAMIGgDAMAAQ4N2VX1LVX2sqr5YVU9U1V+sqgur6sGqenLaXzAz/raqOlxVh6rq+pn6NVX12HTtjqqqkX0DAMBrNfqJ9oeS/Fp3/9kk70jyRJLdSQ5096YkB6bzVNXmJDuSXJlkW5I7q2rNdJ+7kuxKsmnatg3uGwAAXpNhQbuqzk/y7Ul+Pkm6+w+7+3eSbE+ydxq2N8kN0/H2JPd19wvd/VSSw0m2VtWlSc7v7oe6u5PcOzMHAABWpJFPtP9UkuNJfqGqPl9VP1dV35zkku4+miTT/uJp/IYkz8zMPzLVNkzHJ9cBAGDFGhm01yb5C0nu6u53JvlapmUip7DQuus+Tf2VN6jaVVVzVTV3/PjxM+0XAACWzMigfSTJke7+zHT+scwH7+em5SCZ9sdmxl82M39jkmen+sYF6q/Q3Xd395bu3rJ+/fol+0MAAOBMDQva3f3bSZ6pqrdNpeuSPJ5kf5KdU21nkvun4/1JdlTVeVV1Rea/9PjwtLzkRFVdO71t5KaZOQAAsCKtHXz/H07yi1X1hiRfSvL9mQ/3+6rq5iRPJ7kxSbr7YFXty3wYfzHJrd390nSfW5Lck2RdkgemDQAAVqyhQbu7H02yZYFL151i/J4kexaozyW5akmbAwCAgfwyJAAADCBoAwDAAII2AAAMIGgDAMAAgjYAAAwgaAMAwACCNgAADCBoAwDAAII2AAAMIGgDAMAAgjYAAAwgaAMAwACCNgAADCBoAwDAAII2AAAMIGgDAMAAgjYAAAwgaAMAwACCNgAADCBoAwDAAII2AAAMIGgDAMAAgjYAAAwgaAMAwACCNgAADCBoAwDAAII2AAAMIGgDAMAAgjYAAAwgaAMAwABDg3ZVfbmqHquqR6tqbqpdWFUPVtWT0/6CmfG3VdXhqjpUVdfP1K+Z7nO4qu6oqhrZNwAAvFZn44n2X+ruq7t7y3S+O8mB7t6U5MB0nqranGRHkiuTbEtyZ1WtmebclWRXkk3Ttu0s9A0AAK/aciwd2Z5k73S8N8kNM/X7uvuF7n4qyeEkW6vq0iTnd/dD3d1J7p2ZAwAAK9LooN1Jfr2qHqmqXVPtku4+miTT/uKpviHJMzNzj0y1DdPxyXUAAFix1g6+/7u6+9mqujjJg1X1xdOMXWjddZ+m/sobzIf5XUny1re+9Ux7BQCAJTP0iXZ3PzvtjyX5eJKtSZ6bloNk2h+bhh9JctnM9I1Jnp3qGxeoL/R5d3f3lu7esn79+qX8UwAA4IwMC9pV9c1V9eaXj5O8J8kXkuxPsnMatjPJ/dPx/iQ7quq8qroi8196fHhaXnKiqq6d3jZy08wcAABYkUYuHbkkycenN/GtTfJvuvvXquqzSfZV1c1Jnk5yY5J098Gq2pfk8SQvJrm1u1+a7nVLknuSrEvywLQBAMCKNSxod/eXkrxjgfrzSa47xZw9SfYsUJ9LctVS9wgAAKP4ZUgAABhA0AYAgAEEbQAAGEDQBgCAAQRtAAAYQNAGAIABBG0AABhA0AYAgAEEbQAAGEDQBgCAAQRtAAAYQNAGAIABBG0AABhA0AYAgAEEbQAAGGBRQbuqDiymBgAAzFt7uotV9U1J3pjkoqq6IElNl85P8pbBvQEAwKp12qCd5AeT/GjmQ/Uj+aOg/btJPjyuLQAAWN1OG7S7+0NJPlRVP9zdP3uWegIAgFXv6z3RTpJ0989W1bcluXx2TnffO6gvAABY1RYVtKvqXyX51iSPJnlpKncSQRsAABawqKCdZEuSzd3dI5sBAIBzxWLfo/2FJH9iZCMAAHAuWewT7YuSPF5VDyd54eVid3/PkK4AAGCVW2zQ/smRTQAAwLlmsW8d+U+jGwEAgHPJYt86ciLzbxlJkjckeX2Sr3X3+aMaAwCA1WyxT7TfPHteVTck2TqiIQAAOBcs9q0j/5/u/ndJ3r20rQAAwLljsUtHvnfm9HWZf6+2d2oDAMApLPaJ9nfPbNcnOZFk+2ImVtWaqvp8Vf3qdH5hVT1YVU9O+wtmxt5WVYer6lBVXT9Tv6aqHpuu3VFVtdg/EAAAlsNi12h//2v4jB9J8kSSl784uTvJge6+vap2T+c/UVWbk+xIcmWStyT5jar6M939UpK7kuxK8t+TfCLJtiQPvIaeAABgqEU90a6qjVX18ao6VlXPVdUvV9XGxcxL8leS/NxMeXuSvdPx3iQ3zNTv6+4XuvupJIeTbK2qS5Oc390PTT8Bf+/MHAAAWJEWu3TkF5Lsz/yT5g1J/v1U+3r+RZK/l+T/ztQu6e6jSTLtL57qG5I8MzPuyFTbMB2fXAcAgBVrsUF7fXf/Qne/OG33JFl/uglV9VeTHOvuRxb5GQutu+7T1Bf6zF1VNVdVc8ePH1/kxwIAwNJbbND+SlW9f/pi45qqen+S57/OnHcl+Z6q+nKS+5K8u6r+dZLnpuUgmfbHpvFHklw2M39jkmen+sYF6q/Q3Xd395bu3rJ+/Wn/OwAAAIZabND+gSTfl+S3kxxN8teTnPYLkt19W3dv7O7LM/8lx//Q3e/P/BKUndOwnUnun473J9lRVedV1RVJNiV5eFpecqKqrp3eNnLTzBwAAFiRFvXWkST/JMnO7v7fyfwr+pL8TOYD+Jm6Pcm+qro5ydNJbkyS7j5YVfuSPJ7kxSS3Tm8cSZJbktyTZF3m3zbijSMAAKxoiw3af/7lkJ0k3f3VqnrnYj+kuz+V5FPT8fNJrjvFuD1J9ixQn0ty1WI/DwAAlttil4687qQflrkwiw/pAADwDWexYfmfJflvVfWxzL/x4/uywJNnAABg3mJ/GfLeqppL8u7Mv27ve7v78aGdAQDAKrbo5R9TsBauAQBgERa7RhsAADgDgjYAAAwgaAMAwACCNgAADCBoAwDAAII2AAAMIGgDAMAAgjYAAAwgaAMAwACCNgAADCBoAwDAAII2AAAMIGgDAMAAgjYAAAwgaAMAwACCNgAADCBoAwDAAII2AAAMIGgDAMAAgjYAAAwgaAMAwACCNgAADCBoAwDAAII2AAAMIGgDAMAAgjYAAAwwLGhX1TdV1cNV9T+q6mBV/dRUv7CqHqyqJ6f9BTNzbquqw1V1qKqun6lfU1WPTdfuqKoa1TcAACyFkU+0X0jy7u5+R5Krk2yrqmuT7E5yoLs3JTkwnaeqNifZkeTKJNuS3FlVa6Z73ZVkV5JN07ZtYN8AAPCaDQvaPe/3ptPXT1sn2Z5k71Tfm+SG6Xh7kvu6+4XufirJ4SRbq+rSJOd390Pd3UnunZkDAAAr0tA12lW1pqoeTXIsyYPd/Zkkl3T30SSZ9hdPwzckeWZm+pGptmE6PrkOAAAr1tCg3d0vdffVSTZm/un0VacZvtC66z5N/ZU3qNpVVXNVNXf8+PEz7hcAAJbKWXnrSHf/TpJPZX5t9XPTcpBM+2PTsCNJLpuZtjHJs1N94wL1hT7n7u7e0t1b1q9fv5R/AgAAnJGRbx1ZX1XfMh2vS/KdSb6YZH+SndOwnUnun473J9lRVedV1RWZ/9Ljw9PykhNVde30tpGbZuYAAMCKtHbgvS9Nsnd6c8jrkuzr7l+tqoeS7Kuqm5M8neTGJOnug1W1L8njSV5Mcmt3vzTd65Yk9yRZl+SBaQMAgBVrWNDu7t9M8s4F6s8nue4Uc/Yk2bNAfS7J6dZ3AwDAiuKXIQEAYABBGwAABhC0AQBgAEEbAAAGELQBAGAAQRsAAAYQtAEAYABBGwAABhC0AQBgAEEbAAAGELQBAGAAQRsAAAYQtAEAYABBGwAABhC0AQBgAEEbAAAGELQBAGAAQRsAAAYQtAEAYABBGwAABhC0AQBgAEEbAAAGELQBAGAAQRsAAAYQtAEAYABBGwAABhC0AQBgAEEbAAAGELQBAGAAQRsAAAYYFrSr6rKq+o9V9URVHayqH5nqF1bVg1X15LS/YGbObVV1uKoOVdX1M/Vrquqx6dodVVWj+gYAgKUw8on2i0n+Tne/Pcm1SW6tqs1Jdic50N2bkhyYzjNd25HkyiTbktxZVWume92VZFeSTdO2bWDfAADwmq0ddePuPprk6HR8oqqeSLIhyfYk3zEN25vkU0l+Yqrf190vJHmqqg4n2VpVX05yfnc/lCRVdW+SG5I8MKp3AJbP0//4zy13C8Aq8dZ/9Nhyt3BaZ2WNdlVdnuSdST6T5JIphL8cxi+ehm1I8szMtCNTbcN0fHIdAABWrOFBu6relOSXk/xod//u6YYuUOvT1Bf6rF1VNVdVc8ePHz/zZgEAYIkMDdpV9frMh+xf7O5fmcrPVdWl0/VLkxyb6keSXDYzfWOSZ6f6xgXqr9Ddd3f3lu7esn79+qX7QwAA4AyNfOtIJfn5JE909z+fubQ/yc7peGeS+2fqO6rqvKq6IvNfenx4Wl5yoqqune5508wcAABYkYZ9GTLJu5L8jSSPVdWjU+3vJ7k9yb6qujnJ00luTJLuPlhV+5I8nvk3ltza3S9N825Jck+SdZn/EqQvQgIAsKKNfOvIf8nC66uT5LpTzNmTZM8C9bkkVy1ddwAAMJZfhgQAgAEEbQAAGEDQBgCAAQRtAAAYQNAGAIABBG0AABhA0AYAgAEEbQAAGEDQBgCAAQRtAAAYQNAGAIABBG0AABhA0AYAgAEEbQAAGEDQBgCAAQRtAAAYQNAGAIABBG0AABhA0AYAgAEEbQAAGEDQBgCAAQRtAAAYQNAGAIABBG0AABhA0AYAgAEEbQAAGEDQBgCAAQRtAAAYQNAGAIABBG0AABhgWNCuqo9U1bGq+sJM7cKqerCqnpz2F8xcu62qDlfVoaq6fqZ+TVU9Nl27o6pqVM8AALBURj7RvifJtpNqu5Mc6O5NSQ5M56mqzUl2JLlymnNnVa2Z5tyVZFeSTdN28j0BAGDFGRa0u/vTSb56Unl7kr3T8d4kN8zU7+vuF7r7qSSHk2ytqkuTnN/dD3V3J7l3Zg4AAKxYZ3uN9iXdfTRJpv3FU31Dkmdmxh2Zahum45PrAACwoq2UL0MutO66T1Nf+CZVu6pqrqrmjh8/vmTNAQDAmTrbQfu5aTlIpv2xqX4kyWUz4zYmeXaqb1ygvqDuvru7t3T3lvXr1y9p4wAAcCbOdtDen2TndLwzyf0z9R1VdV5VXZH5Lz0+PC0vOVFV105vG7lpZg4AAKxYa0fduKo+muQ7klxUVUeSfDDJ7Un2VdXNSZ5OcmOSdPfBqtqX5PEkLya5tbtfmm51S+bfYLIuyQPTBgAAK9qwoN3d7zvFpetOMX5Pkj0L1OeSXLWErQEAwHAr5cuQAABwThG0AQBgAEEbAAAGELQBAGAAQRsAAAYQtAEAYABBGwAABhC0AQBgAEEbAAAGELQBAGAAQRsAAAYQtAEAYABBGwAABhC0AQBgAEEbAAAGELQBAGAAQRsAAAYQtAEAYABBGwAABhC0AQBgAEEbAAAGELQBAGAAQRsAAAYQtAEAYABBGwAABhC0AQBgAEEbAAAGELQBAGAAQRsAAAYQtAEAYIBVE7SraltVHaqqw1W1e7n7AQCA01kVQbuq1iT5cJL3Jtmc5H1VtXl5uwIAgFNbFUE7ydYkh7v7S939h0nuS7J9mXsCAIBTWi1Be0OSZ2bOj0w1AABYkdYudwOLVAvU+hWDqnYl2TWd/l5VHRraFbw6FyX5ynI3wcpSP7NzuVuAlc6/nbzSBxeKiGfdnzzVhdUStI8kuWzmfGOSZ08e1N13J7n7bDUFr0ZVzXX3luXuA2A18W8nq9FqWTry2SSbquqKqnpDkh1J9i9zTwAAcEqr4ol2d79YVR9I8skka5J8pLsPLnNbAABwSqsiaCdJd38iySeWuw9YApY3AZw5/3ay6lT3K75TCAAAvEarZY02AACsKoI2nEVVta2qDlXV4aravdz9AKx0VfWRqjpWVV9Y7l7gTAnacJZU1ZokH07y3iSbk7yvqjYvb1cAK949SbYtdxPwagjacPZsTXK4u7/U3X+Y5L4k25e5J4AVrbs/neSry90HvBqCNpw9G5I8M3N+ZKoBAOcgQRvOnoV+J9ZrfwDgHCVow9lzJMllM+cbkzy7TL0AAIMJ2nD2fDbJpqq6oqrekGRHkv3L3BMAMIigDWdJd7+Y5ANJPpnkiST7uvvg8nYFsLJV1UeTPJTkbVV1pKpuXu6eYLH8MiQAAAzgiTYAAAwgaAMAwACCNgAADCBoAwDAAII2AAAMIGgDnGOq6qWqenRm2/11xn+iqr5l2n7oVXzeT1bV3331HQOcm9YudwMALLk/6O6rFzu4u/9yklTV5Ul+KMmdY9oC+MbiiTbAN4Cq+mNVdaiq3jadf7Sq/tZ0/OWquijJ7Um+dXoK/tPTtR+vqs9W1W9W1U/N3O8fTPf7jSRvW4Y/CWDF80Qb4NyzrqoenTn/p939S1X1gST3VNWHklzQ3f/ypHm7k1z18tPwqnpPkk1JtiapJPur6tuTfC3JjiTvzPz/jnwuySMD/x6AVUnQBjj3LLh0pLsfrKobk3w4yTsWcZ/3TNvnp/M3ZT54vznJx7v795OkqvYvRdMA5xpLRwC+QVTV65K8PckfJLlwMVMy/zT86mn7093989O1HtUnwLlC0Ab4xvFjSZ5I8r4kH6mq1590/UTmn1a/7JNJfqCq3pQkVbWhqi5O8ukkf62q1lXVm5N89/jWAVYfS0cAzj0nr9H+tSQfSfI3k2zt7hNV9ekk/zDJB18e1N3PV9V/raovJHmgu3+8qt6e5KGqSpLfS/L+7v5cVf1SkkeT/FaS/3w2/iiA1aa6/b9/AACw1CwdAQCAAQRtAAAYQNAGAIABBG0AABhA0AYAgAEEbQAAGEDQBgCAAQRtAAAY4P8BzETqsRFotp4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(data=dataset,x=\"Exited\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-frame",
   "metadata": {
    "papermill": {
     "duration": 0.060921,
     "end_time": "2021-06-08T09:24:05.630188",
     "exception": false,
     "start_time": "2021-06-08T09:24:05.569267",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Some BoxPlots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adequate-serve",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-06-08T09:24:05.757109Z",
     "iopub.status.busy": "2021-06-08T09:24:05.756431Z",
     "iopub.status.idle": "2021-06-08T09:24:05.758616Z",
     "shell.execute_reply": "2021-06-08T09:24:05.759083Z",
     "shell.execute_reply.started": "2021-06-08T08:03:19.873629Z"
    },
    "papermill": {
     "duration": 0.067803,
     "end_time": "2021-06-08T09:24:05.759283",
     "exception": false,
     "start_time": "2021-06-08T09:24:05.691480",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def boxPlotter(columnName):\n",
    "        sns.catplot(x=\"Exited\", y=columnName, data=dataset, kind=\"box\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "indonesian-lover",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-06-08T09:24:05.887971Z",
     "iopub.status.busy": "2021-06-08T09:24:05.887211Z",
     "iopub.status.idle": "2021-06-08T09:24:07.408366Z",
     "shell.execute_reply": "2021-06-08T09:24:07.407784Z",
     "shell.execute_reply.started": "2021-06-08T08:03:19.883266Z"
    },
    "papermill": {
     "duration": 1.587256,
     "end_time": "2021-06-08T09:24:07.408513",
     "exception": false,
     "start_time": "2021-06-08T09:24:05.821257",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = ['CreditScore', 'Age', 'Tenure', 'Balance', 'EstimatedSalary']\n",
    "for column in cols:\n",
    "    boxPlotter(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intended-slovak",
   "metadata": {
    "papermill": {
     "duration": 0.063529,
     "end_time": "2021-06-08T09:24:07.536123",
     "exception": false,
     "start_time": "2021-06-08T09:24:07.472594",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "From above Plots we can conclude that:-\n",
    "1. There is no significant difference in credit score distribution between customers which are churned or not.\n",
    "1. The older customers are churning more than younger ones.\n",
    "1. Bank is loosing customers with significant bank balance.\n",
    "1. Estimated Salary does not have a significant on the likelihood to churn.\n",
    "Interestingly, majority of customers that churned are those with credit cards but this can be a coincidence as majority of customers have credit cards.\n",
    "Unsurprisingly the inactive members have a greater churn and the overall proportion of inactive members is also very high."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becoming-summit",
   "metadata": {
    "papermill": {
     "duration": 0.064246,
     "end_time": "2021-06-08T09:24:07.664891",
     "exception": false,
     "start_time": "2021-06-08T09:24:07.600645",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Correlation Plot\n",
    "Analyzing relationships between variables**\n",
    "\n",
    "We would also like to check, whether there are any significant (<= -0.70, >= 0.70) correlations between all features. The highest correlations are between NumOfProducts and Balance (-0.30) and also between Age and Exited (0.29). Nevertheless, it is not enough to consider there relations statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "physical-security",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-06-08T09:24:07.802538Z",
     "iopub.status.busy": "2021-06-08T09:24:07.801551Z",
     "iopub.status.idle": "2021-06-08T09:24:08.532621Z",
     "shell.execute_reply": "2021-06-08T09:24:08.531937Z",
     "shell.execute_reply.started": "2021-06-08T08:03:19.028747Z"
    },
    "papermill": {
     "duration": 0.803474,
     "end_time": "2021-06-08T09:24:08.532773",
     "exception": false,
     "start_time": "2021-06-08T09:24:07.729299",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABCEAAAO/CAYAAADxudxDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAADi30lEQVR4nOzdd3hURdvH8d8k9JpCSRAUBGyIJDQRUQgQEBQs+LxWQESRKi0gCIoCdgQVEMTuY0MfFEGxIEWKIEW6jS4ltCQQCKEkO+8fWUJ6VtmSbL6f68pFdneGvWdP5pyTO1OMtVYAAAAAAACeFuDrAAAAAAAAQNFAEgIAAAAAAHgFSQgAAAAAAOAVJCEAAAAAAIBXkIQAAAAAAABeQRICAAAAAAB4BUkIAAAAAACKGGPMO8aYQ8aYzbm8bowxrxljthljNhpjGrrjfUlCAAAAAABQ9Lwn6aY8Xu8gqa7zq5ekae54U5IQAAAAAAAUMdbaJZLi8yhyq6QPbJqVkoKMMeEX+r4kIQAAAAAAQFYXSdqT4fFe53MXpNiF/gf5OXtkh/X0e8A13RoN8XUIyMDI+DoEOAVwLAqMQMOxKCjO2FRfhwCn0sbjt2v4B07RNwqMU+JYFBRf7J7j1xfwwvo7bYnKtR9R2jSKc2ZYa2f8g/8ip+N6wZ8FVzUAAAAAAPyMM+HwT5IOWe2VVCPD4+qS9l9QUGI6BgAAAAAAyG6OpG7OXTKaSTpmrY290P+UkRAAAAAAAOTG4Z9Tf4wxn0hqJamSMWavpDGSikuStXa6pHmSOkraJumkpB7ueF+SEAAAAAAAFDHW2nvyed1K6ufu92U6BgAAAAAA8AqSEAAAAAAAwCuYjgEAAAAAQG6sw9cR+BVGQgAAAAAAAK8gCQEAAAAAALyCJAQAAAAAAPAK1oQAAAAAACA3DtaEcCdGQgAAAAAAAK8gCQEAAAAAALyC6RgAAAAAAOTCskWnWzESAgAAAAAAeAVJCAAAAAAA4BUkIQAAAAAAgFewJgQAAAAAALlhi063YiQEAAAAAADwCpIQAAAAAADAK5iOAQAAAABAbtii060YCQEAAAAAALyCJAQAAAAAAPAKl5MQxpjSxpjLPRkMAAAAAADwXy6tCWGM6SRpgqQSkmoZYyIkjbXWdvZgbAAAAAAA+JYj1dcR+BVXR0I8JamppKOSZK1dL6mmJwICAAAAAAD+ydUkRIq19phHIwEAAAAAAH7N1S06Nxtj7pUUaIypK+lRST97LiwAAAAAAOBvXB0JMUBSPUmnJX0s6ZikQR6KCQAAAACAgsE6CudXAZXvSAhjTKCkOdbatpJGeT4kAAAAAADgj/IdCWGtTZV00hhT0QvxAAAAAAAAP+XqmhCnJG0yxsyXlHTuSWvtox6JCgAAAACAgsBRcKc2FEauJiG+cX4BAAAAAAD8Ky4lIay17xtjSki6zPnUn9bas54LCwAAAAAA+BuXkhDGmFaS3pe0S5KRVMMY091au8RjkQEAAAAAAL/i6nSMlyW1s9b+KUnGmMskfSKpkacCAwAAAADA12wB3u6yMMp3dwyn4ucSEJJkrf1LUnHPhAQAAAAAAPyRqyMh1hhj3pb0X+fj+ySt9UxIAAAAAADAH7mahOgjqZ+kR5W2JsQSSa97KigAAAAAAAoEtuh0K1eTEMUkvWqtnShJxphASSU9FhUAAAAAAPA7rq4JsUBS6QyPS0v60f3hAAAAAAAAf+VqEqKUtfbEuQfO78t4JiQAAAAAAOCPXJ2OkWSMaWit/VWSjDGNJCV7LiwAAAAAAAoAtuh0K1eTEIMkfW6M2e98HC7pLo9EBAAAAAAA/JJLSQhr7WpjzBWSLlfa7hh/WGvPejQyAAAAAADgV/JcE8IY08QYEyZJzqRDQ0njJb1sjAnxQnwAAAAAAMBP5DcS4g1JbSXJGHOjpOclDZAUIWmGpDs9GVxBMPrZiVqyfJVCgoM0+8Ppvg7HL3V/6iFFRDXSmeTTmhbzmnZt3pGtTOUaVfTo5BiVDSqnXZt3aOrgV5R6NiXf+iYgQM9+PUHxB+L00oPPeK1NBdk1LSPVbUxPBQQGaNGnP2rutC+ylen2VM/0z3R6zOT0zzS3umUrltOjU4eqcvUqOrz3kF7rO0FJiUkKLBaoh1/op5pXX6rAYoFaOmuR5rye+f2GvjVSVS4O02PtBnq+8QXYNS0j1XXMgwoIDNDiT3/U3GlfZivT9ameiohqqNPJpzUjZkqm45Jb3egHOqpdtw5KTU3V+oVr9elz/9WlDeqo53N90goYoy9fmak13//ilXYWRvVbRui+J9M+359mLtA3ORyb+8Y8qAZRDXUm+YzejJms3Vt2SpJ6vthXEa0bKzHumEa1H5xe/q6R3RTRtrFSz6To0N8H9NawKTqZeNJrbSpsPHWdeG3ZDCUnJcuR6pAjNVWjOsVIkroMulut74lWYlyiJGnmSx9q/aK1Xmpt4XB1ywjd+2QPmcAALZ25QPOmzc5W5t4xD6p+VKTOJJ/R2zFT9PeWnQoOD9VDEweoYuUgWYfVT5/M14/vzkuv06Z7B7XpdpNSUx3auHCtPn/+Qy+2qnDJ7VqdUeUaVTRg8lCVCyqnnZt36PXBr6b3i9zq93qpvyKd562crs0397pV9416QI9EdNPxhOOebWQh1fOph9UwqrFOJ5/WlJhXtCOHY1OlRlUNmRyjckHltXPzdr06eJJSzqboxtta6rbeXSRJp04ma8aoadr1+y5Vu/QiDZ0yLL1+1YvD9OnEj/X1O3O81q4izZHq6wj8Sn67YwRaa+Od398laYa1dpa19glJdTwbWsFwW8doTZ843tdh+K2IqEYKqxWuwS376M2Rr6vn+N45lrt3RHfNe3uOhrTqq6RjJxR1V1uX6nd48Bbt27bX4+0oLExAgHqM66UXu4/TsLaPqnnnFrqobvVMZSKiGiqsVjUNadlXb42cpgfHP5Jv3c5979Dm5Zs0pFU/bV6+SZ363iFJuvbm5ipeophGtB+kUTcPVZt726tS9crp79XkpmY6dfKUl1pfcJmAAHUf97Be7D5ew9sOVLPON6haluPSIKqhwmqFa2jLfnp75HQ9ML5XvnWvvO5qNYpuopE3DdaI6EGaNyPtRmXvn3/riU7DNKrjUL3UfZx6PNtbAYGubpZUtJiAAHUb+7BefuAZjYwepGadW6hanczH5ppWacdmeKv+evfxaer+TK/015b9b7EmdB+X7f/dsmyDRrUbpNEdhujAzv26xdlnkJ2nrxPj7x6tkR0Hpycgzpn39hyN7DhYIzsOJgGRhQkI0P1jH9KkB57R6OjBujaHflG/VaSq1grXyFYD9P7j09XN2S8cKamaOf59jW47SM/cPlKtu96UXveK6+opMrqJnuwwVE+0G6zv3uSXq9zkdq3O6p4R3fTt23M1pFU/JR1LUtRdbfKtv+TzhXqh+9gc/7+Q8FDVb9FAh/cecn+j/ETDqEYKr1VN/Vo+oukjp6rX+D45lus6orvmvj1H/Vv11oljJ9TmrmhJ0sE9B/XE/43UkJse1eevzVTv5/pJkvbv2KehHQdpaMdBGnbLEJ1OPq1fvl/htXYB7pRvEsIYc260RBtJCzO85uqiloVa44j6qlihvK/D8FuNoptq6azFkqRt6/5SmQplFVQlOFu5es3r65d5P0uSlsxapMbtrs23fkhYqCJbN9aiT+d7viGFRJ2Iujq4K1aH9hxU6tkUrZi7TI2im2Yqk/aZLpKU+TPNq27GOkszHB9rrUqWKaWAwACVKFVSKWdTlHw8bWOdkmVKqeNDnTV78ufean6BVTuijg7uitVh52e7Mpfjssz5s7593V8q6zwuedVte397zX39S6WcSfurV2LcMUnSmVNn5EhNW+W5eMnikrVeamnhc2lEHR3cfSD98/1l7jI1bNckU5mG7Zpo+Rc/SZK2r9uqMuXLqmLlIEnSn6t+U9KxE1n/W21euiH9GGxf95eCw0I925BCzJPXCfw7l0bU0aHdB3R4zyFnv1iuiCz9IrJdE/38xWJJ0o51W1WmfBlVrBykY4eP6m/nSKFTSacUu32fgsLSZvhG3dde86adP2cdd45EQXa5XauzytgvlmbrFznX/2PVbzpxNOcRDl2ffFAfP/eBxGUjV02jr9Vi52f717o/VbZCWQXncGzqN79GK+YtlyQtmrVQTZ3H5s+1fygpMSmt/q9/KjS8Uva611+jg38f0OF9hz3VDMCj8ktCfCLpJ2PMV0rbknOpJBlj6kg65uHYUASEhIUobv+R9MfxB+IUUjXzciPlg8srKTEp/YY9LjZOIc4blrzqdxvTUx8/+74cDq6U5wSHhSguNsPnFRunkCy//ASHhSp+f9z5MgfiFFw1JM+6FSsF6eihBEnS0UMJqlipoiRp1bwVOn3ylF5f/Y5eWzFD38yYnf4L2X+G3qNv3vxKp5NPe6axhUhwWKjiYzN85rFxCg4LyVIm+8962nHJvW5YrWq6vOmVemr28xo1c5wuveb8ALbaEXX1/PxX9Nz3k/TuqDfS+xcyC64aoviMn3tsvIKrhmYrk+3Y/IOkwg3/aaNNi9ddeLB+ypPXCSurkR8+pWe+flmt72mX6f9s3+1mvfDdK3rkpf4qW6GsR9pWWAVl6RcJsWnno4yCq2a9lsRn6xeh1Svr4qtqasf6rZKkqpeGq27TKzV69nN6bObTqnlNbQ+2onDL7VqdUfZ+cST9GLhSP6uGbZso4UC8/v59l5ta4Z9CwkJ1ZP/55EDcgTiFZLlu5HTOCs3hutH27mitW5x9JFaLzjdq6Zwlbo4cebKOwvlVQOWZhLDWPiNpqKT3JLWwNv3PZQGS+udWzxjTyxizxhiz5q0PPnFXrPBDxphsz2X7o2weZXKrf24u487N290Rpt8wyunzyvyB5/CRSta6VDer2hF15XA41K9pTw1q0VsdH75VVWpU1SVX1VRYzXDWIXDK6SPP+lemnH/WbZ51A4oFqmzFcnrqthH65Nn31f/1oelFtq/fqhHRg/Rk5+Hq1PeOtBERyCa3zz1LoewVXRxd0qlfFzlSU/XzbG4mc+Op64QkPXXHCD1+81C90H2s2nXroCuaXiVJ+vHDbzXwxt4a0WGwEg4l6P4nelxQG/yNa/0ie72MZUqWKaV+02L0ydj3dOpE2gi5gMBAla1QTuNvG6nPnv2v+kwd4ta4/Ulu1+r8Cp07Bi7Vz6BEqRK6rf+d+nwi9/X5yfmSkPVeK/8+dPV19dXmrmh98Nz7mZ4vVryYmrRtqp+/WX7hwQI+ku+UCmvtSmPMf621X2Z47i9jzH8ldc2lzgylLVyps0d28GdoZBLdrYNa3532F6cdG7cqtNr5YWYhYaFKOBSfqfzx+ESVrVBWAYEBcqQ6FBoeqoSDaWXiYuNyrH9tx+vUsG0TRbRqpOIli6t0+TLq98ogTR30iucbWIDFH4jLNKwvJMNnmV4mNk4h1c5n49M+0wQVK1E817rHjhxVUJVgHT2UoKAqwTp2JG2gVPNbb9SGxeuUmpKqxLhj+mvtH6p1TW2VDy6vWvVr69VlbyigWIAqhlbU6E/HafzdT3iy+QVW/IE4hYRn+MxzOS5Zf9aPHkpQsRLFcq2bEBunNd+tlCTt2LBN1mFVPqSCjsefH+K8f9s+nU4+peqXXaydm0jaZRV/IE4hGT/38BAdzXKOSjiQdmy2nisTlv345eT6Lq0U0aaRXrj3KTdG7B+8cZ2QpATnCK7EuGNa/f0vqh1RV3+s+i39HCZJCz+Zr+HvjPJMQwuphCz9Ijg8NH00XOYyGa8lITrqPCaBxQLVb3qMVs5eql8zJKMTDsRprfPxzlzOWUVZdLcOiro7bd2AHRu35Xitzih7v6iUfgxyu9bnpuolYapco6qe/3ZSWvnwUD3zzct64tbhOnb4qLuaWGjd1K2jop3nrG0bt6pStcqSfpckheZwzkrM4ZwVn+G6cckVNdX3hf4a1/3pbFNjIls10o7N23XsyFGPtgnwJFdXIquX8YExJlBSI/eHg6Jg/gffpi/2teaHX3RDl1aSpDqRl+nk8aRsNzKStGXFJl3bsbkk6cYuUVo7f5Uk6dcfV+VY/9MXP1T/Zg/p0Ra99NqAl7Xl541FPgEhSds3bFVYrXBVrlFFgcWL6bpOLbR2/upMZdb+uFo3dImSlPaZJh8/qaOHEvKs+2uGOjdkOD5x+w6rXvP6kqSSpUuqTuRl2r99n3788Hv1a9pTA1s8oqfvfFyxO2OLbAJCSksQZPxsm3VqoV+zHJdff1ytFs6f9dqRl+mk87jkVXfND7/oKufnH1YrXMWKF9Px+ERVrlElfSHK0IsqK/zSi1hkLBc7N2xT1ZrhqlQ97fO9tlMLrZu/JlOZdfNX6/o7WkqSakfWVfLxk/nelNdvGaGbe9+mVx56XmdOnfFU+IWWN64TJUuXVKmypSSlnZ+uuTFCe//8W5Iyza1v0v5a7XE+jzTZ+8X1Wp/lnLV+/ho1v6OVJOnSyLo6maFf9Hihr2K37dUPb3+dqc66H1bryuuuliRVzXDOQpr5H3yrxzsO0eMdhzj7RfZrdVa/rdic3i9u6BKlNc5+kdu1Pjd7/vxbfRo9oIEtHtHAFo8oPjZOo24eSgLC6bsP5qUvGrnqh1/UyvnZXhZ5uU4eP5ljgmfzik26ruP1kqSoLq21en5aAq5StUoa/sZIvTp4kmJ37s9W74bON2gZUzFQyJm8hlMbY0ZKelxSaUnn9g4zks4obaeMkfm9QWEfCTFszPNavW6jjh5NVGhIkPr27Koundr7Oqx/pVujgjmssce4XmrQMm3bwTdiXtMO519jh7/3hN4cPkUJhxJUpUZVDZgyVOWCymvXlh2aOmhS+sJVudU/58pmV+uWXrcWuC06c5re4A0RUQ3V9cm0bTYXf7ZAX035n9rcl/YzveCj7yVJD4zrpQYtI52f6eT0v5DnVFeSygWV16Ovx6hStUo6sv+IXu3zkpKOnVDJMqXUe8KAtF00jNGSzxfq6zdmZ4qnUvXKGvbOaJ9u0Rngo2ORUYOohrr/3DaQny3QnCmz1Pq+tL+qLPzoB0lS93EP65qWkTrj3KLz3HHJqa4kBRYvpl4v9dPFV9VS6tkUffzMe/rt5826/vaW6tT3dqWeTZW1Vl+++pnW/rDKNw3PIjDHMcK+dU2rhrrvyR4KCAzQks8Wau7UWYpyHptFzmPTdexDusbZZ94aNlW7nMemz2uDdUWzeioXXF6JR47py0kzteSzBXpx8RQVK1E8/S9c29f9pfdHzfBNA3Nxxhac7cg8cZ2oUqOqhswYISntL/PLv1qi2c5zWt9Jg3TJVbUka3V47yG99fi0PH9B87TSpuCtBV6/VaTucfaLZZ8t1NdTv1ArZ79Y7OwX9499SFe3jNCZ5NN6Z9jr2rVpu+o2vkIj/zdee37fLeucrzzrxY+1afE6BRYvpgdf7KsaV9VU6tkUzXzmA/2xYrPP2pibUwWkb+R2rR7+3mjNGD5VRzP0i7JB5bR7y85M/SK3+v1fG6Irr6un8sEVdOzIUc2a9KkWz1yQ6b1fXfaGRneK8fkWnadUMI5FVg+Pe0SRznPOlJjXtH3TNknSqPee1OvDpyjhULyq1qiqIVOGpW3RuWWHXhn0slLOpKjvC/3VrEPz9D8OpKamanintOmUJUqV0Jsr31GfG3rp5PGCta3zF7vnFLwLuBud3rKgUP5OW7JemwJ5XPJMQqQXMuY5VxIOOSnsSQh/UlCTEEWVr5IQyK4gJCGQpiAmIYqqgpSEKOoKYhKiKCsoSQgU3CREUUQSomAqqEmIPK9qxpgrrLV/SPrcGNMw6+vW2l89FhkAAAAAAPAr+aXWh0p6WNLLObxmJbV2e0QAAAAAABQUBXi7y8IozySEtfZh579R3gkHAAAAAAD4q/ymY9yR1+vW2i/cGw4AAAAAAPBX+U3H6OT8t4qk5pIWOh9HSVosiSQEAAAAAABwSX7TMXpIkjHma0lXWWtjnY/DJU31fHgAAAAAAPiQgzUh3CnAxXI1zyUgnA5KuswD8QAAAAAAAD/l6sbTi40x30v6RGm7YtwtaZHHogIAAAAAAH7HpSSEtba/MeZ2STc6n5phrf3Sc2EBAAAAAAB/4+pICEn6VdJxa+2Pxpgyxpjy1trjngoMAAAAAABfszbV1yH4FZfWhDDGPCzpf5LecD51kaTZHooJAAAAAAD4IVcXpuwn6XpJiZJkrd2qtG07AQAAAAAAXOLqdIzT1tozxhhJkjGmmNIWqAQAAAAAwH9Ztuh0J1dHQvxkjHlcUmljTLSkzyXN9VxYAAAAAADA37iahHhM0mFJmyQ9ImmepNGeCgoAAAAAAPiffKdjGGMCJG201l4t6U3PhwQAAAAAAPxRvkkIa63DGLPBGHOxtfZvbwQFAAAAAECB4GBNCHdydWHKcElbjDGrJCWde9Ja29kjUQEAAAAAAL+TZxLCGFNHUlVJT2d5qaWkfZ4KCgAAAAAA+J/8RkK8Iulxa+3GjE8aY5IkjZH0tofiAgAAAADA99ii063y2x2jZtYEhCRZa9dIqumRiAAAAAAAgF/KLwlRKo/XSrszEAAAAAAA4N/yS0KsNsY8nPVJY0xPSWs9ExIAAAAAAPBH+a0JMUjSl8aY+3Q+6dBYUglJt3swLgAAAAAAfM+R6usI/EqeSQhr7UFJzY0xUZKudj79jbV2occjAwAAAAAAfiW/kRCSJGvtIkmLPBwLAAAAAADwY/mtCQEAAAAAAOAWLo2EAAAAAACgSLIOX0fgVxgJAQAAAAAAvIIkBAAAAAAA8AqmYwAAAAAAkBsH0zHciZEQAAAAAADAK0hCAAAAAAAAryAJAQAAAAAAvII1IQAAAAAAyA1bdLoVIyEAAAAAAIBXkIQAAAAAAABeQRICAAAAAAB4BWtCAAAAAACQGwdrQrgTIyEAAAAAAIBXkIQAAAAAAABewXQMAAAAAAByw3QMt2IkBAAAAAAA8AqSEAAAAAAAwCtIQgAAAAAAAK9gTQgAAAAAAHJhbaqvQ/ArHk9CdGs0xNNvARd9sHair0NABvfTNwqMMibQ1yHAKc5x2tchwKkE/aLAqKTivg4BGexRiq9DgFOvU2V8HQKAf4HpGAAAAAAAwCuYjgEAAAAAQG7YotOtGAkBAAAAAAC8giQEAAAAAADwCpIQAAAAAADAK1gTAgAAAACA3FjWhHAnRkIAAAAAAACvIAkBAAAAAAC8giQEAAAAAADwCtaEAAAAAAAgNw7WhHAnRkIAAAAAAACvIAkBAAAAAAC8gukYAAAAAADkhi063YqREAAAAAAAwCtIQgAAAAAAAK8gCQEAAAAAALyCNSEAAAAAAMgNW3S6FSMhAAAAAACAV5CEAAAAAAAAXsF0DAAAAAAAcsMWnW7FSAgAAAAAAOAVJCEAAAAAAIBXkIQAAAAAAABewZoQAAAAAADkhi063YqREAAAAAAAwCtIQgAAAAAAAK8gCQEAAAAAALyCNSEAAAAAAMgNa0K4FSMhAAAAAACAV5CEAAAAAAAAXsF0DAAAAAAAcmOZjuFOjIQAAAAAAABeQRICAAAAAAB4BUkIAAAAAADgFawJAQAAAABAbtii060YCQEAAAAAQBFkjLnJGPOnMWabMWZEDq9XNMbMNcZsMMZsMcb0uND3JAkBAAAAAEARY4wJlDRVUgdJV0m6xxhzVZZi/ST9Zq1tIKmVpJeNMSUu5H2ZjgEAAAAAQG78d4vOppK2WWt3SJIx5lNJt0r6LUMZK6m8McZIKicpXlLKhbwpIyEAAAAAAPAzxphexpg1Gb56ZSlykaQ9GR7vdT6X0RRJV0raL2mTpIHWXlhWhpEQAAAAAAD4GWvtDEkz8ihicqqW5XF7SesltZZUW9J8Y8xSa23iv42LkRAAAAAAABQ9eyXVyPC4utJGPGTUQ9IXNs02STslXXEhb8pICAAAAAAAcuO/W3SullTXGFNL0j5Jd0u6N0uZvyW1kbTUGFNV0uWSdlzIm5KEAAAAAACgiLHWphhj+kv6XlKgpHestVuMMb2dr0+XNE7Se8aYTUqbvvGYtfbIhbwvSQgAAAAAAIoga+08SfOyPDc9w/f7JbVz53vmuyaEMaaqMeZtY8y3zsdXGWN6ujMIAAAAAADg/1xZmPI9pQ3PqOZ8/JekQR6KBwAAAACAgsM6CudXAeXKdIxK1trPjDEjpfR5I6kejsvjuj/1kCKiGulM8mlNi3lNuzZnX1ujco0qenRyjMoGldOuzTs0dfArSj2bkm99ExCgZ7+eoPgDcXrpwWe81iZ/N/rZiVqyfJVCgoM0+8Pp+VfABXvgqYcUGdVIp50/5ztz6ScDJ8eoXFA57dy8Q1Oc/aRa7YvUZ8IA1apXW59O+FBfz/jKBy0ovOq1jNA9T/ZQQGCAls5coG+nzc5W5p4xD6p+VKTOJJ/ROzFT9PeWnQoOD1XPiQNUsXKQHA6rJZ/M14J300bY1biqpu5/ppeKlywuR4pDHz3xpnZu2ObllhVOPZ/upUbOvjB56KvasXl7tjJValTV0CnDVC6ovHZs3q5XB01UytkUNY2+VvfE3CfrsEpNTdU7T7+l31f/Jknq/9KjatymiY7FHdPA6P7eblah5InzUmh4JfWbNFBBzn6z4OMf9O27X3u7aYXKZS0b6NYnu8kEBmjVzEVaPG1OtjKdx3TXFVEROpt8Rp/FTNO+LbskSTf07KAmd7WWrNWBP/fos2HTlXL6rKIHdVHTu1srKT5t17fvXpypPxav92KrChdP3MuGX1pNj04Zll6/ysVV9b+Jn+jbd+bq3se7q2GbJko9m6KDuw9o+rDJOpmY5LX2FkaVohroyvHdpcAA7f1ooXZOztxPwrtcr0v7d5YkpSSd1m/D39Lx3/6WJF3ycAdVv7+1JGnvRwu1e8a33g0e8CBXRkIkGWNC5dwv1BjTTNIxj0blYRFRjRRWK1yDW/bRmyNfV8/xvXMsd++I7pr39hwNadVXScdOKOquti7V7/DgLdq3ba/H21HU3NYxWtMnjvd1GEXGuZ/zgfn0k/uc/WSQs5+0dvaTE0dP6L0xb2num7O9GLV/MAEBum/sQ3rlgWf0RPRgNe3cQuF1qmcqU79VpKrUCtfjrQbog8en6/5nekmSHCmp+mz8+3qi7SA9e/tIRXW9Kb3unSO6au6rn2tsx2H6auKnunNkV6+3rTBqGNVI1WpWU98bH9G0EVP1yDN9cizXbeQDmvvWV+rX8hElHTuhNndFS5I2Lt+gwe0f1ZAOAzUl5jX1fWFAep2Fny/Q2G5PeaMZfsFT56XU1FT9d/y7GtJmgEbfNlztunXQRXWr5/A/Q5JMgNHtY3vo7Qde0MvRMYro3FxV6lyUqcwVrSJUqVaYXmw1WLMef1O3P5M2k7dC1WBd/8BNeq3T45rYfrhMQIAadLouvd7St+fplY4j9UrHkSQg8uCpe9nYHfs1suNgjew4WI/fMlRnkk9r9fcrJUmblm7Q8HaP6rGbBil2537d2reLdxpbWAUYXfX8g1pz7/NadsNQhd9+vcpelrmfJO8+rF9uG6vlUY9p+8QvVO/ltGt5uSuqq/r9rbXiplH6ufVjqhzdUGVqhfmiFYBHuJKEGCJpjqTaxpjlkj6QNCDvKgVbo+imWjprsSRp27q/VKZCWQVVCc5Wrl7z+vpl3s+SpCWzFqlxu2vzrR8SFqrI1o216NP5nm9IEdM4or4qVijv6zCKjCbRTbXE+XO+dd1fKptHP1np7Cc/zVqkJs5+khh3TNs3blPq2UI/cMrrakXU0aHdB3RkzyGlnk3RqrnLFdGuSaYyEe2aaMUXiyVJO9ZtVZnyZVSxcpCOHT6qv7fslCSdTjql2O37FBwWIkmysipdrrQkqXSFMjp6MN57jSrEmrZrpkWzFkqS/lr3p8pWKKvgHPpC/ebX6Od5yyVJi/63QNe2byZJOnXyVHqZUmVKStamP/5t1RYdP3rck+H7FU+dl44eSkgfUXEq6ZT2bdurkKqhHmxJ4VYjoo6O7D6g+D2HlHo2VRvmrlC9do0zlbmqXSP9+sVSSdLf67apdPkyKl85SJIUEBio4qVKKCAwQCVKl1DiwQRvN6HQ8+S97DlXX3+NDv59QEf2HZYkbVq6Xo7UtOHdW9f9qZBw+kheghrW0cmdB5S8+5Ds2VQdmP2zqt6UuZ8cXfOXUo6ljSY5unarSoWnXa/L1r1IR9dulSP5jGyqQwk//66qHZtkew94kcNROL8KqHyTENbaXyW1lNRc0iOS6llrN3o6ME8KCQtR3P7zu4rEH4hTSNWQTGXKB5dXUmJS+sk2LjZOIc4b+bzqdxvTUx8/+74cDiugMAvO8nMel0s/OZmhn8Rn6Cf494Krhighw2efEBun4CyffVDVUMXvjztf5kC8gsIy3xCGVq+si6+qqR3rt0qSZj79ru4c2VUv/jxd/3m8m2a9+JEHW+E/QsNCFRebpS9k+azLB1dQUuKJ9L5wJDZOoRnKXNu+mSYvnKZR743RlGGveidwP+SN81Ll6lVUq96l2rb+L/cE7YcqVg3WsQznn2OxcapQNThLmRAdzVDm6IF4VQwLUeLBBP305td6/OcpGr1qmk4dP6mtSzell2vevb0Gf/uC/vPiIypdoaznG1NIefJe9pzmnVvo5zlLc3z/Vv/XVhsW/+qWtvirkmEhSs7QB07tj1fJPM5F1e+N0uGF6yVJJ/7Yo5BmV6p4cDkFlC6hym0jVOoikj7wH67sjnGHpM6SLpd0maROxpg2xpgqng7OU4wx2Z6zWXMGeZTJrX5k68ZKjDumnTnMFQYKmwvtJ7gAOX6uNr8imT78kmVKqe+0GM0c+55OnUiWJLW6v71mjntPw5v31sxx7+mBF/q6NeyixJXjkbHML9+v1IDWffT8Q8/onpj7PR2e3/L0ealkmVIaMv0xvT/2bSU7+w1ykOMPfP5lrLUqXaGs6kU31vM3PKrx1/ZV8TIlFXlbC0nSig9/1As3DtQrHUco8VCCbhlNX8mNp+5lzwksXkyN2jbVL98sz1butv53ypGSqmVf/vSPYi5ycrpOZ+soaUKuv0rV743SX+M+liQlbd2vHVPmqPFno9T4k5FK3LJbNqXg/lUb+KdcWZiyp6TrJC1yPm4laaWky4wxY621/81awRjTS1IvSWoc0kB1ytV0S7AXIrpbB7W+O2170x0btyq0WqX010LCQpVwKPOw5OPxiSpboawCAgPkSHUoNDxUCc6hy3GxcTnWv7bjdWrYtokiWjVS8ZLFVbp8GfV7ZZCmDnrF8w0E3KBdtw5q4+wn27P0k9Bc+kmZDP0kJEM/wb+XcCBOwRk+++DwUB09lJCtTEi1838VCQ4LSZ9eEVgsUH2mx2jl7KX69ftf0stc16WlPnn6HUnSmm9WqPvzOa9tAKlDt46Kvqe9JGnbxq0KDc/SF7L8nCfGJ6pshXLpfaFSeKjic+gLv63aorCLw1U+uIKOJyR6thF+wlvnpcBigRo6/TEtm/2TVn230r2N8DPHDsSrYobzT8XwUCVmOUcdOxCnoAxlgpyjIOq0uFrxew4pKT5tGtLm71brkkaXad3sZTpx5PySY6s+Xagebw/3cEsKF2/cy54T0aqhdm7eoWNHMi8Dd2OXKEW2aaxn7nnS7e3zN6dj41U6Qx8oVS1Epw9kn3pU7qqLdfXER7Tmnud1NuFE+vP7Pl6kfR+n/fpV9/G7dSrDqAqgsHNlTQiHpCuttV2stV0kXSXptKRrJT2WUwVr7QxrbWNrbeOCkICQpPkffJu+0M6aH37RDV1aSZLqRF6mk8eTst3gS9KWFZt0bcfmktJOumvnr5Ik/frjqhzrf/rih+rf7CE92qKXXhvwsrb8vJEEBAqVHz74Vo91HKzHOg7W6h9+0Y3On/O6efST31ZsUjNnP2nZJUprnP0E/96uDdtUtWa4KlWvosDixdS00/XaMH91pjLr56/RdXe0kiRdGllXycdP6tjho5Kk7i/0Vey2vZr/dubV/Y8dStDlzepJkq5oXl+HdsV6vC2F1bcfzNOQDgM1pMNA/fL9SkV1SVuh/LLIy3Xy+Ekl5NAXNq/YqOYdr5ckRd3ZRqt+SEsAhV0Snl7m0qtrq1iJYiQg/gFvnZd6v9hf+7bt1TdvZd/lAZnt3bBdlWqGKbh6ZQUWD1SDTtfpt/lrM5X5bf6vanjHDZKkiyPrKPn4SR0/fFRH9x/RxZF1VbxUCUlSneuv1qFt+yQpfc0ISbq6fRMd+GuPdxpUSHjjXvac5p1v0M9zlmT6vxq0jFSnPndoQs9ndebUGQ+00L8cW7ddZS4NU+mLK8sUD1TYbc116PvM/aTURaGKfGeINvabqpM7Ml+TS1SqkF6mascmiv3yZ6/Fjhz4em0HP1sTwmQdUpqtgDGbrLX1Mzw2kjZZa682xqyz1kbmVf+eS24rkIOze4zrpQYtG+p08mm9EfOadmxKm0Ix/L0n9ObwKUo4lKAqNapqwJShKhdUXru27NDUQZOUciYlz/rnXNnsat3S69YCtUXnB2sn+jqECzJszPNavW6jjh5NVGhIkPr27Koundr7Oqx/7f5GQ3wdQr4edP6cn9u+69zP+Yj3ntAbGfrJwAz9ZLKzn1SsHKTn5k5Q6XJlZB1Wp04ma2jbAQVyiHN548qgMO+q3ypSdzm36Fz+2UJ9M/ULtbwv7S9gP330gyTp3rEP6eqWETqTfFrvDntduzdtV53GV2jE/8Zr7++75XDuD/3lix9r0+J1qtP4Ct0zpocCigXq7Omz+mj0m9qdw5ZuvhTnOO3rEHLUa1xvRbZKO+dPjnlV2zembW06+r0xmvrYZCUcjFfVi6tq6JThadtCbtmhSQNfVsqZFN3ep4tadWmt1LMpOnPqjN5/9t30LTqHTI5Rvevqq0JwBR09clSfTvxYC2YWjIWNS5hAX4eQI0+cly6+oqbGznpOu3/fJetc0+mTlz7U+kVr8wrFay4xpX0dQjZXtIpQpye7KSAwQKs/W6yFU2er2X1pOy+s/OhHSdJtY3vo8pYNdCb5tD4f9ob2bko730QPvlMNbmkmR4pD+7bs0v9GzFDqmRTdNbGvql11iWSlhL2HNevxt3TcmVwtSPbYgnEd89S9bIlSJTRl5VsaeENvJR8/mf5+k36apuIliut4Qtoolm3r/tTbo3y7ZXr3U6V8+v75qdQmQleO6y4TGKC9nyzSjldmq0a3tH6y54MfVW9iL4Xd3FTJe9PW57ApqVrRfpQkqelXT6lEcDk5UlL1x5j/Kn7pZp+1wxU3Hfw0xwko/iL5s7EF8nfa/JT+vycL5HFxJQnxuqSLJX3ufKqLpL2Shkn62loblVf9gpqEKIoKexLC3xSGJERRURCTEEVVQU1CFEUFNQlRFBXEJERRVlCSECj4SYiihCREwVRQkxCu3Hn3k3SHpBbOx6skhVtrkyTlmYAAAAAAAAA4J98khLXWGmO2K20NiP+TtFPSLE8HBgAAAACAz7H9m1vlmoQwxlwm6W5J90iKkzRTadM3GP0AAAAAAAD+sbxGQvwhaamkTtbabZJkjBnslagAAAAAAIDfySsJ0UVpIyEWGWO+k/SppAK5sAUAAAAAAB5RgLe7LIwCcnvBWvultfYuSVdIWixpsKSqxphpxph2XooPAAAAAAD4iVyTEOdYa5OstR9Za2+RVF3SekkjPB0YAAAAAADwL/kmITKy1sZba9+w1rb2VEAAAAAAAMA/5btFJwAAAAAARRZrQrjVPxoJAQAAAAAA8G+RhAAAAAAAAF7BdAwAAAAAAHJjmY7hToyEAAAAAAAAXkESAgAAAAAAeAVJCAAAAAAA4BWsCQEAAAAAQG7YotOtGAkBAAAAAAC8giQEAAAAAADwCpIQAAAAAADAK1gTAgAAAACA3Fjr6wj8CiMhAAAAAACAV5CEAAAAAAAAXsF0DAAAAAAAcsMWnW7FSAgAAAAAAOAVJCEAAAAAAIBXkIQAAAAAAABewZoQAAAAAADkhjUh3IqREAAAAAAAwCtIQgAAAAAAAK9gOgYAAAAAALmxTMdwJ0ZCAAAAAAAAryAJAQAAAAAAvIIkBAAAAAAA8ArWhAAAAAAAIBfWYX0dgl9hJAQAAAAAAPAKkhAAAAAAAMArSEIAAAAAAACvYE0IAAAAAABy43D4OgK/wkgIAAAAAADgFSQhAAAAAACAVzAdAwAAAACA3FimY7gTIyEAAAAAAIBXkIQAAAAAAABeQRICAAAAAAB4BWtCAAAAAACQG4f1dQR+hZEQAAAAAADAK0hCAAAAAAAAr/D4dAwj4+m3gIvubzTE1yEggw/XTvR1CHCibxQcFQJK+DoEOAVy/S4wttkkX4eADMoym7nAeLtUsq9DgNNNvg7A0xxs0elOjIQAAAAAAABeQRICAAAAAAB4BUkIAAAAAADgFUxqAwAAAAAgN6wJ4VaMhAAAAAAAAF5BEgIAAAAAAHgFSQgAAAAAAOAVrAkBAAAAAEBurPV1BH6FkRAAAAAAAMArSEIAAAAAAACvYDoGAAAAAAC5YYtOt2IkBAAAAAAA8AqSEAAAAAAAwCtIQgAAAAAAAK9gTQgAAAAAAHLjYItOd2IkBAAAAAAA8AqSEAAAAAAAwCuYjgEAAAAAQG4sW3S6EyMhAAAAAACAV5CEAAAAAAAAXkESAgAAAAAAeAVrQgAAAAAAkBu26HQrRkIAAAAAAACvIAkBAAAAAAC8giQEAAAAAADwCtaEAAAAAAAgF9bh8HUIfoWREAAAAAAAwCtIQgAAAAAAAK9gOgYAAAAAALlhi063YiQEAAAAAADwCpIQAAAAAADAK0hCAAAAAAAAr2BNCAAAAAAAcmPZotOdGAkBAAAAAAC8giQEAAAAAADwinyTECbN/caYJ52PLzbGNPV8aAAAAAAAwJ+4sibE65IcklpLGivpuKRZkpp4MC4AAAAAAHzPYX0dgV9xJQlxrbW2oTFmnSRZaxOMMSU8HBcAAAAAAPAzrqwJcdYYEyjJSpIxprLSRkYAAAAAAAC4zJWREK9J+lJSFWPMM5LulDTao1EBAAAAAFAQOPgbvDvlmYQwxgRI2ilpuKQ2koyk26y1v3shNgAAAAAA4EfyTEJYax3GmJettddJ+sNLMQEAAAAAAD/kypoQPxhjuhhjjMejAQAAAAAAfsuVNSGGSCorKcUYc0ppUzKstbaCRyMDAAAAAMDX2KLTrfJNQlhry3sjEAAAAAAA4N/yTUIYY27M6Xlr7RL3hwMAAAAAAPyVK9MxhmX4vpSkppLWSmrtkYjc6JqWkeo2pqcCAgO06NMfNXfaF9nKdHuqpyKiGulM8mlNj5msXZt35Fm3bMVyenTqUFWuXkWH9x7Sa30nKCkxSYHFAvXwC/1U8+pLFVgsUEtnLdKc1zO/39C3RqrKxWF6rN1Azze+kHrgqYcUGdVIp5NPa1rMa9rpPB4ZVa5RRQMnx6hcUDnt3LxDUwa/otSzKapW+yL1mTBAterV1qcTPtTXM77yQQuKhtHPTtSS5asUEhyk2R9O93U4fssT/SE0vJL6TRqooMpBcjisFnz8g75992tvN61Qqd8yQvc9+aACAgP008wF+mbal9nK3DfmQTWIaqgzyWf0Zsxk7d6yU5LU88W+imjdWIlxxzSq/eD08ncMuVsNo5vKYR06fuSY3oyZoqOHErzWpsLq6pYRuvfJHjKBAVo6c4HmTZudrcy9Yx5U/ahInUk+o7djpujvLTsVHB6qhyYOUMXKQbIOq58+ma8f350nSbp9yN2KiG4iax1KPJKodzgWLuv51MNqGNVYp5NPa0rMK9qRwzmqSo2qGjI5RuWCymvn5u16dfAkpZxN0Y23tdRtvbtIkk6dTNaMUdO06/ddkqRbenZW27vbSdZq9x+7NWXYqzp7+qw3m1bg1W8Zqa5j0s5Liz/9UV/ncF7q+lRPNYhqqNPJpzUjZop2O49PbnX7TRmq8EurSZLKVCirk4lJGt1xqAKLBarnC31V8+pLFVAsUMtnLdbc17PfU+O8Hk89rIbO6/fUmFdzvH5XqVFFgyYPS79+T3b2jWq1L1K/CY+qVr3a+mTCh5o7Y3amegEBAXr+65cVfyBOzz843kstgixbdLpTvgtTWms7ZfiKlnS1pIOeD+3CmIAA9RjXSy92H6dhbR9V884tdFHd6pnKREQ1VFitahrSsq/eGjlND45/JN+6nfveoc3LN2lIq37avHyTOvW9Q5J07c3NVbxEMY1oP0ijbh6qNve2V6XqldPfq8lNzXTq5Ckvtb5wiohqpLBa4RrYso/eHPm6eo7vnWO5+0Z017y352hQq75KOnZCre9qK0k6cfSE3hvzlua+OduLURdNt3WM1vSJXPg8yVP9ITU1Vf8d/66GtBmg0bcNV7tuHbKdG3GeCQhQt7EP6+UHntHI6EFq1rmFqtXJ/Hld06qhwmqFa3ir/nr38Wnq/kyv9NeW/W+xJnQfl+3/nTfjK43uMERPdozR+oVrdevA/3i8LYWdCQjQ/WMf0qQHntHo6MG6NodjUb9VpKrWCtfIVgP0/uPT1c15LBwpqZo5/n2NbjtIz9w+Uq273pRe99sZX2lMh6F6quMwbVy4Vp04Fi5pGNVI4bWqqV/LRzR95FT1Gt8nx3JdR3TX3LfnqH+r3jpx7ITa3BUtSTq456Ce+L+RGnLTo/r8tZnq/Vw/SVJI1RDd3KOTht8yRIPaDVBAYIBadLrBa+0qDExAgLqPe1gvdR+vx9oO1HWdb1C1LOfxBlENVbVWuGJa9tM7I6erx/he+dad2v9lje44VKM7DtXq71ZqzXcrJUlNb26u4iWK6/H2g/XkzTGKurddpntcZBYZ1UjhtcI1oGVvvTFyqh7OpW/cN6K7vn57jh5t1Ucnsly/3xnzZq73sx0fvEX7tu3xVPiAV7iyO0ZWe5WWiCjQ6kTU1cFdsTq056BSz6ZoxdxlahTdNFOZRtFNtXTWIknStnV/qUyFsgqqEpxn3Yx1ls5apMbtrpUkWWtVskwpBQQGqESpkko5m6Lk48mSpJJlSqnjQ501e/Ln3mp+odQkuqmWzFosSdq67i+VdR6PrOo1r6+V836WJP00a5GaOI9BYtwxbd+4TalnU70Wc1HVOKK+KlZguRhP8lR/OHooIf0vMqeSTmnftr0KqRrqwZYUbpdG1NHB3Qd02Hk9+GXuMjVs1yRTmYbtmmj5Fz9Jkrav26oy5cuqYuUgSdKfq35T0rET2f7fUyeS078vWaakxHpX+bo0oo4O7T6gw3sOOY/FckVkORaR7Zro5y8WS5J2rNuqMuXLqGLlIB07fFR/O0ennEo6pdjt+xQUFpL2OMOxKFGmpGQ5GK5oGn2tFjvvh/5a96fKViir4BzOUfWbX6MV85ZLkhbNWqimznPUn2v/UFJiUlr9X/9UaHil9DqBgQEqUaqEAgIDVLJ0ScUfjPd0cwqV2hF1dHBXbPp5aWUO97gNo5tqmfMast15j1uxSrBLdaW0P66tmLNM0rl73JLOe9wSme5xkV2T6Kb6ydk38rp+X938Gq109o2fZi1Uk3bNJJ2/fqecTclWJyQsVA1bN9aCT+d7sAWA57myJsRknb89CpAUIWmDB2Nyi+CwEMXFHkl/HB8bpzqRl2UpE6r4/XHnyxyIU3DVkDzrVqwUlD5M8+ihBFWsVFGStGreCjWObqrXV7+jEqVL6sOx76TfeP5n6D365s2vdDr5tGca6yeCw0IUt//85x53IE4hVUMyDYstH1xeJxOT5EhNGxIVHxunEOeNJOBPvNEfKlevolr1LtW29X+5L3A/E1w1RPH7M14P4lU7om62MhmPVfyBOAWHherY4aN5/t9dYu7V9Xe0VPLxk3r+njFujdsfBWU5Fgmxcbo027HIel2Pz3YsQqtX1sVX1dSO9VvTn7sj5h41v6OlTh4/qZfuecpjbfAnIWGhOrL/cPrjtHNUqBKynKOSMpyj4mLjFBqWPenZ9u5orVu8VpIUfzBeX82YrTdWvK0zp85ow9J12rB0vWcbU8gEh4UqPjbDz3lsnGpHZukLYVnOXc5riCt1L296lY4dOaqDu2IlSavnrVCj6KaavPptlSxdUh+NfTfH5CrShISFZrl+H1FI1dA8r99xLl6/e4x5SB8++75KlSvt/sABL3JlJMQapa0BsVbSCkmPWWvvz6uCMaaXMWaNMWbNthO7LjzKf8HIZHvOZvnrhsleRLLWpbpZ1Y6oK4fDoX5Ne2pQi97q+PCtqlKjqi65qqbCaoZrzfe//KP4iyKTwwHJ9rG7UgbwA57uDyXLlNKQ6Y/p/bFvK/kEf9HKTc7HwWYtlL2iCwdi1oSPNaT5I1rx1RK17d7h34ZYZLh2LLLXy1imZJlS6jctRp+MfS/TCIgvJnyimOa9tfKrpWrd/Sa3xezPcv6xz3qflf8xu/q6+mpzV7Q+eO59SVLZCmXVtN216tPiYT3U9AGVLF1KN97eyl1h+4Vcbl8zl8nls3el7nWdW2ilcxSEJF3qvMd9tOlDGtKijzo83FmVa1T954EXETl99lk/ZFfKZNWwdWMdizuqHZu3X0h4+LcctnB+FVCubNH5/j/9T621MyTNkKR7L7ndJ62PPxCXaWhfSHioErIM54uPjVNItfMZ+ZCwtAx+sRLFc6177MhRBVUJ1tFDCQqqEqxjR45JkprfeqM2LF6n1JRUJcYd019r/1Cta2qrfHB51apfW68ue0MBxQJUMbSiRn86TuPvfsKTzS802nXroDZ3t5Mkbd+4VaHVzn/uoWGhSjiU+Zgdj09UmQplFRAYIEeqI8fjChRW3uoPgcUCNXT6Y1o2+yetcs75Rc7iD8QppFrG60GIjmY5DgkH4hRarZLO/V09JOyfnZdWfLVMQ955XF9OmumOkP1WQpZjERwemm0BybQyGa/rITrqPBaBxQLVb3qMVs5eql9z+cPAL18t1cB3HtdXkz7zQAsKv5u6dVS08xy1beNWVapWWdLvknI+RyXGJ6pshnNUaHhopqkVl1xRU31f6K9x3Z/WiaPHJUnXtIjQwT0HlRifKEn65bsVuqLRFVry5WLPN7CQiD8Qp5DwDD/n4aHpP+fpZWKznLvS73GL5Vk3IDBAjW9qpiduOb8uffNbb9DGHO5xD+8p8EvEeU37bh3V9u609U62bdyW5fpdSfE59I0y2fpG3gviXtH4SjVu21SRrRqpRMkSKl2+jAa8MliTB01yf4MAD8t3JIQx5npjzHxjzF/GmB3GmJ3GmOxLvBYw2zdsVVitcFWuUUWBxYvpuk4ttHb+6kxl1v64Wjd0iZIk1Ym8TMnHT+rooYQ86/6aoc4NXaK0dv4qSVLcvsOq17y+JKlk6ZKqE3mZ9m/fpx8//F79mvbUwBaP6Ok7H1fszlgSEBn88MG3eqzjYD3WcbBW//CLbuzSSpJUN/IynTyelOMK5b+t2KRmHZtLklp2idIa5zEACjtv9YfeL/bXvm179c1bc9wavz/auWGbqtYMV6XqadeDazu10Lr5azKVWTd/ta6/o6UkqXZkXSUfP5nvVIyqNcPTv49s21ix2/e5PXZ/k/1YXK/1Wa7r6+evUfM7WkmSLo2sq5MZjkWPF/oqdtte/fB25t1gqtQMS/8+om0THeBY5Oq7D+ZpaMdBGtpxkFb98ItaOe+HLou8XCePn8w0FeOczSs26bqO10uSorq01ur5aQmgStUqafgbI/Xq4EmK3bk/vfyR/Yd1WeTlKlGqhCSp/vUNtJdF+DLZsWFbpvvUZp1a6NcsfeHXH1erhfMaUjvysrS+cCgh37r1WjRQ7PZ9SjhwfsrGkX1HdFWWe1zOWZl9/8E8Des4WMM6DtbqH1aqpbNv5HX93rJik5o5+0bLDH0jNx+/+F/1btZT/Vr00qQBE7T5540kIFBomfymGRhj/pA0WGnTMdJXOLPWxuVaKQNfjYSQ0na/6Ppk2jabiz9boK+m/E9t7msvSVrw0feSpAfG9VKDlpE6nXxab8RM1s5N23OtK0nlgsrr0ddjVKlaJR3Zf0Sv9nlJScdOqGSZUuo9YUDaKvPGaMnnC/X1G7MzxVOpemUNe2e0z7boTC0EK589OK6XGrRsqDPOLQl3OI/HiPee0BvDpyjhUIKq1KiqgVOGqlxQee3askOTB01SypkUVawcpOfmTlDpcmVkHVanTiZraNsBBXao+YdrJ/o6hH9t2JjntXrdRh09mqjQkCD17dlVXTq193VY/9r9jYb4OoQceaI/XHxFTY2d9Zx2/75L1jlM75OXPtT6RWt92dR0pUygr0PI5ppWDXXfkz0UEBigJZ8t1NypsxR1X9pfgxd99IMkqevYh3SN81ry1rCp2uU8Vn1eG6wrmtVTueDySjxyTF9Omqklny1Q/2nDFH5pNVmH1ZF9h/X+qDcK3KiuwBwHbvtW/VaRusd5LJZ9tlBfT/1CrZzHYrHzWNw/9iFd3TJCZ5JP651hr2vXpu2q2/gKjfzfeO35fbesc5u1WS9+rE2L16nvtBiFOY9F3L7D+mDUjGx/Vfa1o/aMr0PI0cPjHlFky4bOLTpf0/ZN2yRJo957Uq8Pn6KEQ/GqWqOqhkwZlrZF55YdemXQy0o5k6K+L/RXsw7NdXjvIUlpO/cM7zRUknTX4Ht0/S03yJGaqh1bduj1xyYr5Uz2Rfp8paxLO9x7VoOohulbBy/5bIHmTJml1s6+sNDZF7qPe1j1W0bqTPJpvRkzJf0eN6e65/Sa0F/b1v2V/n9IadOYek3or2p1q8s473HnvVEwtkE/pYK5GHnPcY8owvnZT42ZrB3OvjHyvSc0ffhUJRyKV5UaVTV4Skx633ht0ESlnElRUOUgPT/3Zef126FTJ09pcNv+me5nr2p2tTr3uq1AbdH5+e6vCt5Fw42SRv2n4P8ilYOyz3xeII+LK0mIX6y11/7bN/BlEgKZFYYkRFFSmJMQ/qagJiGKooKYhCiqCmISoqgqqEmIoqogJCGQpqAmIYoif09CnBjZpVD+IlXuuVkF8ri4chZdZIx5SdIXktK3d7DW/uqxqAAAAAAAgN9xJQlxbhRE4wzPWUmt3R8OAAAAAADwV67sjhHljUAAAAAAAChwCvB2l4WRK7tjVDXGvG2M+db5+CpjTE/PhwYAAAAAAPxJvkkISe9J+l5SNefjvyQN8lA8AAAAAADAT+WahDDGnJuqUcla+5kkhyRZa1MklqIFAAAAAAD/TF5rQqyS1FBSkjEmVGmLUcoY00zSMS/EBgAAAACAb7EmhFvllYQ4t6foEElzJNU2xiyXVFnSnZ4ODAAAAAAA+Je8khCVjTFDnN9/KWme0hITpyW1lbTRw7EBAAAAAAA/klcSIlBSOZ0fEXFOGc+FAwAAAABAAWIdvo7Ar+SVhIi11o71WiQAAAAAAMCv5bVFZ9YREAAAAAAAAP9aXkmINl6LAgAAAAAA+L1cp2NYa+O9GQgAAAAAAAUOW3S6VV4jIQAAAAAAANyGJAQAAAAAAPAKkhAAAAAAAMAr8tqiEwAAAACAIs2yJoRbMRICAAAAAAB4BUkIAAAAAACKIGPMTcaYP40x24wxI3Ip08oYs94Ys8UY89OFvifTMQAAAAAAyI2fTscwxgRKmiopWtJeSauNMXOstb9lKBMk6XVJN1lr/zbGVLnQ92UkBAAAAAAARU9TSdustTustWckfSrp1ixl7pX0hbX2b0my1h660DclCQEAAAAAgJ8xxvQyxqzJ8NUrS5GLJO3J8Hiv87mMLpMUbIxZbIxZa4zpdqFxMR0DAAAAAAA/Y62dIWlGHkVMTtWyPC4mqZGkNpJKS1phjFlprf3r38ZFEgIAAAAAgNw4HL6OwFP2SqqR4XF1SftzKHPEWpskKckYs0RSA0n/OgnBdAwAAAAAAIqe1ZLqGmNqGWNKSLpb0pwsZb6SdIMxppgxpoykayX9fiFvykgIAAAAAACKGGttijGmv6TvJQVKesdau8UY09v5+nRr7e/GmO8kbZTkkPSWtXbzhbwvSQgAAAAAAHLjp1t0SpK1dp6keVmem57l8UuSXnLXezIdAwAAAAAAeAVJCAAAAAAA4BUkIQAAAAAAgFewJgQAAAAAALnx4zUhfIGREAAAAAAAwCtIQgAAAAAAAK8gCQEAAAAAALyCNSEAAAAAAMiFtawJ4U6MhAAAAAAAAF5BEgIAAAAAAHgF0zEAAAAAAMgNW3S6FSMhAAAAAACAV5CEAAAAAAAAXkESAgAAAAAAeAVrQgAAAAAAkBvWhHArRkIAAAAAAACvIAkBAAAAAAC8giQEAAAAAADwCtaEAAAAAAAgF5Y1IdzK40mIABlPvwVcVMYE+joEZHB/oyG+DgFOH66d6OsQ4FS62g2+DgFOt4c39nUIcCrOwNUCJcBwb1tQ1LPlfB0CgH+BqxoAAAAAAPAKpmMAAAAAAJAbpmO4FSMhAAAAAACAV5CEAAAAAAAAXkESAgAAAAAAeAVrQgAAAAAAkBuHrwPwL4yEAAAAAAAAXkESAgAAAAAAeAXTMQAAAAAAyIVli063YiQEAAAAAADwCpIQAAAAAADAK0hCAAAAAAAAr2BNCAAAAAAAcsOaEG7FSAgAAAAAAOAVJCEAAAAAAIBXkIQAAAAAAABewZoQAAAAAADkxuHrAPwLIyEAAAAAAIBXkIQAAAAAAABewXQMAAAAAAByYdmi060YCQEAAAAAALyCJAQAAAAAAPAKkhAAAAAAAMArWBMCAAAAAIDcsEWnWzESAgAAAAAAeAVJCAAAAAAA4BVMxwAAAAAAIBds0elejIQAAAAAAABeQRICAAAAAAB4BUkIAAAAAADgFawJAQAAAABAbtii060YCQEAAAAAALyCJAQAAAAAAPAKl5MQxpgWxpgezu8rG2NqeS4sAAAAAADgb1xaE8IYM0ZSY0mXS3pXUnFJH0q63nOhAQAAAADgW5Y1IdzK1ZEQt0vqLClJkqy1+yWV91RQAAAAAADA/7iahDhjrbWSrCQZY8p6LiQAAAAAAOCPXN2i8zNjzBuSgowxD0t6UNKbngsLAAAAAIACgOkYbuVSEsJaO8EYEy0pUWnrQjxprZ3v0cgAAAAAAIBfcXVhylqSlp5LPBhjShtjalprd3kyOAAAAAAA4D9cXRPic2UehJLqfA4AAAAAAMAlrq4JUcxae+bcA2vtGWNMCQ/FBAAAAABAgcAWne7l6kiIw8aYzuceGGNulXTEMyEBAAAAAAB/5OpIiN6SPjLGTJFkJO2R1M1jUQEAAAAAAL/j6u4Y2yU1M8aUk2Sstcc9GxYAAAAAAAUA0zHcytXdMUpK6iKppqRixhhJkrV2rMciAwAAAAAAfsXV6RhfSTomaa2k054Lx3OuaRmprmMeVEBggBZ/+qPmTvsyW5muT/VURFRDnU4+rRkxU7Rr845860Y/0FHtunVQamqq1i9cq0+f+68ubVBHPZ/rk1bAGH35ykyt+f4Xr7SzsKnXMkL3PNlDAYEBWjpzgb6dNjtbmXvGPKj6UZE6k3xG78RM0d9bdio4PFQ9Jw5QxcpBcjislnwyXwvenSdJqnFVTd3/TC8VL1lcjhSHPnriTe3csM3LLSucHnjqIUVGNdLp5NOaFvOadjr7QEaVa1TRwMkxKhdUTjs379CUwa8o9WyKqtW+SH0mDFCterX16YQP9fWMryRJoeGV1G/SQAU5j9WCj3/Qt+9+7e2m+a3Rz07UkuWrFBIcpNkfTvd1OEXOpIlj1eGm1jqZnKyePQdr3frN2crMeGOCGjVqIGOkrVt36sGeg5SUdNIH0fqHHk89rIbO89TUmFdzPE9VqVFFgyYPSz9PTR48SSnO81S/CY+qVr3a+mTCh5o7Y3Z6nanLZuhUUrIcqQ6lpjo0otNQL7aq8PPE9QOuqd8yQvc9mXaf+tPMBfomh3vc+8Y8qAZRDXUm+YzejJms3Vt2SpJ6vthXEa0bKzHumEa1H5xe/o4hd6thdFM5rEPHjxzTmzFTdPRQgtfa5C/qtLxGN43pqoDAAP366WItmzY30+uVaofr1gmPKLxeTS2c8Jl+npF2L1shPES3T+qjcpUryjqs1n68UL+8+70vmgB4hKsLU1a31t5lrX3RWvvyuS+PRuZGJiBA3cc9rBe7j9fwtgPVrPMNqla3eqYyDaIaKqxWuIa27Ke3R07XA+N75Vv3yuuuVqPoJhp502CNiB6keTPmSJL2/vm3nug0TKM6DtVL3cepx7O9FRDo6kdddJiAAN039iG98sAzeiJ6sJp2bqHwOpmPS/1WkapSK1yPtxqgDx6frvufSTsujpRUfTb+fT3RdpCevX2korrelF73zhFdNffVzzW24zB9NfFT3Tmyq9fbVhhFRDVSWK1wDWzZR2+OfF09x/fOsdx9I7pr3ttzNKhVXyUdO6HWd7WVJJ04ekLvjXlLc9+cnal8amqq/jv+XQ1pM0Cjbxuudt066KIs/Q//3m0dozV94nhfh1EkdbipterWqaUrrmqhPn0e09Qpz+VYbmjMU2rUOFoNG0Vrz9/71K9vDy9H6j8ioxopvFa4BrTsrTdGTtXD4/vkWO6+Ed319dtz9GirPjqR5Tz1zpg3s52nznnq7tEa1nEwCYh/yFPXD+TPBASo29iH9fIDz2hk9CA169xC1bLcS13TKu0ed3ir/nr38Wnq7ryXkqRl/1usCd3HZft/5834SqM7DNGTHWO0fuFa3TrwPx5vi78xAUYdxz2gj7q/qKlth+vqztepct2LMpVJPpqkb8d8oJ/f/CbT845Uh34Y/5Gmthmut24bo6bdorPVBQozV38z/tkYU9+jkXhQ7Yg6OrgrVof3HFTq2RStnLtMjaKbZirTKLqpls1aLEnavu4vla1QVkFVgvOs2/b+9pr7+pdKOZMiSUqMOyZJOnPqjBypaROHipcsLlnrpZYWLrUi6ujQ7gM6sueQUs+maNXc5Ypo1yRTmYh2TbTii8WSpB3rtqpM+TKqWDlIxw4f1d/OLP7ppFOK3b5PwWEhkiQrq9LlSkuSSlcoo6MH473XqEKsSXRTLXH2ga0Z+kBW9ZrX18p5P0uSfpq1SE3aXSsp7ed/+8ZtSj2bmqn80UMJ6X8RO5V0Svu27VVI1VAPtqRoaRxRXxUrlPd1GEVSp07t9d+P/idJ+mXVr6oYVFFhYVWylTt+/ET696VKl5LlmvCvNYluqp9mLZKU93nq6ubXaOW85ZKkn2YtVJN2zSSdP0+lnE3xXtBFgKeuH8jfpRF1dHD3gfT71F/mLlPDLPdSDds10fIvfpIkbV+3VWXKl1XFykGSpD9X/aakYyey/rc6dSI5/fuSZUpKnLb+sYsiait+10El7Dms1LOp2jx3pS6PbpSpTFJcovZv3CFHlp/9E4eOKnbzLknSmaRTOrxtv8pXzd6n4D3WUTi/CipXkxAtJK01xvxpjNlojNlkjNnoycDcKTgsVPGxcemP42Pj0n9hPV8mRHH7z+86Gn8gTsFVQ/KsG1armi5veqWemv28Rs0cp0uvqZNernZEXT0//xU99/0kvTvqjfSkBM4LrhqihAyfeUJs2meeUVDVUMXvP//5JxyIV1BY5l9gQ6tX1sVX1dSO9VslSTOffld3juyqF3+erv883k2zXvzIg63wH1n7QNyBOIVkOR7lg8vrZGJS+s9zfGycQrL0pbxUrl5Ftepdqm3r/3JP0IAPXVQtTHv37E9/vG9vrC6qFpZj2bfenKh9e9brisvraMrUd7wVot8JCQvNcp46ki2pmfU8FfcPzlOjP3xaL3z9stre0859QRcB3rh+IGfBVUMUn/H+NTZewVn6RHDVHO5xw/L/Y0CXmHs18ec3dN2tN+qLiZ+6L+giokJYiBIz/A6RGBuvCmH/PJEQVL2Swutdon3rt7szPMCnXE1CdJBUV1I7SZ0k3eL8N0fGmF7GmDXGmDVbT+y88CgvkMnpySwZ3XOLbWYqYm2edQOKBapsxXJ66rYR+uTZ99X/9fPDN7ev36oR0YP0ZOfh6tT3jrQREcgsl888nyKZRpaULFNKfafFaObY99Kz9q3ub6+Z497T8Oa9NXPce3rghb5uDdtf5dwHshXKv0wuSpYppSHTH9P7Y99Wcoa/sACFVW7XjZw89PAQ1bikoX7/Y6v+7z+dPR2a38rpM896EnKlTE5G3zFCj908RM90H6v23TrqyqZX/dswixxPXz+QO5fOQ/+yT8ya8LGGNH9EK75aorbdO/zbEJHBPx0JV6JMSf3f9EH6bux/dZp7J/gRl5IQ1trd1trdkpKV9iv4ua/cys+w1ja21jauW66WeyK9APEH4hQSfj7jGxIeqoQsQ/TjY+MUWq3S+TJhoTp6KCHPugmxcVrz3UpJ0o4N22QdVuVDKmT6f/dv26fTyadU/bKL3d6uwi7hQJyCM3zmweGh2RY9SjgQp5Bq5z//4LCQ9OkVgcUC1Wd6jFbOXqpfMyz8eV2Xlvr1u7THa75ZoVoN6gg5a9etg16YN0kvzJukhIPxmfpAaFioEg5l7ifH4xNVpkLZ9DVOcupLOQksFqih0x/Tstk/aZWzzwCFUZ/e3bVm9Q9as/oH7Y89oOo1qqW/dlH1cO2PPZhrXYfDoc8/n6M7br/ZG6H6jfbdOuqleZP00rxJis92nqqk+CznqcQs56nQ8FDFH8x/Qb1z57vEuGNa9f1K1Ym4zI2t8D/eun4gb/EH4hSS8f41PERHs3z2CQey3+P+k89+xVfL1PimZhcebBGTeCBeFTL8DlEhPETHDx51uX5AsUD93/RB2jR7uX7/bo0HIgR8x6UkhDGmszFmq6Sdkn6StEvStx6My612bNimsFrhqlyjigKLF1OzTi306/zVmcr8+uNqtejSSpJUO/IynTx+UkcPJeRZd80Pv+iq5mlLZYTVClex4sV0PD5RlWtUOX/zc1FlhV96kQ7vPeS9BhcSuzZsU9Wa4apUPe2zbdrpem3IclzWz1+j6+5oJUm6NLKuko+f1LHDRyVJ3V/oq9htezX/7cw7LRw7lKDLm9WTJF3RvL4O7Yr1eFsKqx8++FaPdRysxzoO1uofftGNzj5QN/IynTyelONK2L+t2KRmHZtLklp2idKa+avyfZ/eL/bXvm179c1bc9waP+Bt06a/r8ZN2qlxk3aaM+d7db3vTknStU0bKvFYog4cyH6ur127Zvr3t9wcrT//ZLeef+L7D+ZpWMfBGtZxsFb/sFItu0RJyvs8tWXFJjXreL0kqWWX1lo9P+8dqkqWLqlSZUunf9/gxkjt+XO3m1viX7x1/UDedma5l7q2Uwutm5/5F9Z181fr+jtaSpJqZ7mXyk3VmuHp30e2bazY7fvcHru/279hh0JrhSmoRmUFFg/U1Z2a6c/5a12uf+uLD+vItn1a8Vah+ZXLr/l6bQd/WxPCuDIsyBizQVJrST9aayONMVGS7rHW9sqnqu6/5I4CMdiuQVRD3X9u+6LPFmjOlFlqfV/anM+FH/0gSeo+7mFd0zJSZ5xbdO7ctD3XupIUWLyYer3UTxdfVUupZ1P08TPv6befN+v621uqU9/blXo2VdZaffnqZ1r7g+8vtKVMwduho36rSN3l3KJz+WcL9c3UL9TSeVx+ch6Xe8c+pKtbRuhM8mm9O+x17d60XXUaX6ER/xuvvb/vlsPZw7588WNtWrxOdRpfoXvG9FBAsUCdPX1WH41+U7tz2CrM147bgrcw2oPjeqlBy4Y649xibYezD4x47wm9MXyKEg4lqEqNqho4ZajKBZXXri07NHnQJKWcSVHFykF6bu4ElS5XRtZhdepksoa2HaCLr6ipsbOe0+7fd8k60k4Hn7z0odYvcv1C7Gkfrp3o6xD+tWFjntfqdRt19GiiQkOC1LdnV3Xp1N7XYf1rpavd4OsQ/pHXXn1G7du10snkZD300BCt/TVtuaS5X32gXr2H6cCBQ/pp0ZcqX6GcjDHauPE39es/MtNilQXV7eGNfR1CjnqOe0QRzmv11JjJ2rEpLakz8r0nNH34VCUcileVGlU1eEqMygWV184tO/TaoIlKOZOioMpBen7uy87zlEOnTp7S4Lb9VT64gobNGCkpbeTWsq+W6Ispn/uymZkE5Dw5tEDxxPWjoE7dK2UCfR1CJte0aqj7nPdSSz5bqLlTZynKeS+1yHkv1XXsQ7qmZaROJ5/WW8Omapfz+PR5bbCuaFZP5YLLK/HIMX05aaaWfLZA/acNU/il1WQdVkf2Hdb7o94okCNXatlSvg4hT3WjGuimJ7vKBAZo3Wc/aemUr9T4vjaSpDUfLVC5yhXVa+54lSxXWtbh0JmTpzW17XBVvaKGHpw1Rgd//zv93mnBSzO1ddEGXzYnT0/t/qjgn6guwKE2LQvE77T/VJUFPxXI4+JqEmKNtbaxMxkRaa11GGNWWWub5le3oCQhUDCTEEVZQUxCFFWFOQnhbwpbEsKfFdQkRFFUGJIQRUlBS0IUZQU9CVGUkIQomApqEqKYi+WOGmPKSVoi6SNjzCFJ/AYFAAAAAPBrBXlqQ2Hk6p/Gb1XaopSDJX0nabvy2B0DAAAAAAAgK5dGQlhrkzI8fN9DsQAAAAAAAD+WZxLCGHNcOW/FaSRZa22FHF4DAAAAAADIJs8khLW2vLcCAQAAAACgwLEFcn3HQsvVhSklScaYKpLSl6G11v7t9ogAAAAAAIBfcmlhSmNMZ2PMVkk7Jf0kaZekbz0YFwAAAAAA8DOujoQYJ6mZpB+ttZHGmChJ93guLAAAAAAAfI8tOt3L1S06z1pr4yQFGGMCrLWLJEV4LiwAAAAAAOBvXB0JcdQYU07SEkkfGWMOSUrxXFgAAAAAAMDfuDoS4lZJJyUNlvSdpO2SOnkqKAAAAAAA4H9cGglhrU1yfuswxnwjKc5aaz0XFgAAAAAAvmcdbNHpTnmOhDDGNDPGLDbGfGGMiTTGbJa0WdJBY8xN3gkRAAAAAAD4g/xGQkyR9LikipIWSupgrV1pjLlC0idKm5oBAAAAAACQr/zWhChmrf3BWvu5pAPW2pWSZK39w/OhAQAAAAAAf5LfSIiMO6ImZ3mNNSEAAAAAAH7NOvIvA9fll4RoYIxJlGQklXZ+L+fjUh6NDAAAAAAA+JU8kxDW2kBvBQIAAAAAAPybS1t0AgAAAABQFFnLFp3ulN/ClAAAAAAAAG5BEgIAAAAAAHgFSQgAAAAAAOAVrAkBAAAAAEAu2KLTvRgJAQAAAAAAvIIkBAAAAAAA8AqSEAAAAAAAwCtYEwIAAAAAgFxYh/F1CH6FkRAAAAAAAMArSEIAAAAAAACvYDoGAAAAAAC5sNbXEfgXRkIAAAAAAACvIAkBAAAAAAC8giQEAAAAAADwCtaEAAAAAAAgF2zR6V6MhAAAAAAAAF5BEgIAAAAAAHgF0zEAAAAAAMgF0zHci5EQAAAAAADAK0hCAAAAAAAAryAJAQAAAAAAvII1IQAAAAAAyIW1vo7AvzASAgAAAAAAeAVJCAAAAAAA4BUkIQAAAAAAgFewJgQAAAAAALmwDuPrEPwKIyEAAAAAAIBXeHwkRKAha1RQxDlO+zoEZFAhoISvQ4BT6Wo3+DoEOCXvX+rrEODUo1GMr0OAE3dSQM7W2KO+DgHAv8B0DAAAAAAAcmEt6WB3YjoGAAAAAADwCpIQAAAAAADAK0hCAAAAAAAAr2BNCAAAAAAAcmEdvo7AvzASAgAAAAAAeAVJCAAAAAAA4BVMxwAAAAAAIBcOtuh0K0ZCAAAAAAAAryAJAQAAAAAAvIIkBAAAAAAARZAx5iZjzJ/GmG3GmBF5lGtijEk1xtx5oe/JmhAAAAAAAOTC+umaEMaYQElTJUVL2itptTFmjrX2txzKvSDpe3e8LyMhAAAAAAAoeppK2mat3WGtPSPpU0m35lBugKRZkg65401JQgAAAAAAUPRcJGlPhsd7nc+lM8ZcJOl2SdPd9aYuJSGMMbWNMSWd37cyxjxqjAlyVxAAAAAAAMB9jDG9jDFrMnz1ylokh2o2y+NXJD1mrU11V1yurgkxS1JjY0wdSW9LmiPpY0kd3RUIAAAAAAAFjXUUzjUhrLUzJM3Io8heSTUyPK4uaX+WMo0lfWqMkaRKkjoaY1KstbP/bVyuJiEc1toUY8ztkl6x1k42xqz7t28KAAAAAAB8arWkusaYWpL2Sbpb0r0ZC1hra5373hjznqSvLyQBIbmehDhrjLlHUndJnZzPFb+QNwYAAAAAAL7hHGjQX2m7XgRKesdau8UY09v5utvWgcjI1SRED0m9JT1jrd3pzJR86ImAAAAAAAAoKGzWVRL8iLV2nqR5WZ7LMflgrX3AHe/pahIi2lr7aIY332mMSXZHAAAAAAAAoGhwdYvO7jk894Ab4wAAAAAAAH4uz5EQznUg7pVUyxgzJ8NL5SXFeTIwAAAAAADgX/KbjvGzpFilbcXxcobnj0va6KmgAAAAAAAoCArrFp0FVZ5JCGvtbkm7jTH3SdpvrT0lScaY0krbQ3SXxyMEAAAAAAB+wdU1IT6T5MjwOFXS5+4PBwAAAAAA+CtXd8coZq09c+6BtfaMMaaEh2ICAAAAAKBAcFimY7iTqyMhDhtjOp97YIy5VdIRz4QEAAAAAAD8kasjIXpL+sgYM0WSkbRHUjePRQUAAAAAAPyOS0kIa+12Sc2MMeUkGWvtcc+GBQAAAAAA/I1LSQhjzJNZHkuSrLVjPRATAAAAAAAFgmVNCLdydTpGUobvS0m6RdLv7g8HAAAAAAD4K1enY7yc8bExZoKkOR6JCAAAAAAA+CVXd8fIqoykS90ZCAAAAAAA8G+urgmxSZJ1PgyUVFkS60EAAAAAAPyatfmXgetcXRPilgzfp0g6aK1N8UA8AAAAAADAT+WZhDDGhDi/zbolZwVjjKy18Z4JCwAAAAAA+Jv8RkKsVdo0DCPpYkkJzu+DJP0tqZYngwMAAAAAwJccbNHpVnkuTGmtrWWtvVTS95I6WWsrWWtDlTY94wtvBAgAAAAAAPyDq7tjNLHWzjv3wFr7raSWngkJAAAAAAD4I1cXpjxijBkt6UOlTc+4X1Kcx6ICAAAAAAB+x9UkxD2Sxkj60vl4ifM5AAAAAAD8lmVNCLdyKQnh3AVjoDGmgiSHtfaEZ8MCAAAAAAD+xqU1IYwx9Y0x6yRtkrTFGLPWGHO1Z0MDAAAAAAD+xNWFKd+QNMRae4m19hJJQyXN8FxYAAAAAADA37i6JkRZa+2icw+stYuNMWU9FBMAAAAAAAWCtb6OwL+4moTYYYx5QtJ/nY/vl7TTMyEBAAAAAAB/5GoS4kFJT0v6wvl4iaQeHonIC+q3jNB9Tz6ogMAA/TRzgb6Z9mW2MveNeVANohrqTPIZvRkzWbu3pOVcer7YVxGtGysx7phGtR+cXv6ukd0U0baxUs+k6NDfB/TWsCk6mXjSa20qzHo+3UuNohrpdPJpTR76qnZs3p6tTJUaVTV0yjCVCyqvHZu369VBE5VyNkVNo6/VPTH3yTqsUlNT9c7Tb+n31b9Jkvq/9Kgat2miY3HHNDC6v7ebVeh4ol/cMeRuNYxuKod16PiRY3ozZoqOHkrwWpv81aSJY9XhptY6mZysnj0Ha936zdnKzHhjgho1aiBjpK1bd+rBnoOUlMQ5ydNGPztRS5avUkhwkGZ/ON3X4fiFa1pGquuYtHPT4k9/1Nwczk1dn+qpiKiGOp18WjNipmjX5h151r1z6D1qGN1E1mGVGHdMbwydrKOHEnR1iwa6a8T9Kla8mFLOpuiTZ9/Xbz9n719FVf0sn+fXuRyLBhmOxW7nscit7sVX1tQDzz6iUmVK6cjeQ3p94Cs6dSJZklTjikvU47neKl2utKzDakzn4Tp7+qz3GlxIeOL6fU6Hhzvr7lHd1S/yAZ1IOO7xtviLXk8/osZRjXU6+bReGTpJ23O4t61ao6qGT3lM5YPKadvm7Zo46GWlnE1Jf73uNXU14auX9WK/F7R83nJJ0q09b1O7e9pJ1mrXH7v1Sswk+gQKpXzXhDDGBEr63Fr7qLW2ofNrkLW2UP4mYQIC1G3sw3r5gWc0MnqQmnVuoWp1qmcqc02rhgqrFa7hrfrr3cenqfszvdJfW/a/xZrQfVy2/3fLsg0a1W6QRncYogM79+uWvnd4vC3+oGFUI1WrWU19b3xE00ZM1SPP9MmxXLeRD2juW1+pX8tHlHTshNrcFS1J2rh8gwa3f1RDOgzUlJjX1PeFAel1Fn6+QGO7PeWNZhR6nuoX82Z8pdEdhujJjjFav3Ctbh34H4+3xd91uKm16tappSuuaqE+fR7T1CnP5VhuaMxTatQ4Wg0bRWvP3/vUr2+hzRsXKrd1jNb0ieN9HYbfMAEB6j7uYb3YfbyGtx2oZp1vULW6mc9NDaLSzk1DW/bT2yOn64HxvfKt+80bs/X4TUM0quNQrVuwRrcP/D9J0vGERL384LMa2X6w3hgyWb0nDfRugwuwc5/nS93H67G2A3VdLseiaq1wxbTsp3dGTlePLMcip7o9X+irz57/rx5vP1hrvv9FNz9ymyQpIDBAvV8ZqPcef0Mjowfp2bueUMrZVK+2uTDw1PVbkkLCQ1XvhgY6svewR9vgbxpHNVa1mtXU68aHNWXEZPV9pl+O5R4Y2UNfvTVbvVr2UtKxE4q+q136awEBAXpgZA+t++nX9OdCq4aqU49OGnzzIPWL7qeAwADd2Kmlx9uDNA5rCuVXQZVvEsJamyrppDGmohfi8bhLI+ro4O4DOrznoFLPpuiXucvUsF2TTGUatmui5V/8JEnavm6rypQvq4qVgyRJf676TUnHsu9QunnpBjlSHc46fyk4LNSzDfETTds106JZCyVJf637U2UrlFVwleBs5eo3v0Y/O7PAi/63QNe2byZJOnXyVHqZUmVKZpqw9duqLTp+lKy9KzzVL879NUuSSpYpKTGf7oJ16tRe//3of5KkX1b9qopBFRUWViVbuePHzx+PUqVLyTKZ0SsaR9RXxQrlfR2G36gdUUcHd8Wmn5tWzl2mRtFNM5VpFN1Uy2YtlpR2/S1boayCqgTnWTc507npfP/YvWVn+mitvX/9reIlS6hYCVcHjfo3V45FwyzHokyFsqqYz7EIv7Sa/vglbQTj5qUb1KRD2vW9/o0R2vPHbv39+y5J0omjJ2QdDu80thDx1PVbku59oodmPveBLBfvf+Tads200Hlv+2ce97bXNL9Gy+YtkyQt+N8CXee8t5WkW3p00s/fLtfRuGOZ6gQWC1SJUiUUEBigkqVLKv5gnAdbAniOq7tjnJK0yRjztjHmtXNfngzMU4Krhih+/5H0x/Gx8QquGpqtTFzGMgfi/lFS4Yb/tNGmxesuPNgiIDQsVHGx5z/ruANxCsnyWZcPrqCkxBPpSZ4jsXEKzVDm2vbNNHnhNI16b4ymDHvVO4H7GU/2iy4x92riz2/oultv1BcTP3Vf0EXURdXCtHfP/vTH+/bG6qJqYTmWfevNidq3Z72uuLyOpkx9x1shAm4THBaq+NjzN9nxsXEKDgvJUiaHc1PVkHzr/mfYvXp1xQw1v+1Gzcrh3NSk43XavWWHUs6kZHutKHL1WMRnORYh+RyLvX/9rYbRab80N725uULCK0mSwmpVk7VWwz54QuO+mZA+QgKZeer6Hdm2sRIOxmvP77vdG3AREBoWqiOx50ePxB04kum+VZIqBFdQUmJShnvb82VCq4bquvbX6dsPv81UJ+5gnL6c8YXeXfme/rvmQ51MTNK6pfy+gcLJ1STEN5KeUNpaEGszfBU6xmQflpLtL4Q5lHF1SdRO/brIkZqqn2cv+TfhQdmPR86H43yZX75fqQGt++j5h57RPTH3ezo8v+TJfjFrwsca0vwRrfhqidp27/BvQ4STS8fK6aGHh6jGJQ31+x9b9X//6ezp0AC3y3EgabZTU859Ir+6n7/0sQZe10s/z16i6Cznpovq1tDdI7rqnZGs63FOTp9n9suE68fiXN03h01V224dNPbrl1S6bOn0OfGBxQJ1eZMrNW3gKxrX5XE1uulaXXV9/QtrhB/yxPW7RKkS6tS/C384+JdMDj/x2T7uPA7Jw0/10nvPvStHlpE/ZSuW07XRzdTz+gfVrUlXlSxTSq1uj3JT1IB35TvG0Bhzm6TKkjZZa7935T81xvSS1EuSmoVE6rLytS4kRreKPxCnkGqV0h+HhIfo6KH4TGUSDsQptFolbT1XJixUCQczl8nJ9V1aKaJNI71w71NujNj/dOjWUdH3tJckbdu4VaHh549HaA6fdWJ8ospWKKeAwAA5Uh2qFB6q+ByOx2+rtijs4nCVD66g4wmJnm2En/FkvzhnxVfLNOSdx/XlpJnuCLlI6dO7u3r2vE+StGbNelWvUS39tYuqh2t/7MFc6zocDn3++RwNHdJH73/wmcdjBdwp/kCcQsLP/wUxJDz7eSc+Nu3clF4mLFRHDyWoWIli+daVpJ+/WqqYd0fpC+e5KSQsVINmPKbpQ17Tob9z71tFTU7H4mgOxyIky7FIyOVYnKsbu32fXuw6VpIUVitcDVo3cv5fR/THyi3piyFuWPSral59qX5bvskzDSykPHH9rnJJmCpXr6px376cXn7s1y/p6dtG6Njho+5ugl+4udvNan/PTZKkrRv/UqXwyumvhYZVyjZtIu3etmyGe9vzZerUr6PhUx6TJFUIqaDGUY2VmpKqwOLFdHDPQSXGp93jrvjuZ13Z6Eot/nKRN5pY5NkCvL5CYZTnSAhjzOuSBksKlTTOuU1nvqy1M6y1ja21jQtSAkKSdm7Ypqo1w1WpehUFFi+mazu10Lr5azKVWTd/ta6/I22hl9qRdZV8/GS+J936LSN0c+/b9MpDz+vMqTOeCt8vfPvBPA3pMFBDOgzUL9+vVFSX1pKkyyIv18njJ5WQw+4Jm1dsVPOO10uSou5so1U//CJJCrskPL3MpVfXVrESxUhA/Aue6hdVa54/PpFtGyt2+z63x14UTJv+vho3aafGTdppzpzv1fW+OyVJ1zZtqMRjiTpw4FC2OrVr10z//pabo/Xnn9u8FS7gNjs2bFNYrXBVrpF2bmrWqYV+nb86U5lff1ytFl1aSZJqR16mk8dP6uihhDzrZjw3NYxukn5uKlOhjIa+O0qfvfihtq75wzuNLCT+7bE4ls+xqBCatuSYMUa3DviPFn6U9veujT+tV40ra6bPf7/i2qu0b+te7zW4kPDE9Xvvn39rQOMHFdOij2Ja9FH8gTg9ecswEhB5+OaDb/RohwF6tMMArfh+pVo7720vj7xcJ48n5Xhvu2nFJrXo2EKS1ObONlrpvLd9qEVP9bz+QfW8/kEtn7dc00a/rpU/rNThfYd1ecPLVbJUSUlSg+sbaM+2PV5qIeBe+Y2EuFFSA2ttqjGmjKSlknJeQreQcKQ69N8n39KwD55QQGCAlny2UPu27lHUfWkr0i766AdtWPSrrolqqJd+mqrTyaf11rCp6fX7vDZYVzSrp3LB5TVpxQx9OWmmlny2QF2ffkjFShTXsA+flJS2INP7o2b4pI2FydqFa9QoqrGmLZ2RtkVnzPk1HUa/N0ZTH5ushIPx+uC59zR0ynDdO+x+7dyyQz/O/EGSdF3H5mrVpbVSz6bozKkzernfi+n1h0yOUb3r6qtCcAW9+cu7+nTix1owc77X21gYeKpf/Oex+xV+aTVZh9WRfYf1/qg3fNVEvzHv2wW66abW+vP35TqZnKyHHhqS/trcrz5Qr97DdODAIb379isqX6GcjDHauPE39es/0odRFx3Dxjyv1es26ujRRLW57X717dlVXTq193VYhZYj1aH3n3xLwz94Mm37wc8WaN/WPWrtPDct/OgHrV+4Vg2iGurlJa/rjHNbyLzqStJdI+5X+KUXyTocOrLvsN59PO3cFN29o6rWDNNtA/6j2wak7ebzQtexSsyyOFxR5Eh16IMn39Iw5+e5JIdjsWHhWkVENdQE57F4M8OxyKmuJDXr3EJtu6VNh1nz3Uot+SxtQb+TiUn69q05enrui5KVNixaqw0LC+VMYI/y1PUb/96ahavVOKqx3lz6VtoWnTGT0l976r2n9Npjryn+YLzefe5dPTZluO4f1lU7tuzQDzPzHnD+1/o/tXzecr0y71U5UlO1fcsOfffxt3nWAQoqk9eK6caYX621DXN77IruNbuwpG4BkehghEZBUiGghK9DgNNH+1f6OgQ4Je9f6usQ4NSjUYyvQ4ATg4ALloCc1liAT8Q5TuVfCF7x9d/f+HXH+KXaHYXyd9pr939RII9LfiMhrjDGbHR+byTVdj42kqy19hqPRgcAAAAAAPxGfkmIhpKS8ykDAAAAAACQr/ySEB9baxsaY/5rre3qlYgAAAAAAIBfyi8JUcIY011Sc2PMHVlftNZ+4ZmwAAAAAADwvUK5IEQBll8Sorek+yQFSeqU5TUriSQEAAAAAABwSZ5JCGvtMknLjDFrrLVveykmAAAAAADgh/IbCSFjTBVJlxhj/qe00Q+/SZpqrT3k6eAAAAAAAID/CMjrRWPM9ZJWKy358IGkD50vrXK+BgAAAACA33JYUyi/Cqr8RkK8LOk2a+26DM99ZYz5UtIbkq71WGQAAAAAAMCv5DkSQlKFLAkISZK1dr2k8h6JCAAAAAAA+KX8RkIYY0ywtTYhy5Mhyj+BAQAAAABAoWYL8NSGwii/RMIkST8YY1oaY8o7v1pJ+tb5GgAAAAAAgEvy26JzhjFmv6Rxkuo5n94iaby1dq6ngwMAAAAAAP4j3y06rbVfS/raC7EAAAAAAAA/lm8SQpKMMbUkDZBUM2Mda21nz4QFAAAAAIDvOXwdgJ9xKQkhabaktyXNFccAAAAAAAD8C64mIU5Za1/zaCQAAAAAAMCvuZqEeNUYM0bSD5JOn3vSWvurR6ICAAAAAKAAsGKLTndyNQlRX1JXSa11fjqGdT4GAAAAAADIl6tJiNslXWqtPePJYAAAAAAAgP8KcLHcBklBHowDAAAAAAD4OVdHQlSV9IcxZrUyrwnBFp0AAAAAAL/lsL6OwL+4moQY49EoAAAAAACA33MpCWGt/cnTgQAAAAAAAP/mUhLCGHNcabthSFIJScUlJVlrK3gqMAAAAAAA4F9cHQlRPuNjY8xtkpp6IiAAAAAAAAoKh4yvQ/Arru6OkYm1drak1u4NBQAAAAAA+DNXp2PckeFhgKTGOj89AwAAAAAAIF+u7o7RKcP3KZJ2SbrV7dEAAAAAAFCAWKZjuJWra0L08HQgAAAAAADAv+WZhDDGPJnHy9ZaO87N8QAAAAAAAD+V30iIpByeKyupp6RQSSQhAAAAAACAS/JMQlhrXz73vTGmvKSBknpI+lTSy7nVAwAAAADAHzh8HYCfyXdNCGNMiKQhku6T9L6khtbaBE8HBgAAAAAA/Et+a0K8JOkOSTMk1bfWnvBKVAAAAAAAwO/kNxJiqKTTkkZLGmVM+tYkRmkLU1bwYGwAAAAAAPgUW3S6V35rQgR4KxAAAAAAAODfSDIAAAAAAACvIAkBAAAAAAC8It/dMQAAAAAAKKrYotO9GAkBAAAAAAC8giQEAAAAAADwCpIQAAAAAADAK1gTAgAAAACAXLAmhHsxEgIAAAAAAHgFSQgAAAAAAOAVTMcAAAAAACAXVsbXIfgVjychzthUT78FXFTCBPo6BGQQyMmswLg9vLGvQ4BTj0Yxvg4BTu+uneDrEOB0f6Mhvg4BGVlfB4Bzypvivg4BwL/AdAwAAAAAAOAVJCEAAAAAAIBXsCYEAAAAAAC5cDCL2q0YCQEAAAAAALyCJAQAAAAAAPAKpmMAAAAAAJALB7vauRUjIQAAAAAAgFeQhAAAAAAAAF5BEgIAAAAAAHgFa0IAAAAAAJAL6+sA/AwjIQAAAAAAgFeQhAAAAAAAAF5BEgIAAAAAAHgFa0IAAAAAAJALh68D8DOMhAAAAAAAAF5BEgIAAAAAAHgF0zEAAAAAAMiFwxhfh+BXGAkBAAAAAAC8giQEAAAAAADwCpIQAAAAAADAK1gTAgAAAACAXFhfB+BnGAkBAAAAAAC8giQEAAAAAADwCpIQAAAAAADAK1gTAgAAAACAXDh8HYCfYSQEAAAAAADwCpIQAAAAAADAK/KcjmGMuSOv1621X7g3HAAAAAAACg6H8XUE/iW/NSE6Of+tIqm5pIXOx1GSFksiCQEAAAAAAFySZxLCWttDkowxX0u6ylob63wcLmmq58MDAAAAAAD+wtU1IWqeS0A4HZR0mQfiAQAAAAAAfsrVLToXG2O+l/SJJCvpbkmLPBYVAAAAAAAFgEMsCuFOLiUhrLX9jTG3S7rR+dQMa+2XngsLAAAAAAD4m3yTEMaYAEkbrbVXSyLxAAAAAAAA/pV8kxDWWocxZoMx5mJr7d/eCAoAAAAAgILA+joAP+PqmhDhkrYYY1ZJSjr3pLW2s0eiAgAAAAAAfsfVJMTTHo0CAAAAAAD4PVcXpvzJ04EAAAAAAAD/5lISwhjTTNJkSVdKKiEpUFKStbaCB2MDAAAAAMCnHOzQ6VYBLpabIukeSVsllZb0kPM5AAAAAAAAl7i6JoSstduMMYHW2lRJ7xpjfvZgXAAAAAAAwM+4moQ4aYwpIWm9MeZFSbGSynouLAAAAAAA4G9cnY7R1Vm2v9K26KwhqYunggIAAAAAoCBwFNKvgirPkRDGmMqSKltrf3M+dUrS08aYqyUd83RwAAAAAADAf+Q3EmKypMo5PH+RpFfdHw4AAAAAAPBX+SUh6ltrf8r6pLX2e0nXeCYkAAAAAAAKBltIvwqq/BamLP4vXyuQuj/1kCKiGulM8mlNi3lNuzbvyFamco0qenRyjMoGldOuzTs0dfArSj2bkmf915bNUHJSshypDjlSUzWqU4wkqcugu9X6nmglxiVKkma+9KHWL1rrpdYWHg889ZAioxrptPNz3ZnLcRk4OUblgspp5+YdmuI8LtVqX6Q+EwaoVr3a+nTCh/p6xleSpNDwSuo3aaCCKgfJ4bBa8PEP+vbdr73dtELl6pYRuvfJHjKBAVo6c4HmTZudrcy9Yx5U/ahInUk+o7djpujvLTsVHB6qhyYOUMXKQbIOq58+ma8f350nSbp9yN2KiG4iax1KPJKod2Km6OihBC+3rPDq8dTDaujsG1NjXs2xb1SpUUWDJg9L7xuTB09SirNv9JvwqGrVq61PJnyouTNmp9eZumyGTjnPWampDo3oNNSLrSocrmkZqa5jHlRAYIAWf/qj5k77MluZrk/1VMT/t3ff4VFUbR/Hv3dC7yS0oCio2JWOgCgdJQoW9LWDWECx0FFsYC+Poo+gIvbeHmwoFpSm0hWlWOhILwm9JznvHzMJm75AdrNZfh+uXOzOntm9Z87OnNl7zpxp05C9u/cyeuDIjDYht3kvG3AVDTs0waU5tiVt5eUBI9iyYTOnt6zHFXdfS7HixUjZn8IHj73Fn1Pnh3V5o9F9jw1nyi8ziatcic/fHVXY4UQltd+F63DWf17zd+pxIe2u6gBmTPhgPONeHwvAsafU5qbHbqFUmdJsXLWBEX2Gs3vH7vAtcIQLxe+MhONqcufIQRnzVzumOv8b/gHfvD6WsxJbcFm/K6l5wtHc32UQS+ctCduyihyu/HpCLDKzxKwTzawTkH3LimD12zSiRp0E+rW6lVeGvMiNj9ySY7mr7+7OuNe+pH/r3uzcuoM2V7QPav5HrryPIYn9MhIQ6ca99iVDEvsxJLGfEhA5SF+vffKpl2v8eunr10tbv152bNnBm0NfZewrn2cqn5qayjuPvEH/dndw38WD6ditE0fVPTrUi1NkWUwM1z50E89e/yj3dejHWV1aUvOEzOvrjNYNqF4ngSGt7+Cte0bR7dGeAKSlpPLRI29xX/u+PHrJENped37GvN+M/oKhnQYwLHEQcyf8Suc+l4d92YqqBm0akVAngTta3cLLQ17g5kduzbHcNXd356vXvuTO1reyI8u28frQV7JtG+mGXXkfgxL7KQGRA4uJofvDN/NU90cY3L4PzbqcQ80s+496bRpSo04CA1rdxmtDRnH9Iz3znffrlz/nnvP7c2/iAOb8OJtL+vwfANs3b+OZGx5jyHn9eLn/CG55tk94FzhKXZzYgVHDHynsMKKW2u/CdbjrP7f5a514DO2u6sA9XQYx+Py+NGzXmBq1EwDo9eRtvP/EOww6rw8zv5tO516XhGdhi4BQ/c5Yu3RNxu+Iey4cwL7de5n13XQAVi78l+G9nuDvGX/m+FkikSy/JEQ/4Dkze9PM7vD/3sIbD6JIHSU16tCUn8ZMAmDxnIWUqVCWStUqZyt3WoszmDFuKgBTxkykccezDmp+OThNOjRlir9eF81ZSNk86mW6Xy+Tx0ykiV8v25K2smTuYlL3p2Yqv2XD5oyM/p6de1i9eBVx1eNDuCRF23H1T2DDinVsXLmB1P0pzBj7C/U7NslUpkHHJkz9dBIAS+csokz5MlSsWomtG7fw74JlgLeu1y5ZTaUacd7zgDMkJcqUBBfJHcMiS5MOTZk8ZiKQ97ZxeoszmT7uFwAmj5lAk47NgAPbRop/hkWCd3z9E1i/fC0bV64ndX8K08f+TKMOTTOVadShKT/7+64lAfWT17yBZwxLlimF87eHFQuWZfQQWrXwX4qXLEGxEsHeQVty07j+GVSsUL6ww4haar8L1+Gu/9zmP+qEo1k0ZyH79uwjLTWNP2csoOl5XruScNxR/DVjAQDzfvqDszo1D/FSFh3h+J1x+tlnsv7fdWxavRGANYtXsXbpmhAtkUho5ZmEcM4tBM4AJgO1/b/JwJn+a0VGXI04ktZsynievC6JuOpxmcqUr1yendt2kpbq3dAkaW0Scf6PqbzmdziGvDuMR796hrZXdcz0nud1u4Anv32OXv+5nbIVyoZk2YqyylnWa1Iu9bIroF6SA+olGFWPrkad045j8e9F6isbVpWqx5EcUA+b1yZROUs9VK4eT/KapIznyeuSqVwj84Fh/NFVOebU2iz9fVHGtEsHXsXTU0fR7KJz+Hz4RyFagugTVyM+y7axKduBeNZtI+kgto373n2QJ796hvZZ9lkClWvEk7w24Lu+NonKWdZr1n1X8jpvm8lv3ssHXc1/p42mxcXnMmb4h9k+u0lic1YsWErKPiWPJLKp/S5ch7v+c5t/5cJ/ObnpqZSrVJ4SpUrQoE1D4mtWAbwz7439pGqzC1oQn1AlpMtYlITyd0a6Fl1aMvXLn0K1CJKPNCuaf8Ews/PN7B8zW2xmd+fw+jVmNtf/m2pm9Q53febXEwIgBbjGOTfA/3vdObcnrxnMrKeZzTaz2Yt3LD/cGAuEWfZayHZSNo8yec0/7NK7ueeCATzZ/SE6duvEyU1PBeCHd7+hz7m3cHenfmzesJlr7+9xWMsQjQ63XvJTskwp+o+6i7ceek3XLeYh53rIspJz2JEFlilZphS3vTSQDx56M1MPiE+f/oCBLW5h+hc/0bb7+QUWc7TLqU6yfvGDKZOT+y69m7su6M+j3R/ivG6JnOLvs8STY5uddXPIZZvJb95P/vM+fZr3ZOrnU+jQvVOmYkfVrcWVd1/H60M0foFEPrXfhStUx7WrF6/iy1Gfcd97w7jn7aGs+HM5qSleb5VRg0bQsVsij3/1DKXLliZl//7DXo5oEcrfGQCxxYvRqH1TZnz9y+GEKZKNmcUCLwCdgFOBq8ws64HhMqCVc+5M4GFg9OF+br79PZ1zqWa2y8wqOue2BvOmzrnR6cFddezFhdb/ukO3TrS90jvLt3TuooxMLnhnGTdvSM5UfnvyNspWKEtMbAxpqWnEJ8Szeb1XJmltUq7zb/a70W5L2sqs72ZwfP26/D3zT7ZuOrC6JnwwnsGv3xuaBS1iOnbrRDu/XpZkqZf4XOqlTEC9xAXUS15ii8UyYNRd/Pz5ZGZ+O71gFyLKbF6XRFxAPVROiM82gKRX5sCZ+LgacWzx6yG2WCy3jRrI9M9/4rfvZuT4GTO++Ik+r9/DF89+HIIliA7ndUuk/ZUdAFg8d3GWbaMKyVm2jW1Zto34hHiS1+c/8Gf6NrYtaSszv5vOCfVP5K+ZuqY0XfK6JOISAr7rOexzknNoE7Zs2EyxEsXynRdg6hc/MfCNe/n02Y8y5u87+i5G9X+eDf+uL+hFEikQar8LV0Gu/6z7sMD5J370AxM/+gGAKwddS/I6r3fXmiWreey6YQAk1KlJg7aNQrOgRUS4fmcA1G/dkGXzl2b6bSFSQJoCi51zSwHM7EPgIiDjwNA5NzWg/HTgsAfqCaYnBMAeYJ6ZvWZmz6f/He6Hh9r4t7/JGMxl9vczOKdrawBOaHAiu7bvzHGU/gXT5nFWYgsAzu3ahl/HzwTgtx9m5jh/ydIlKVW2FAAlS5fkzHPrs+qffwEyXcvV5LyzWOlPP9J9//Y33JXYj7sS+zHr+xmc66/XunnUy5/T5tHMr5dWXdsw26+XvNzy1O2sXryKr1/9skDjj0bL/lhM9doJVDm6GrHFi3FW57P5ffysTGV+Hz+bFpe2BuC4BnXZtX0XWzduAaDHk71Zu3gV37+WeQTzarVrZDyu374J65asDulyFHXfvT2OQYn9GJTYj1nfT6dV1zZA3tvGgmnzaJZ4NgCturZl1vick0DpvH1W6YzH9c5twMp/VhTwkhRtS/9YTI06CVSt5W0PzTq35Lcs28NvP8yipb/vOr7BiezavostGzbnOW91f3A3gIYdmrDW3x7KVCjDgDfu5eOn3mXR7L/Ds5Aih0Dtd+EqyPU/+4eZuc5fIb4iAPE1q9D0/Gb88sWUTNPNjEvvuJzx730XsmUtCsLxOyNdiy7nMPXLKaFdIMlTWhH9C8JRwMqA56v8abm5EfgmuLfOnWXrcp1TIbPuOU13zr2V37yF2RMiqx4P96ReK+92ai8PfD7jVjaD37yfVwaPZPOGzVSrVZ07Rg6gXKXyLF+wlBf6PptxbW5O81erVZ3+o71LZ2KLxfLLF1P4fOT/AOj9bF+OPbUOOMfGVRt49Z6XCvX2hEF+EcPuBn+9pt+SKL1e7n7zfl4OqJc+AfUywq+XilUr8fjYpyldrgwuzbFn124GtL+DY06uzUNjHmfFX8txad5X8IMIu0VqWYusgefOaN2Aqx7oQUxsDD9/PIGvXviU1td4Gf5J730PwLUP3cTpreqzb/deXh/0IsvnLaFu45MZ8r9HWPnXCpzzvmVjnnqfeZPm0PulgdQ4riYuzZG0eiNv3zs6o/dEJNnuIrNL6Y0P96J+qwbs272XFwaOYOm8xQAMefN+Rg1+gc0bkqlWqzr9Rg6kXKXyLFuwlOf7DidlXwqVqlbiibHP+NtGGnt27aFf+9spX7kCg0YPAbx91s9fTOHTkZ8U5mJmUpLYwg4B8O5+ce0D3m02J3/8I1+OHENbf3uY4G8P3R++mTP9+hk9cCTL/H1XTvMC3DlqEAnHHYVLS2PT6o28cc/LbF6fzEV3XEbn3peyftnajM9/8rqH2JZUuGe83vj16UL9/MM1aOgTzJozly1bthEfV4neN15H187nFXZYh+TaRv0LO4QcHantd6Q4nPWf1/zDPnmM8pXLk7o/hbcfeYP5v8wFvFt3duzmXUY289vpfPDkO4Ww1JkFezY1HELxOwOgRKkSjJz+Kn3OuYXd23dlfF7j887i+gdvpkJcRXZt28nyP5fxRLcHw7/gvg9WfB7kCARF0ytHXxsxv2kPRs/V7/UCegZMGu1ftQCAmV0OnOecu8l/fh3Q1Dl3R9b3MrM2wItAS+dcUtbXD0aeSQgzqwpUdc79mWX66cB659zG/D4gkpIQR7pITUIcqSItCXEki9QkxJEoUpIQUvSTENEkUpMQIoUtkpIQRzolISLTzavezbNezKw5MMw5d57/fAiAc+7xLOXOBD4DOhXEDSry23ZHAFVzmH4U3m06RURERERERKTomQXUNbM6ZlYCuBLIdC2cmR0DfApcV1B3yMzvVOwZzrnJWSc6574zs2cKIgARERERERGRSBWtPcqdcylmdjvwHRALvO6cW2Bmt/ivjwIeAOKBF/07uaQ45xofzufml4QofoiviYiIiIiIiEgEc86NA8ZlmTYq4PFNwE0F+Zn5XY6xyMwSs040s07A0oIMRERERERERESiW349IfoBX5nZ/wHpwxI3BpoDF4YyMBERERERERGJLnkmIZxzC83sDOBq4HR/8mSgl3NuT6iDExERERERESlMLqrv/RF++d4j0Dm318w+Bt52zqWa2YlARzP7xjnd105EREREREREghPs7XWnACXN7CjgR6AH8GaoghIRERERERGR6JNvTwifOed2mdmNwAjn3FNmNieUgYmIiIiIiIgUtmi9RWdhCbYnhJlZc+Aa4Gt/WrAJDBERERERERGRoJMQfYAhwGfOuQVmdhwwMXRhiYiIiIiIiEi0Cao3g3NuCt64EOnPlwJ3hiooEREREREREYk+QSUhzKwqMBg4DSiVPt051zZEcYmIiIiIiIgUOo0JUbCCvRzjPeBvoA7wILAcmBWimEREREREREQkCgWbhIh3zr0G7HfOTXbO3QA0C2FcIiIiIiIiIhJlgr3DxX7//7VmdgGwBjg6NCGJiIiIiIiIRAZX2AFEmWCTEI+YWUVgADACqAD0C1lUIiIiIiIiIhJ1gr07xlf+w61Am9CFIyIiIiIiIiLRKs8khJmNII/eJ8453aZTRERERERERIKSX0+I2QGPHwSGhjAWERERERERkYiSZoUdQXTJMwnhnHsr/bGZ9Q18LiIiIiIiIiJyMIK9RSdoUFAREREREREROQwHk4QQERERERERETlk+Q1MuZ0DPSDKmNm29JcA55yrEMrgRERERERERApTWmEHEGXyGxOifLgCEREREREREZHopssxRERERERERCQs8rtFp4iIiIiIiMgRS5djFCz1hBARERERERGRsFASQkRERERERETCQkkIEREREREREQkLjQkhIiIiIiIikgtX2AFEGfWEEBEREREREZGwUBJCRERERERERMJCSQgRERERERERCQuNCSEiIiIiIiKSizQr7Aiii3pCiIiIiIiIiEhYKAkhIiIiIiIiImGhyzFEREREREREcpFW2AFEGfWEEBEREREREZGwUBJCRERERERERMJCSQgRERERERERCQuNCSEiIiIiIiKSC1fYAUQZ9YQQERERERERkbBQEkJEREREREREwkKXY4iIiIiIiIjkIk0XZBQo9YQQERERERERkbBQEkJEREREREREwiLkl2OUNl3xESmqULywQ5AAi93Owg5BfMWVj40YVtgBSIZrG/Uv7BDE9+6vwws7BAmgbSNyzNuzrrBDEJFDoAyBiIiIiIiISC7SCjuAKKPTfyIiIiIiIiISFkpCiIiIiIiIiEhYKAkhIiIiIiIiImGhMSFEREREREREcuEKO4Aoo54QIiIiIiIiIhIWSkKIiIiIiIiISFjocgwRERERERGRXOgWnQVLPSFEREREREREJCyUhBARERERERGRsFASQkRERERERETCQmNCiIiIiIiIiOQizQo7guiinhAiIiIiIiIiEhb5JiHMLMbM5ocjGBERERERERGJXvlejuGcSzOzP8zsGOfcv+EISkRERERERCQSpOEKO4SoEuyYEAnAAjObCexMn+ic6xKSqEREREREREQk6gSbhHgwpFGIiIiIiIiISNQLKgnhnJtsZscCdZ1zP5hZGSA2tKGJiIiIiIiISDQJ6u4YZnYz8D/gZX/SUcDnIYpJREREREREJCK4IvoXqYK9RedtwNnANgDn3CKgWqiCEhEREREREZHoE2wSYq9zbl/6EzMrRmQnV0REREREREQkwgSbhJhsZvcApc2sA/AJMDZ0YYmIiIiIiIhItAn27hh3AzcC84BewDjg1VAFJSIiIiIiIhIJ0go7gCgT7N0x0szsLWAG3mUY/zjndDmGiIiIiIiIiAQtqCSEmV0AjAKWAAbUMbNezrlvQhmciIiIiIiIiESPYC/HeAZo45xbDGBmxwNfA0pCiIiIiIiISNRK0z0ZClSwA1NuSE9A+JYCG0IQj4iIiIiIiIhEqTx7QpjZpf7DBWY2DvgYb0yIy4FZIY5NRERERERERKJIfpdjdA54vB5o5T/eCFQOSUQiIiIiIiIiEpXyTEI453qEKxARERERERGRSKMRIQpWsHfHqAPcAdQOnMc51yU0YYmIiIiIiIhItAn27hifA68BY4G0kEUjIiIiIiIiIlEr2CTEHufc8yGNRERERERERCTC6Cx8wQo2CfFfMxsKfA/sTZ/onPstJFGJiIiIiIiISNQJNglxBnAd0JYDiSDnPxcRERERERERyVewSYhLgOOcc/tCGYyIiIiIiIiIRK9gkxB/AJWADaELRURERERERCSypOkmnQUq2CREdeBvM5tF5jEhdItOEREREREREQlKsEmIoSGNQkRERERERESiXlBJCOfcZDM7FqjrnPvBzMoAsaENTURERERERESiSUwwhczsZuB/wMv+pKOAz0MUk4iIiIiIiEhEcEX0L1IFlYQAbgPOBrYBOOcWAdVCFZSIiIiIiIiIRJ9gkxB7A2/PaWbFiOzkioiIiIiIiIhEmGAHppxsZvcApc2sA9AbGBu6sEREREREREQKX1phBxBlgu0JcTewEZgH9ALGAfeFKigRERERERERiT7B3h0jDXjF/xMREREREREROWh5JiHMbG5erzvnzizYcMLj9Fb1ufqBHlhsDD999CPjXvo8W5mrh97AGW0asG/3Pl4bOJJ/FyyjckI8Nw2/g4pVK+HSHJM/GM8Pb4zLmKdd906063Y+qalpzJ3wK5888W4Yl6poOrFVPS56oBsWG8PMjyYy6aUvs5XpMrQ7J7epz/7d+/h44EusXrAcgHNu7ESTK9qCc6z7ZyUfDxpFyt79dOjblaZXtmVn8jYAvn3qI/6e9HsYl6rounHYzTRs05i9u/cycuBzLJ2/NFuZarWq03/EQMpVKs+y+Uv4b79nSdmfwrkXt+LiW7oCsGfXbkbf+xLL/1oOwIU3dqH9lR3BOVb8vYKRg/7L/r37w7loRd71w26iQZtG7N29l5cGPs+yHOqmaq1q9BkxkHKVyrFs/lJG9nuO1P0p1Dz+KG59+g7qnHY8Hz79Ll+N/qIQlqBoOaNVA64begMxsTFM+vAHvnrps2xlrht2I/XaNGTv7r2MHjiSFX6d5DbvMafU5vrHelGqTCk2rdrAi32eY8+O3QDUOvlYejx+C6XLlcalOYZ2GaxtJBeh2BbiE6pw27N9qFS1Emlpjh/f/55v3vgq3IsWte57bDhTfplJXOVKfP7uqMIOJyqFqo245T+307BtY7YlbWVgxz7hXKSoMeTR/pzTrjl7du/l3jsf5q95/2Qrc9UNl3Fdzys4pk4tWp5yHluSt2a81qRFQ+56uC/FihVjc/IWelzSO5zhi4REfpdjpAGpwDvA/wGds/wVORYTw7UP3cSz1z/KfR36cVaXltQ84ehMZc5o3YDqdRIY0voO3rpnFN0e7QlAWkoqHz3yFve178ujlwyh7XXnZ8x7cvPTaNChCQ90GsD9Hfvx7SvZf0xLZhZjXPJQD167/kme6TCQ+l1aUO2EozKVObl1farUqcFTrfsx5p5XuOTRGwGoUL0yZ19/Ps93vofh5w3GYmKo17l5xnw/vTaO5xKH8FziECUggtSwTSMS6tTktla9GDXkBXo+cmuO5a67uztjX/uS21vfwo6tO2h3RQcA1q9cz/3/N4T+59/JJ89/xC2P3wZAXPU4LujRmcEX9qdvxzuIiY2hZedzwrZc0aB+m0bUqJNAn1a38sqQF7nxkVtyLHfN3d0Z99qX9G3dm51bd9D2ivYA7NiygzeHvsrYVz4PY9RFl8XE0P3hm/lP90e4q30fmnc5h5p1M7cT9do0pHqdBAa2uo3Xh4yixyM98533xid78/ET73DPef2Y/d0MLuh1MQAxsTHc8lwf3rznZYZ06MtjV9xPyv7UsC5zURGqbSE1NZV3HnmD/u3u4L6LB9OxWyeOylLncuguTuzAqOGPFHYYUSuUbcTkTybwePeHQhl+VDunXXOOqVOLxGaXM2zg49z/1OAcy82ZOZebLr+T1f+uzTS9fIVy3PfEIG7vNoiLW13NgJvvDUfYkgNXRP9FqjyTEM65+sBVQDngfeBR4DRgtXNuRcijC4Hj6p/AhhXr2LhyA6n7U5gx9hfqd2ySqUyDjk2Y+ukkAJbOWUSZ8mWoWLUSWzdu4d8FywDYs3MPa5esplKNOADaXHMe4176jJR9KQBsT9oWvoUqomrVP4FNK9aRvHIDqftT+WPsNE7r2DhTmVM7NuK3T38C4N85iyldvgzlq1YCICY2luKlShATG0OJ0iXYtn5zuBchqjTtcBaTxkwEYOGcfyhboSyVq1XOVu6MFmcybdwvAEwcM4GmHc8C4J9f/2bntp3e/L/9Q3xClYx5YmNjKOHXVcnSJUlenxzqxYkqTTo0ZcqYSQAsmrOQshXKUimHujmtxRlMHzcVgMljJtLEr5ttSVtZMncxqfphG5Tj65/A+uVr2bhyPan7U5g+9mcadWiaqUzDDk352a+TJXMWUqZCWSpWq5znvAnH1eTvGX8CMP+nP2jSqRkAZ5xbn5V/r+Bfv+fQji07cGkaAisnodoWtmzYnHHmeM/OPaxevIq46vEhXJIjS+P6Z1CxQvnCDiNqhbKN+Gvmn+zYsiN0wUe5Nuefy5efeL2m5/66gPIVylGlWvZ9y9/zF7Jm5dps0xMvPY8fxk1i3er1ACRv0rGuRId8B6Z0zv3tnBvqnGuId0eMt4F+IY8sRCpVjyN5zaaM55vXJlG5elymMpWrx5O8JinjefK6ZCrXyLzDiD+6KsecWpulvy8CoPpxCdRtegr3ff44d330ILXPPD6ESxEdKlavzNaA9bx1bRIVqlfOUiaOLQFltqxLpmKNOLat38zkV77inqkjuW/mS+zZvotFP83LKNei+3n0++ZJLn+qF6UrlA39wkSBuBrxbFqzMeN50rqkbAfh5SuXZ+e2naSlej+QktYmEV8je2Pa/soOzJn0KwDJ65P5YvTnvDztNV6b9Ra7tu/kj59+D92CRKHKNeJICthveXWTeb9VvnJ5dgXUTfLaJOJqZC4jwalcI57ktQFtwNokKmdZl5VrZG5Lkv06yWveVQv/pWEHL+nd9IIWxPmJuhp1auKcY9Db9/Pw109n9JCQ7MKxLVQ9uhp1TjuOxb8vLJigRUJMbUTkqp5QlXWrN2Q8X792A9UTqgY9f+3ja1GhYnne+PRFPvr+Tbpc3ikUYYqEXb5JCDM7yswGmNnPwLV4CYiX8pmnp5nNNrPZ/2zPfk1aYTKzbNOcy9JVJXuRTGVKlinFbS8N5IOH3sy4njcmNpayFcrxyMVD+Pixd7j1hf4FGndUyqEusvUayqW+Slcoy2kdGvPEOXfyyFm9KV6mJA0ubgnAtHd/4Mlz+/Bc4t1s27CZC++7NgTBR58cqyPLthHM9nN68zNod0UH3n78LQDKVihL045ncWvLm7mp6fWULF2Kcy9pXVBhHxFyXu/ZCuVfRoKSw6aQbV3mti3kNe8rg16gfbdOPPTVfyhdtjQp+72ec7HFYjmpySm81Oc5Hu56D43OP4tTzz7j8BYiSoV6WyhZphT9R93FWw+9xm6/fReJdGojIpfl0Cpk+92Rh9jYWE6tdzK9r+1Pryv70Kv/DRx7XK2CDFGkUOQ3MOVkoDzwMXA9kN6HuoSZxTnncuxT7ZwbDYwGuKH2ZRG1i9u8Lom4mge6iVdOiGfLhs05lDlwdjeuRhxb/O7jscViuW3UQKZ//hO/fTcj0zy/+s+X/bEYl+YoH1eB7cm6LCM3W9clUzFgPVdMiGdblrrYui6JSgFlKvm9IE5oeTrJKzewM3k7APO/ncWxjU5kzuc/s2PTgcF8Zn44gR6v5Xz9ncD53RLpcGVHABbPXUSVmlWBvwCIrxHP5g2ZN/FtydsoW6EsMbExpKWmEZ8Qn+nSimNPrk3vJ2/n4e4PsmOLVzdntqzP+pXr2eZvCzO+ncbJjU5mymeTQr+ARVjHbp1o59fNkrmLiA/Yb+VUN9uTt1EmoG7iEuLZrMteDknyuiTiEgLagIT4jDYgo8zazG1JXI14Nm/YTLESxXKdd+2S1Tx1nXdtdY06CdRr28h/r038PX0BOzZ728wfE3+j9unH8ecvB3p3HcnCtS3EFotlwKi7+Pnzycz8dnrBLoRIAVMbEbmu7NGVy669CID5v/9FjaOqZbxWPaEaG9Ztym3WbNav3cCW5K3s3rWH3bv28Ov0OZx0Wl1WLF1Z4HFL3nSRZMHKryfEsUBloBfwPTDb//vV/7/IWfbHYqrXTqDK0dWILV6Mszqfze/jZ2Uq8/v42bS4tDUAxzWoy67tu9i6cQsAPZ7szdrFq/j+tcyjZs/5fhanND8dgOp1EihWvJgSEPlY9ccSqtSuQeWjqxJbPJZ6nZvz5/hfM5X5c/xvNLzUG8TwmAYnsHv7LrZv3MKWNZs4pkFdipcqAcAJZ5/OhsWrATLGjAA4/bwmrFuoHXVuvn17HAMS+zIgsS8zv59B665tADixwUns2r6LzRuyX3s4f9o8mieeDUCbrm2ZNd5LvlWpWYXBLw/hv/2eZe2yNRnlN63ZyIkNTqKEX1dnnF2PVYtVJ/n5/u1vuCuxH3cl9mPW9zM4t2trAOo2OJFd23dmS54C/DltHs0SWwDQqmsbZo+fGc6Qo8bSPxZTo04CVWt57USzzi35LUs78dsPs2jp18nxDU702okNm/Oct0J8RcA7a3nRHZcz4b3vAJg7+XdqnVI7Y9yUk886ldWLVoVvgSNcuLaFW566ndWLV/H1qxpYWiKf2ojI9eEbY7isXTcua9eNCd9MpsvliQCc2eg0dmzfwaYNSfm8wwETv/2Jhs3qERsbS6nSJTmj4WksXbQ8RJGLhI8dTJegQxFpPSHAu/vFVQ/0ICY2hp8/nsBXL3xK62u8bPKk974H4NqHbuL0VvXZt3svrw96keXzllC38ckM+d8jrPxrBc55+bAxT73PvElziC1ejBue6k2tU2uTuj+Fjx59m7+nzS+0ZcxJFYoXdgjZnNy6Pp0f6EZMbAyzPp7EhBc+p9k13mjN09/7AYCLH+rBSa3qsW/3Xj4Z9DKr5nmX+HTodxn1LmxGWkoaqxcs5393jyZ1XwpXDO9NzVOPBQebV21kzD2vst1PIkWSxW5nYYeQzc0P96JBq4b+LTqfZ8m8xQDc++YDvDh4JJs3JFO9VnX6jxzk3aJzwVKe6/sMKftS6P3k7TTr1IKNq7xrH1NTUxnceQAAV/S7irMvPIe01FSWLljKi3eNyBjENRIUz//KtEJ3w8M9qdeqIfv8268tnbcEgLvfvJ+XB49k84bNVKtVnT4jB1CuUnmWL1jKiL7PkrIvhYpVK/H42KcpXa4MLs2xZ9duBrS/IyK7m5eIkLqo16Yh1zzg3WZzysc/8uXIMbT124kJfjvR/eGbOaNVA/bt3ssrA0eyzK+TnOYF6NjjAtp3867nnf3tdD5+8sBtnFtcci6de18KDv6Y+CsfPv5OOBc3R/si9LxPKLaFY06uzUNjHmfFX8txad5hywf/eZffJ/6aVyhh8+6vwws7hMMyaOgTzJozly1bthEfV4neN15H187nFXZYh+zaRpF3yW2o2og7n+/Pqc1Pp3zlCmzdtIVPnv2QiR/9UMhLe8CCPesKO4R83fv4QFq2bcbu3Xu4v88jLPjjbwBefG84Q/s/xsb1m7jmpv+jx23XUqVaHMmbNvPTj9MY2v8xAHr0voaLr7yQNJfGmPe+5N3RHxXm4uRq/vrpOV2RGDVur31FxP2mDcbI5R9FZL0ElYQw72Kza4A6zrmHzewYoIZzLt8UaiQmIY5UkZiEOJJFYhLiSFUUkhBHikhJQkjkJiGOREU9CRFtIjEJcaQqCkmII0W0JyF61/6/Ivmb9sXlH0dkvQR7tPci0By42n++HXghJBGJiIiIiIiISFTKc2DKAGc55xqa2RwA59xmMysRwrhEREREREREJMoE2xNiv5nF4t9A0cyqokFCRUREREREROQgBNsT4nngM6CamT0KXAbcF7KoRERERERERCJAkRwQIoIFlYRwzr1nZr8C7QADLnbO/RXSyEREREREREQkqgSVhDCz/wIfOec0GKWIiIiIiIiIHJJgL8f4DbjPzE7EuyzjI+fc7NCFJSIiIiIiIlL40nRBRoEKamBK59xbzrlEoCmwEHjSzBaFNDIRERERERERiSrB3h0j3QnAyUBt4O8Cj0ZEREREREREolZQSQgzS+/58BCwAGjknOsc0shEREREREREJKoEOybEMqC5c25TKIMRERERERERiSRphR1AlMkzCWFmJzvn/gZmAseY2TGBrzvnfgtlcCIiIiIiIiISPfLrCdEf6Ak8k8NrDmhb4BGJiIiIiIiISFTKMwnhnOvpP+zknNsT+JqZlQpZVCIiIiIiIiISdYK9O8bUIKeJiIiIiIiIRA1XRP9FqvzGhKgBHAWUNrMGgPkvVQDKhDg2EREREREREYki+Y0JcR5wPXA03rgQ6UmIbcA9oQtLRERERERERKJNfmNCvAW8ZWZdnXNjwhSTiIiIiIiISETQLToLVrBjQjQys0rpT8ysspk9EpqQRERERERERCQaBZuE6OSc25L+xDm3GUgMSUQiIiIiIiIiEpWCTULEmlnJ9CdmVhoomUd5EREREREREZFM8huYMt27wI9m9gbggBuAt0MWlYiIiIiIiEgEiOTbXRZFQSUhnHNPmdlcoD3eHTIeds59F9LIRERERERERCSqBNsTAufct8C3ZlYWuMTMvnbOXRC60EREREREREQkmgSVhDCzEngDUV4NnA+MAUaFMC4RERERERGRQqdbdBasPJMQZtYBuAo4D5gIvAM0dc71CENsIiIiIiIiIhJF8usJ8R3wE9DSObcMwMz+G/KoRERERERERCTq5JeEaARcCfxgZkuBD4HYkEclIiIiIiIiIlEnzySEc24OMAe4y8zOxrs0o4SZfQN85pwbHYYYRURERERERApFmtMtOgtSTLAFnXO/OOduB44CngWahywqEREREREREYk6QSUhzOxs/9accOAOGcNCFZSIiIiIiIiIRJ9ge0K8BOwys3rAYGAF8HbIohIRERERERGRqBNsEiLFOeeAi4D/Ouf+C5QPXVgiIiIiIiIihc8V0b9IFWwSYruZDQGuBb42s1igeOjCEhEREREREZFQMrPzzewfM1tsZnfn8LqZ2fP+63PNrOHhfmawSYgrgL3Ajc65dXiDU/7ncD9cRERERERERMLP71zwAtAJOBW4ysxOzVKsE1DX/+uJN1TDYcnzFp3p/MTD8IDn/6IxIURERERERCTKpUX0xQ2HpSmw2Dm3FMDMPsQbguHPgDIXAW/7wzNMN7NKZpbgnFt7qB+aZxLCzLaT8+UkBjjnXIVD/WARERERERERCQ0z64nXeyHdaOfc6IDnRwErA56vAs7K8jY5lTkKCE0SwjmnwSdFREREREREihg/4TA6jyKW02yHUOagBDsmhIiIiIiIiIhEj1VArYDnRwNrDqHMQVESQkRERERERCQXroj+C8IsoK6Z1TGzEsCVwJdZynwJdPPvktEM2Ho440FAkANTioiIiIiIiEj0cM6lmNntwHdALPC6c26Bmd3ivz4KGAckAouBXUCPw/1cJSFEREREREREjkDOuXF4iYbAaaMCHjvgtoL8TCUhRERERERERHKRVtgBRBmNCSEiIiIiIiIiYaEkhIiIiIiIiIiEhZIQIiIiIiIiIhIWIR8TYo9LDfVHSJBWklLYIUiAshqSJWLEmBV2CCKRJ6g7e0k4XNuof2GHIAHe/XV4YYcgvpsaDyrsEOQIkaZGsUCpJ4SIiIiIiIiIhIWSECIiIiIiIiISFkpCiIiIiIiIiEhY6KJ0ERERERERkVw4jQlRoNQTQkRERERERETCQkkIEREREREREQkLXY4hIiIiIiIikou0wg4gyqgnhIiIiIiIiIiEhZIQIiIiIiIiIhIWSkKIiIiIiIiISFhoTAgRERERERGRXDinW3QWJPWEEBEREREREZGwCCoJYWYXmpkSFiIiIiIiIiJyyIJNLFwJLDKzp8zslFAGJCIiIiIiIhIp0nBF8i9SBZWEcM5dCzQAlgBvmNk0M+tpZuVDGp2IiIiIiIiIRI2gL7Fwzm0DxgAfAgnAJcBvZnZHiGITERERERERkSgS7JgQXczsM2ACUBxo6pzrBNQDBoYwPhERERERERGJEsHeorMr8KxzbkrgROfcLjO7oeDDEhERERERESl8aYUdQJTJtyeEmcUCR2VNQKRzzv1Y4FGJiIiIiIiISNTJNwnhnEsFdplZxTDEIyIiIiIiIiJRKtjLMfYA88xsPLAzfaJz7s6QRCUiIiIiIiIiUSfYJMTX/p+IiIiIiIjIEcPhCjuEqBJUEsI591aoAxERERERERGR6BZUEsLM6gKPA6cCpdKnO+eOC1FcIiIiIiIiIhJlgr0c4w1gKPAs0AboAVioghIRERERERGJBGm6HKNA5Xt3DF9p/1ac5pxb4ZwbBrQNXVgiIiIiIiIiEm2CvjuGmcUAi8zsdmA1UC10YYmIiIiIiIhItAm2J0RfoAxwJ9AIuA7oHqKYRERERERERCQKBXt3jFn+wx1440GIiIiIiIiIRD3nNCZEQcozCWFmYyH3UTicc10KPCIRERERERERiUr59YR4OixRiIiIiIiIiEjUyzMJ4ZybHK5ARERERERERCS6BTUmhJnVBR4HTgVKpU93zh0XorhERERERERECl1aYQcQZYK9O8YbwEtACtAGeBt4J1RBiYiIiIiIiEj0CTYJUdo59yNgzrkVzrlhQNvQhSUiIiIiIiIi0SaoyzGAPWYWAywys9uB1UC10IUlIiIiIiIiUvhc7jeMlEMQbE+IvkAZ4E6gEXAd0D1EMYmIiIiIiIhIFAqqJ4Rzbpb/cIeZ9Qe2OOeUDhIRERERERGRoOXZE8LMHjCzk/3HJc1sIrAEWG9m7cMRoIiIiIiIiIhEh/x6QlwBPOw/Tr/8oipwIvAW8EOI4hIREREREREpdGkaE6JA5TcmxL6Ayy7OAz50zqU65/4i+EEtRURERERERETyTULsNbPTzawq0Ab4PuC1MqELS0RERERERESiTX69GfoC/8O7BONZ59wyADNLBOaENjQRERERERGRwqV7MhSsPJMQzrnpwMk5TB8HjAtVUCIiIiIiIiISffJMQvi348yVc254wYYjIiIiIiIiItEqv8sxyvv/nwQ0Ab70n3cGpoQqKBERERERERGJPvldjvEggJl9DzR0zm33nw8DPgl5dAWs27Abqd+mEft272XUwBEsn780W5mqtapxx4gBlKtUjmXzl/Jiv/+Suj8lz/l7/ud2GrRtzLakrdzVsU+297yg50Vcc+/19Krfje2bt4d2IYuI7sNuyliXLw18Pte6uHPEQMpWKsfy+Ut5od9zGXWR0/wJx9XkzpGDMuavdkx1/jf8A755fSxX39Odhu2akLo/hfUr1jFq0Ah2bdsZtuWNVGe0asB1Q28gJjaGSR/+wFcvfZatzHXDbqRem4bs3b2X0QNHssKvq9zmvW3kABKOqwlAmQpl2bVtJ/clDiC2WCw3Ptmb2qcfR0yxWH4ZM4mxL34avoUtYs5oVZ9rHvDW7+SPfuTrHOrmmqE3UK9NQ/bt3scrA0ewYsEyAG58qjf1/X3Svef1yyh/af8radihKWkuje2btvLKwJFs2bA5bMtUVIWiLtJ1urkLV97bndsaXM8OtQ+5un7YTTRo04i9/j5/WS5tRp8RAzPa75EBbUZu83fqcSHtruoAZkz4YDzjXh8LwLGn1Oamx26hVJnSbFy1gRF9hrN7x+7wLXARcTj1UvP4o7j16Tuoc9rxfPj0u3w1+ouMeW75z+009LebgTkcV8mhu++x4Uz5ZSZxlSvx+bujCjucqBSKNuOKId2o374xqftS2PDvOl4dNJJd23aFbZlEt+gsaPndHSPdMcC+gOf7gNoFHk0I1W/TkBp1atK/VW9eHfISNzzSK8dyV93djW9eG0v/1rexc+tO2lzRLt/5p3wygSe7P5Tj+8UlxHNGy3psXLWh4BeqiKrfphE16iTQr9WtvDLkRW585JYcy119d3fGvfYl/Vv3ZufWHbS5on2e869duoYhif0YktiPey4cwL7de5n13XQA5v30B4M73sld5/dl7bI1XNS7a3gWNoJZTAzdH76Z/3R/hLva96F5l3OoWffoTGXqtWlI9ToJDGx1G68PGUWPR3rmO+8Ltz/DfYkDuC9xALO+nc7sb706aHpBC4qXKM495/XjgQsG0ubqjlQ5ump4F7qIsJgYuj10M89c/yhDOvSlWZeW1Dwhc92c2bohNeokMLj17bxxz0t0f7Rnxms//28ST3d/ONv7jhv9Bfd16s8DiQP5fcKvXNTn8pAvS1EXqroAr3047Zx6bFq1MaTLUNSl7/P75NNmXOO3GX39NqNtljYj6/y1TjyGdld14J4ugxh8fl8atmtMjdoJAPR68jbef+IdBp3Xh5nfTadzr0vCs7BFyOHWy44tO3hz6KuMfeXzbPNM/mQCj+dyXCWH5+LEDowa/khhhxG1QtVmLPj5D+7t2Jf7OvVn3bI1XNj70pAvi0goBZuEeAeYaWbDzGwoMAN4O3RhFbxGHZry05iJACyes5AyFcpSqVrlbOVOa3EGM8ZNBeCnMRNp3PGsfOf/e+af7NiS8xms6x64gfcffxslzw7w1uUkIPi6mJKtLvKe//Szz2T9v+vYtNo7uJ/30++kpaYBsGjOP8QlxIdi0YqU4+ufwPrla9m4cj2p+1OYPvZnGnVomqlMww5N+dlf10v8dV2xWuWg5gU464IWTPvyZ8AbVbhkmZLExMZQolQJUvansHu7zizm5Lj6J7B+xbqM9Ttj7M807NgkU5mGHZvwy6eTAVgyZxFlypelYtVKAPwz8092bt2R7X33BJzJLVmmpPZLQQhVXQBcfX8PPnr8bZwqIk9NOjRlir8fWjRnIWXzaDOm+23G5DETaeK3GbnNf9QJR7NozkL27dlHWmoaf85YQNPzmgGQcNxR/DVjAeAlsc/q1DzES1n0HG69bEvaypK5i0ndn5ptnr9m/smOLTlvN3J4Gtc/g4oVyudfUA5JqNqM+T/9kXEcu2TOQirX0HGsFG1BJSGcc48CPYDNwBagh3PusRDGVeAq14gneU1SxvPkdUlUrh6XqUz5yuXZuW1nxkaetHZTxkYezPxZNWzfhM3rkvn3r+UFtBTRIa5GHElrNmU8T16XRFy+dZFEXI24oOdv0aUlU7/8KcfPb/1/7flj0m8FsixFWeUa8SSvDfhOr02ico24LGXiSM5hXQcz70lNT2Xrpi2sX74WgFnjprF3115GzHqN56aN5pvRX+T64+xIV7l6lvW+NpnK1eOzlcm6HQRzUNJ14NUMn/oyzS86l0+Hf1hwQUepUNVFg/aN2bw+mZV/rSjYgKNQ5Sz7/KRc2oxdAW1GckCbkdv8Kxf+y8lNT6VcpfKUKFWCBm0aEl+zCgArF/5LYz+x2uyCFsQnVAnpMhZFh1svItEolO13unMub8e8SXMOP1iRQhRsTwiAMsA259x/gVVmVidEMYWEWQ4Ts97vNYdC6feEDWr+ACVKleDi2y/jk+EfHESURwbLcT1nK5Rrmfzmjy1ejEbtmzLj61+ylbv49stIS0nl588mH1TM0Si4TSLnbSKYeZt3acl0vxcEwHH165KWlsadTW+if8tb6XRzF6rWqn7wgR8BclvvWQplnzGIe1iPefp9+rfoxbQvptC+e6dDDfGIEYq6KFGqBJ1v76okUJBC1WasXryKL0d9xn3vDeOet4ey4s/lpKZ4Z+VHDRpBx26JPP7VM5QuW5qU/fsPezmizeHWi0g0CmX7DdD5tq6kpaYy9XPdHyDcXBH9F6nyuzsGAP4lGI3x7pLxBlAceBc4O5fyPYGeAE3i6nNCudoFEetB69CtE22u7ADA0rmLiat5IMsYVyOezVkGZNuevI2yFcoSExtDWmoa8QlV2LI+GfCz9/nMH6j6sTWoWqs6T3zzrFc+IZ5Hv36G+y8azNaNWwpqEYuMDt060fbKjgAsnbso42wTpK/L5Ezls9dFPJv9ukham5Tn/PVbN2TZ/KVs3bQ103ue27UNDdo15tGrHijw5SuKktclZbosJS4hPuP7nlFmbRJx2db1ZoqVKJbnvDGxMTQ+vxn3X3hgoNAWF53D3ElzSE1JZVvSVhb++jd1zjyejSvXh2LxirTkdVnWe0IcW7JsI5vXedvBovQyNQ5sI8GY9sXP9H/9Hj579qOCCDlqhaIuqh1bg6pHV+fhb57JKP/QV//hwYvvPiLbh5x07NaJdn6bsSRLmxGfS5tRJqDNiAtoM5KztBmB80/86AcmfvQDAFcOupbkdV4PrzVLVvPYdcMASKhTkwZtG4VmQYuYgqwXkWgUyvb77K6tqd+uEU9ePawAIxYpHMH2hLgE6ALsBHDOreHA7Tuzcc6Nds41ds41LqwEBMD4t7/hnsT+3JPYn9nfz+Ccrm0AOKHBiezevivHUeH/nDafsxJbAHBO1zbMHj8TgF9/mBXU/OlW/vMvtza6nj4te9GnZS+S1yZx7wUDjtgDzPFvf5MxaKRXF60Bb13u2r4zx3W5YNq8jLo4t2sbfvXr4rcfZuY5f4su5zD1y8wZ4nqtGtD51kt5+sbH2LdnHwJL/1hMjToJVK1VjdjixWjWuSW/jZ+VqcxvP8yipb+uj29wIru272Lrhs35zntay3qsXbKazesOXLKxafUmTm1xBgAlS5fkhAYnsnbJ6tAvaBG07I/FVK+dQJWjvfV7VueWzBk/O1OZOeNncfalrQA4vkFddm/fle/+pbo/6B54lwNo/ecvFHWx6p9/uaPxDQxseSsDW95K8rokHrhw0BHbPuTk+7e/4a7EftyV2I9Z38/gXH8/VDePNuPPafNo5rcZrQLa79k/zMx1/grxFQGIr1mFpuc345cvpmSabmZcesfljH/vu5Ata1FSkPUiEo1C1X6f0ao+F9xyMc/d9ISOYyUqWLYuQjkVMpvpnGtqZr855xqaWVlgmnPuzPzmvfrYSyKmH8j1D/ekXqsG7N29l5cHjmDZvCUADH7zPkYPfoEtGzZTrVZ17hg5gLKVyrFiwTJe6PssKftS8pz/9uf7c0rz0yhfuQJbN21hzLMfMumjHzN99n9/fpn7Og8s1Ft0RlKXnB4P96Req4b+unyepRl1cT+vDB7J5oC6KFepPMsXLM1UF7nNX6JUCUZOf5U+59zC7u0Hbl307OSXKF6ieMb6XzznH167t3BvTVXsoK6GCo16bRpm3EZqysc/8uXIMbS9xjvLNeG97wHo/vDNnNGqAft27+WVgSMzvvc5zZuu59O3s3jOwoz3AChZphQ9n76dmnWPxsyY8skExr38BZEgJsfrrQrXma0bcs0DPfz1O4GxL4yhjV83E/31et1DN3Gmv096ddALLPfr5tbn+3Fys9MoV7k82zZt5bNnP2LKxz9y+0uDSDiuJi7NsWn1Rt6692WdlQxCKOoi0NM/v8SwzoMj7hade1z2AQMLyw3+Pj/9tszp+/y737yflwPajD4BbcaIgDYjt/mHffIY5SuXJ3V/Cm8/8gbzf5kLeLfu7NjNu1xp5rfT+eDJdwphqSPf4dRLxaqVeHzs05QuVwaX5tizazcD2t/B7h27ufP5/pza/PSM46pPnv0wo8dKJHj31+GFHcIhGzT0CWbNmcuWLduIj6tE7xuvo2vn8wo7rEN2U+NB+RcKs1C0GU9NGkmxEsUzBsJfMmchb907unAWMBdvLR8TeQdTBejco9pFzg+pgzBl9Y8RWS/BJiEGAnWBDsDjwA3AB8655/ObN5KSEEe6SEpCSGQkIcQTiUkIkcIWSUkIkUhSlJMQ0SYSkxBHKiUhIlOkJiGCGhPCOfe0mXUAtuGNC/GAc258SCMTERERERERkagS7MCUTzrn7gLG5zBNRERERERERCRfwfYH75DDNN3bTURERERERKKaK6J/kSrPnhBmdivQGzjOzOYGvFQe+CWUgYmIiIiIiIhIdMnvcoz3gW/wBqO8O2D6duechlQXERERERERkaDlmYRwzm0FtgJXAZhZNaAUUM7Myjnn/g19iCIiIiIiIiKFIy2iL24oeoIaE8LMOpvZImAZMBlYjtdDQkREREREREQkKMEOTPkI0AxY6JyrA7RDY0KIiIiIiIiIyEEINgmx3zmXBMSYWYxzbiJQP3RhiYiIiIiIiEi0yW9gynRbzKwcMAV4z8w2ACmhC0tERERERESk8GlMiIIVbE+Ii4DdQD/gW2AJ0DlUQYmIiIiIiIhI9AmqJ4RzbieAmVUAxoY0IhERERERERGJSkElIcysF/AQXm+INMAABxwXutBEREREREREJJoEOybEQOA059ymUAYjIiIiIiIiEkmc05gQBSnYMSGWALtCGYiIiIiIiIiIRLdge0IMAaaa2Qxgb/pE59ydIYlKRERERERERKJOsEmIl4EJwDy8MSFEREREREREop5u0Vmwgk1CpDjn+oc0EhERERERERGJasGOCTHRzHqaWYKZxaX/hTQyEREREREREYkqwfaEuNr/f0jANN2iU0RERERERESCFlQSwjlXJ9SBiIiIiIiIiEQapzEhClSeSQgza+ucm2Bml+b0unPu09CEJSIiIiIiIiLRJr+eEK3w7orROYfXHKAkhIiIiIiIiIgEJc8khHNuqP/wIefcssDXzEyXaIiIiIiIiEhUc06XYxSkYO+OMSaHaf8ryEBEREREREREJLrlNybEycBpQMUs40JUAEqFMjARERERERERiS75jQlxEnAhUInM40JsB24OUUwiIiIiIiIiEoXyGxPiC+ALM2vunJsWpphEREREREREIkKabtFZoIIdE+ISM6tgZsXN7Ecz22Rm14Y0MhERERERERGJKsEmITo657bhXZqxCjgRGBSyqEREREREREQk6gSbhCju/58IfOCcSw5RPCIiIiIiIiISpfIbmDLdWDP7G9gN9DazqsCe0IUlIiIiIiIiUvic05gQBSmonhDOubuB5kBj59x+YBdwUSgDExEREREREZHokmcSwswGBzxt75xLBXDO7QTuDGVgIiIiIiIiIhJd8usJcWXA4yFZXju/gGMRERERERERiShpuCL5F6nyS0JYLo9zei4iIiIiIiIikqv8khAul8c5PRcRERERERERyVV+d8eoZ2bb8Ho9lPYf4z8vFdLIRERERERERCSq5JmEcM7FhisQERERERERkUjjdBFAgQrqFp0iIiIiIiIiIodLSQgRERERERERCQslIUREREREREQkLPIbmFJERERERETkiJXmNCZEQVJPCBEREREREREJCyUhRERERERERCQsdDmGiIiIiIiISC50i86CpZ4QIiIiIiIiIhIWIe8JsYfUUH+EBKnnnjKFHYIEeK3U7sIOQXynuXKFHYL4ZrsthR2C+Mpb8cIOQXzz9qwr7BAkwE2NBxV2COJ7dfZ/CjsEETkE6gkhIiIiIiIiImGhMSFEREREREREcqFbdBYs9YQQERERERERkbBQEkJEREREREREwkKXY4iIiIiIiIjkQrfoLFjqCSEiIiIiIiIiYaEkhIiIiIiIiIiEhZIQIiIiIiIiIhIWGhNCREREREREJBe6RWfBUk8IEREREREREQkLJSFEREREREREJCyUhBARERERERGRsNCYECIiIiIiIiK5cGhMiIKknhAiIiIiIiIiEhZKQoiIiIiIiIhIWOhyDBEREREREZFc6BadBUs9IUREREREREQkLJSEEBEREREREZGwUBJCRERERERERMJCY0KIiIiIiIiI5EK36CxY6gkhIiIiIiIiImGhJISIiIiIiIiIhIUuxxARERERERHJhXNphR1CVFFPCBEREREREREJCyUhRERERERERCSDmcWZ2XgzW+T/XzmHMrXMbKKZ/WVmC8ysTzDvrSSEiIiIiIiIiAS6G/jROVcX+NF/nlUKMMA5dwrQDLjNzE7N7401JoSIiIiIiIhILtKOzFt0XgS09h+/BUwC7gos4JxbC6z1H283s7+Ao4A/83pj9YQQERERERERkUDV/SRDerKhWl6Fzaw20ACYkd8bqyeEiIiIiIiISJQxs55Az4BJo51zowNe/wGokcOs9x7k55QDxgB9nXPb8iuvJISIiIiIiIhIlPETDqPzeL19bq+Z2XozS3DOrTWzBGBDLuWK4yUg3nPOfRpMXEpCiIiIiIiIiOTCuSNyTIgvge7AE/7/X2QtYGYGvAb85ZwbHuwba0wIEREREREREQn0BNDBzBYBHfznmFlNMxvnlzkbuA5oa2a/+3+J+b2xekKIiIiIiIiISAbnXBLQLofpa4BE//HPgB3seysJISIiIiIiIpKLI/QWnSGjyzFEREREREREJCyUhBARERERERGRsFASQkRERERERETCQmNCiIiIiIiIiOTiCL1FZ8jkmYQws/55vX4w9wIVERERERERkSNbfj0hyvv/nwQ0Ab70n3cGpoQqKBERERERERGJPnkmIZxzDwKY2fdAQ+fcdv/5MOCTkEcnIiIiIiIiUojSdDlGgQp2YMpjgH0Bz/cBtQs8GhERERERERGJWsEOTPkOMNPMPgMccAnwdsiiEhEREREREZGoE1QSwjn3qJl9A5zjT+rhnJsTurBEREREREREJNoczC06ywDbnHNvmFlVM6vjnFsWqsBERERERERECptDY0IUpKDGhDCzocBdwBB/UnHg3VAFJSIiIiIiIiLRJ9ieEJcADYDfAJxza8ysfN6zRLYbh91MwzaN2bt7LyMHPsfS+UuzlalWqzr9RwykXKXyLJu/hP/2e5aU/Smce3ErLr6lKwB7du1m9L0vsfyv5dQ87igGjByUMX/1Y2rw4fD3+er1L7O9t2RXpU09TnmkO8TGsOq9CSwbkXm9JXQ9m+Nu7wJAys69/Dn4Vbb/+S8Ax97ciaOvbQvAqvcmsGL0N+ENPkr0GHYzDds0Yu/uvbww8L8sy3G7qEbfEYMoV6kcy+YvZYS/XdQ8/ihue/pO6px2PB88/S5jR3+eab6YmBie+OoZktcl8cQNj4RpiaLDCa3O5Pyh1xETG8NvH07i55fGZnq9yvEJXPR0LxJOq82Epz9m6uhxAFRIiOOSZ2+lXNWKuDTHr+9PYMYb3xXGIhR5PR/sRWO/zXhuwLMsmb8kW5nqtaozeORdlK9UjsXzlzC87zOk7E/JeL3umXV5+otneOq2J/ll3C8AXHTjxXS8qiM4x/K/V/DcwGfZv3d/2JarqOg+7Cbqt2nEvt17eWng8yzPYd9UtVY17hwxkLKVyrF8/lJe6Pccqf76z2n+hONqcmdAm13tmOr8b/gHfPP6WM5KbMFl/a6k5glHc3+XQSydl72+JbMhj/bnnHbN2bN7L/fe+TB/zfsnW5mrbriM63pewTF1atHylPPYkrw147UmLRpy18N9KVasGJuTt9Djkt7hDL9IO6NVfa554AZiYmOY/NGPfP3SZ9nKXDP0Buq1aci+3ft4ZeAIVizwOjPf+FRv6rdtzLakrdx7Xr+M8lcM6Ub99o1J3ZfChn/X8eqgkezatitsy3QkuO+x4Uz5ZSZxlSvx+bujCjsckbAK9u4Y+5xzDm9QSsysbOhCCr2GbRqRUKcmt7XqxaghL9DzkVtzLHfd3d0Z+9qX3N76FnZs3UG7KzoAsH7leu7/vyH0P/9OPnn+I255/DYA1ixdzYDEvgxI7MugC/uzd/deZnw3LWzLVaTFGKc+cQOzr36Cn88ZQMIlZ1P2xKMyFdm9YiMzLn6IX9rcxZLhn3LaMz0BKHfy0Rx9bVumnX8vU9veRdUODSlTp0ZhLEWR1qBNIxLqJHBHq1t4ecgL3JzLdnHN3d356rUvubP1rezYuoO2V7QHYMeWHbw+9BXGvvJ5jvMl3nAhqxevDFX4UctijMSHr+e97k/xQvvBnN6lOVXrZtk2tuzkm6FvM/WVrzNNT0tN4/tH3uOFdoN59eKhNO3WIdu8kr/GbRpTs3ZNep57MyPvHkHvR2/Lsdz1Q3rwxauf07NVT3Zu3UGHKzpmvBYTE8P1Q3owZ/JvGdPiq8fTuUdn+l3Ql9s63EZMbAzndm4V8uUpauq3aUSNOgn0a3Urrwx5kRsfuSXHclff3Z1xr31J/9a92bl1B238fVNu869duoYhif0YktiPey4cwL7de5n13XQAVi78l+G9nuDvGX+GZyGLuHPaNeeYOrVIbHY5wwY+zv1PDc6x3JyZc7np8jtZ/e/aTNPLVyjHfU8M4vZug7i41dUMuPnecIQdFSwmhm4P3cwz1z/KkA59adalJTVPODpTmTNbN6RGnQQGt76dN+55ie6P9sx47ef/TeLp7g9ne98FP//BvR37cl+n/qxbtoYLe18a8mU50lyc2IFRw3VSRo5MwSYhPjazl4FKZnYz8APwaujCCq2mHc5i0piJACyc8w9lK5SlcrXK2cqd0eJMpvlnqyaOmUDTjmcB8M+vf7Nz205v/t/+IT6hSvZ5zz6T9f+uY+PqjaFajKhSqeEJ7Fq2jt0rNuD2p7Lu86lUP79xpjJbZi8kZau33rf8uohSCXEAlK17FFt+XUTa7n241DQ2T/2L6olNwr4MRV2TDk2Z7G8Xi+YspGyFslTKYbs4vcWZTPe3i8ljJtCkYzMAtiVtZcncxZnO/KaLqxFPw7aN+fHD8SFcguh0VP3jSV6+ns0rN5K6P5X5Y6dzUodGmcrsTNrGmrlLSdufmmn6jg1bWDt/OQD7du5h4+I1lK+evU4lb2d1bMaEMRMA+CePNuPMFmfy87ifAfjxfz/S/LxmGa9d2KMzU7/5hS1JWzPNE1sslhKlShATG0PJ0iVJXp8UwiUpmhp1aMpPYyYBsHjOQsrksm86rcUZzBg3FYApYybS2G+zg5n/dL/N3uS32WsWr2Lt0jUhWqLo0+b8c/nyE68H1txfF1C+QjmqVIvPVu7v+QtZs3JttumJl57HD+MmsW71egCSN20ObcBR5Lj6J7B+xTo2rlxP6v4UZoz9mYYdMx8DNezYhF8+nQzAkjmLKFO+LBWrVgLgn5l/snPrjmzvO/+nP0hLTfPnWUjlGtnrUw5P4/pnULFCke5YfkRxzhXJv0gVVBLCOfc08D9gDHAS8IBz7vlQBhZKcTXi2bTmQHIgaV0ScdUz71zLVy7Pzm07M3bASWuTiM9hB9z+yg7MmfRrtuktu5zLT19OKeDIo1fJGnHsXnPg4HvPmmRK1ojLtfzRV7dh44TfAdjx90rimp1C8crliCldgqrt61PqKDWWByuuRjxJazZlPE9atynH7WJXlu0iLo96Stdj6E28+9hbpKVF7s4wUlWoEce2tQe2jW1rk6lQ4+ATCZWOrkLCacey+nd1Kz9Y8TXi2bQ2sM3YlK09qFC5QqY2Y9PaA2Xiq8fT/LzmfPNu5svEktYn8dnoT3lj+pu8M/tddm3byZyfdOOprOJqxGXaNyWvSyKueub9Tk5tdvq+KZj5W3RpydQvfwrVIkS96glVWbd6Q8bz9Ws3UD2hatDz1z6+FhUqlueNT1/ko+/fpMvlnUIRZlSqXD2O5MDv99pkKmdpuytXz74NHExS4ZzL2zFvkvZNIlJwgh2Y8knn3Hjn3CDn3EDn3HgzezKP8j3NbLaZzV62Y0XBRVtAzLJPy5opshwKZS1zevMzaHdFB95+/K1M04sVL0aT9k2Z+vUvhx/skSKHOiGXUWjjzj6Vo69uw8KH3wdg56I1LB35JY0/vpfGHwxh24IVuJS00MUapXL6zhPEdpG1TFYN2zZma9IWluZwDb0cmoPNbJcoU5L/G9WXbx96h707docoquhlOeygslVBHpvGzcN68ubjb5CWlnm/VLZiOc7q0Iwbz76Bbk2uo2SZUrS+pE0BRR09cm6PsxXKtUx+88cWL0aj9k2ZoTb7kOW8jQS/n4qNjeXUeifT+9r+9LqyD73638Cxx9UqyBCjVjDHq7kc+Ab1/p1v60paaipTP9eJNREpOMEOTNkB7+4YgTrlMA0A59xoYDTApcd2iYhTn+d3S6TDld71uYvnLqJKzarAX4B3lmvzhuRM5bclb6NshbLExMaQlppGfEI8yesPlDn25Nr0fvJ2Hu7+IDu2bM80b4PWjVg6fwlbN20J6TJFk71rkyld80BWvlTNOPauy94ds9ypx3D68F7MvuoJ9m8+0H1w9fsTWf2+dylB3XuuZM8adWkOxnndEml/pTfWyeK5i4mveeDSovgaVUjOYbsok227yLvb7MmNT6Fx+6Y0aN2IEiVLULp8Ge54rh8j+j5b8AsUhbatS6ZCwoFto0JCHNvXbwl6/phisfzfqL7M+/wX/vp2dggijE4XdLuA8646H4BFcxdSJeCsbnyNKtkum8jaZlRJOFDmhDNOYPBIr7msEFeBxm0ak5qSSmzxYqxfuZ5tydsAmPbtVE5pdAqTPpsYjkWMaB26daKt32Yvnbso074pLoc2e3sObfZmv81OWpuU5/z1Wzdk2fylbN2U+VIZyduVPbpy2bUXATD/97+ocVS1jNeqJ1Rjw7pNuc2azfq1G9iSvJXdu/awe9cefp0+h5NOq8uKpRpHKD/J65KIC/x+J8SxJcv2sXmdtw0sSi9T48D2kZezu7amfrtGPHn1sAKMWKRoStMtOgtUnj0hzOxWM5sHnGRmcwP+lgFzwxNiwfj27XEZg0bO/H4Grbt6Z5tObHASu7bvYvOG7D+k5k+bR/PEswFo07Uts8bPAKBKzSoMfnkI/+33LGuXZb9m9Jwu5/CzLsU4KFvnLKHMcTUofUxVrHgsNS5uwYbvMl/mUuqoeBq83p+5t73ArqWZryktUaVCRpnqiU1Y+9nUsMVelH339jgGJfZjUGI/Zn0/nVb+dlG3wYns2r6TLTlsFwumzaOZv120CtgucvP+U+9wS7Mbua1lT56942nmT52rBMRBWPPHUuLr1KBSrarEFo/l9M7N+Gd89kvAcnPRUzezafFqpr2qO8YcjK/f/po7O93BnZ3uYNp302nb1bv7zkkNTmLX9p05thnzps2jZWJLANpd1o7p33vbxk0tb+TGs2/gxrNv4Jdxv/DSfS8y/fvpbFy9kZMankTJUiUBqHd2PVZq8FYAxr/9TcagkbO/n8E5XVsDcEI++6azElsAcG7XNvw6fiYAv/0wM8/5W3Q5h6lqsw/ah2+M4bJ23bisXTcmfDOZLpcnAnBmo9PYsX0HmzYEfzJg4rc/0bBZPWJjYylVuiRnNDyNpYuWhyjy6LLsj8VUr51AlaOrEVu8GGd1bsmc8ZkTznPGz+LsS71Bb49vUJfd23exdeOWPN/3jFb1ueCWi3nupifYt2dfqMIXkSOU5dVdzswqApWBx4G7A17a7pzLP4VK5PSEyOrmh3vRoFVD/xadz7Nk3mIA7n3zAV4cPJLNG5KpXqs6/UcO8m7RuWApz/V9hpR9KfR+8naadWrBxlXe9Y+pqakM7jwAgBKlSvDK9Ne59Zye7NoeWbcy6rmnTGGHkKcq7epzysPdsdgYVn0wkaXPfU6tbt7o5ivf/oHThvekxgVN2b3KO7viUlKZdp43gnbTL4ZRonI50lJS+XvoOyT/NL/QliNYr5WKvG7xNz7ci/qtGrBv915eGDiCpf52MeTN+xk1+AU2b0imWq3q9Bs5MGO7eL7vcFL2pVCpaiWeGPsMpcuVwaWlsWfXHvq1v53dAd3/T212Ol16Xhxxt+g8jXKFHUKe6rapx/kPXIfFxjDn48n8NPILGl/TDoDZ7/1IuaoV6Tn2EUqWK41LS2Pfrr280H4w1U+uxQ1jhrL+r39x/ngcP/7nIxZN/KMwFydPs92Wwg4hR7c8fCuNWnu3r31u4LMsnuttG8PeHMbzdz1P8vpkqh9Tg7tGDqZcpfIsXbCUp/v8h5R9mQdq7ftMP2b9ODPjFp1X97+Gcy48h7TUVJYsWMrzg/+bbZ7CUt6KF3YIGXo83JN6fpv98sDnM26ZOfjN+3ll8Eg2b9hMtVrVuWPkAMpVKs/yBUt5oe+zGesyt/lLlCrByOmv0uecW9gd0GY3Pu8srn/wZirEVWTXtp0s/3MZT3R7MPwL7pu3Z12hfXaw7n18IC3bNmP37j3c3+cRFvzxNwAvvjecof0fY+P6TVxz0//R47ZrqVItjuRNm/npx2kM7f8YAD16X8PFV15ImktjzHtf8u7ojwpzcfLUqHRk3WXozNYNueaBHsTExjDl4wmMfWEMba7xehJNfO97AK576CbObNWAvbv38uqgF1jubwO3Pt+Pk5udRrnK5dm2aSufPfsRUz7+kacmjaRYieIZvX2XzFnIW/eOLpwFzMOrs/9T2CEcskFDn2DWnLls2bKN+LhK9L7xOrp2Pq+wwzpkxascl+PF1dGiasWTIvI3bX42bv0nIuslvyREBefcNjPLceS5YBIRkZqEOBJFehLiSBOJSYgjVaQnIY4kkZqEOBJFUhLiSFcUkhBHkkhLQhzJinISItooCRGZIjUJkd+YEO8DFwK/4o0SGLgQDjguRHGJiIiIiIiIFLpIvt1lUZRnEsI5d6H/f53whCMiIiIiIiIi0SrYW3TemOV5rJkNDU1IIiIiIiIiIhKNgr1FZzsz6wrcCFQBXgcmhywqERERERERkQiQpssxClRQSQjn3NVmdgUwD9gFXOWc+yWkkYmIiIiIiIhIVAn2coy6QB9gDLAcuM7MdKsFEREREREREQlaUEkIYCxwv3OuF9AKWATMCllUIiIiIiIiIhJ1gh0ToqlzbhuA8+5P8oyZfRm6sEREREREREQKn27RWbDy7AlhZoMBnHPbzOzyLC/3CFlUIiIiIiIiIhJ18rsc48qAx0OyvHZ+AcciIiIiIiIiIlEsvySE5fI4p+ciIiIiIiIiIrnKb0wIl8vjnJ6LiIiIiIiIRJU0/fQtUPklIeqZ2Ta8Xg+l/cf4z0uFNDIRERERERERiSp5JiGcc7HhCkREREREREREoluwt+gUEREREREROeLoFp0FK7+BKUVERERERERECoSSECIiIiIiIiISFkpCiIiIiIiIiEhYaEwIERERERERkVykaUyIAqWeECIiIiIiIiISFkpCiIiIiIiIiEhYKAkhIiIiIiIiImGhMSFEREREREREcuHQmBAFST0hRERERERERCQslIQQERERERERkbDQ5RgiIiIiIiIiudAtOguWekKIiIiIiIiISFgoCSEiIiIiIiIiYaEkhIiIiIiIiIiEhcaEEBEREREREcmF05gQBUo9IUREREREREQkLJSEEBEREREREZGw0OUYIiIiIiIiIrlw6HKMgqSeECIiIiIiIiISFkpCiIiIiIiIiEhYKAkhIiIiIiIiImGhMSFEREREREREcqFbdBYs9YQQERERERERkbBQEkJEREREREREwkJJCBEREREREREJC40JISIiIiIiIpILjQlRsNQTQkRERERERETCQkkIEREREREREQkLXY4hIiIiIiIikgtdjFGw1BNCRERERERERMJCSQgRERERERERCQslIUREREREREQkLEy3GwmOmfV0zo0u7DhEdRFJVBeRQ3URWVQfkUN1ETlUF5FDdRE5VBdyJFJPiOD1LOwAJIPqInKoLiKH6iKyqD4ih+oicqguIofqInKoLuSIoySEiIiIiIiIiISFkhAiIiIiIiIiEhZKQgRP12pFDtVF5FBdRA7VRWRRfUQO1UXkUF1EDtVF5FBdyBFHA1OKiIiIiIiISFioJ4SIiIiIiIiIhEWRTUKYWQ0z+9DMlpjZn2Y2zsxOPMT3etPMLvMfv2pmp/qP78lS7l4zW2Bmc83sdzM76/CXRLIys0vMzJnZyYUdS7Qzs3j/u/y7ma0zs9UBz0sUdnzRzsxS/XX9h5n9ZmYtgphnRzhiKyr8fcUzAc8HmtmwAnz/nmb2t/8308xaBrx2jt8m/G5mp5jZbv/xn2Y2yswOuY01s+VmVuUQ5qttZlcf6ueGU9bvspldb2YjD/G9TvSPAxab2V9m9rGZVT/cskF+dsYxRCQIZh9hZg38bee8IMpeb2Y1A55nHCcdQmzLzeynLNN+N7P5h/J+Obx/xNRFwP49/e/uPMpeHLhOzewhM2tfADFUMrPehzDfMDMb6D9uZmYz/GX4K7/9q5m1NrOvDjHkIu1g6twvP86vo8OuJ5GipkgmIczMgM+ASc65451zpwL3ANUDysQeyns7525yzv3pP81IQphZc+BCoKFz7kygPbDyEBch/T2LHc78Uewq4GfgysIOJNo555Kcc/Wdc/WBUcCz6c+dc/sK8rMOdZuMcrv9dV0PGAI8XtgBFUF7gUsP5Qd7fszsQqAX0NI5dzJwC/C+mdXwi1wDPO1vP7uBJf7jM4FTgYuzvF849vm1gSKRhCgoZlYK+Bp4yTl3gnPuFOAloGqWcsWCLZvHZ0XLfiy9nb0qiLLXAxlJiCzHSYeivJnVAjCzUw7jfQpUCOp2d0B7Wt8590QeZS/G22cA4Jx7wDn3QwHEUAk46B+3WbwF9PT3bacDHx/m+2USZcfCB1PnOOcSnXNbKJh6EilSimQSAmgD7HfOjUqf4Jz7HYg1s4lm9j4wz8xizew/ZjbLvN4LvcBLYpjZSP9s1ddAtfT3MbNJZtbYzJ4ASvuZzPeABGCTc26v/3mbnHNr/HmamNlU885mzjSz8mZWyszeMLN5ZjbHzNr4Za83s0/MbCzwvZmVNbPX/RjnmNlFYVmDEcrMygFnAzfiJyHMLMbMXjTvjONXfuY4vedKIzObbGa/mtl3ZpZQiOFHhdzWqb9tPOl/xxea2Tn+9ExnL/06au0/3uGf0ZkBNDeza/35fzezl6PogL4gVAA2g7cdmNmP5vWOmJfTfiG3MuadCf/LzF7xt5nvzay0/9oJZvaDHeh5cbw/fVDAfvLBMC5zQUjBG9SrX9YXLMtZUfPPEJt3pm6yeWfAF5rZE2Z2jf/dnJe+XoC7gEHOuU0Azrnf8A7IbzOzm4D/Ax7w24gMzrkUYCpwQg77/Dgz+9xf19PN7Ew/pni/ruaY2cuA+dNrW8BZYgvo6ZFLfT4BnONvY/3M7LSAbW6umdU97DUeBmbW2byzr3P8ZazuT29lB84yzjGz8nhJl2nOubHp8zvnJjrn5mdd//mUrW1mP/nrMqNnkv99CTy2MMvlGCKSmFmCmU3x19X8gH22AZfhJRc6mpeYSZ9nsL8N/OFvF5cBjYH3/PcpbQeOk241s6cC5r3ezEb4j/Pa138MXOE/vgr4IOA9cjtuC3abBWjv1+NC8xKJ+b1vRt0WzJrPmx/7n34cT/vfsy7Af/z1dbxl7qG73MweM7NpZjbbzBqa1zYvMbNb/DK5tRlPAMf77/sfv2yO+3vzevv+Y2Y/ACcFhFwNWAvgnEtNT0CZWVPzjn3n+P8HzkNeZbJul2b2TkDMmNl7ZtaloNZ5YTKziv56TV/2D8zsZv/xcvMS6AVRTyJFi3OuyP0Bd+Kdsc06vTWwE6jjP+8J3Oc/LgnMBuoAlwLjgVi87P4W4DK/3CSgsf94R8B7lwN+BxYCLwKt/OklgKVAE/95BaAYMAB4w592MvAvUAqv0V8FxPmvPQZc6z+u5L9/2cJex4VYt9cCr/mPpwIN8Q6WxuElzWrg/VC7DCjul6nql78CeL2wl6Go/gHDgEG5rVN/23jGf5wI/OA/vh4YGfA+XwGt/ccO+D//8SnAWKC4//xFoFthL3chr/NUf7/yN7AVaORPLwZU8B9XARZzYCDhHXmVwTsTngLU91/7OGAfMwO4xH9cCigDdMT7EW/+NvYVcG5hr5uDWIc7/P3ucqAiMBAY5r/2Jv6+Pcu6a42330/AaxtWAw/6r/UBnvMfJwMVs3zeRcCnWd/fX+/z/cdlgFlAJ7Lv80cAQ/3HbYHf/cfPAw/4jy/wt50qge/rvxa4fDnVZ2vgq4DyI4Br/MclgNKFXWc5fP/T//7F35cAlQO+8zdxYN8zFjjbf1zO3w6GA31y+Yys6z+vsmWAUv7jusDsgO9L4LFFrscQkfAX8D0fANzrP44FyvuPWwI/+o/fBy71H3fC2/+X8Z+nr7NJ+MdFgc/xeo8sDpj+jf/eue7r8bbTE4Gp/vM5eD0A0red3I7bWhPcNvsm8C3evqyuX/el8nnfjLoN8ff7CiAO+IcD3+1KAXEH7qsynvvr7Fb/8bPAXKC8v/43+NPzag8C9x857u+BRnhJmDJ4+9PFwEB/ngfwjrs+w+sZlr6NVACK+Y/bA2MCtpev8ilzPZm3y1bA5/7jisCy9PmK0l9Ode5P7wBMwzu59m1A+eXkvJ8/6HrSn/6K2l80dYFKN9M5t8x/3BE40w6cCauI1yidC3zgnEsF1pjZhPze1Dm3w8waAefg9cT4yLxrvX4F1jrnZvnltgGYd93wCH/a32a2Aq/hBRjvnEsOiLGLHbimqxRwDPDXoS1+kXcV8Jz/+EP/eXHgE+dcGrDOzCb6r5+E1zVwvHdih1j8bL0cspLkvU4/9f//Fa/RzE8qMMZ/3A6vAZ3lv3dpYMNhR1y07XZeF9f0S77eNrPT8Q48HjOzc4E04Ci8y83WBcybWxmAZc7rHQZ+XZl3xvgo59xnAM65Pf7ndsTbD83xy5fD209OKfClDRHn3DYzexsvQb07yNlmOefWApjZEryz5OAd4LXJYz7DSxDk5Hgz+91//Qvn3Ddmdj2Z9/ktga5+3BPM6wFREa9dutSf/rWZbc4r+DzqM2vRacC9ZnY0XvJkUV7vG2YZ33/wzo7i/bgFOBqvnU3AS56kt+u/AMPN633yqXNuVQ7LnFXg+s9LcWCkmdXH23cFjjMVeGxx0McQhWQW8LqZFcf7gfe7P/0qvPYV///r8Pbt7fFOnuwCyG+dOec2mtlSM2sGLMJrk38BbiPvfX0ysNnMrsQ71tkV8Fpux237CH6b/dg/XlhkZkvxTgTl9b6BdVuQMn2//biLAXuAV83rRRPs2Alf+v/PA8o557YD281sj5lVwkuk5NYeBMptf18e+Cy97s0s/fNwzj3kb28d8XoSXYWXaKgIvGVe7yqHt/1klVeZjO3SOTfZzF4ws2p4+8ExzutRVtRkq3MA59x4M7sceAGoF8T7HHQ9iRQ1RTUJsQDvTHhOdgY8NuAO59x3gQXMLJHcDyJz5R9wTAImmdk8oDvwWy7vlddRUdYYuzrn/jnYeKKNmcXjnRk83cwc3g9gh5d9z3EWYIFzrnmYQjwS5LdO9/r/p3Jg/5FC5ku7SgU83uNvN+nv/ZZzbkhBBRtNnHPT/G6ZVfF6mlTF6xmx38yWk3m9gjceQW5l9gaUS8X7EZDbPsmAx51zLxfIghSe5/D2x28ETMv4bpr3ayhwsNXAdZQW8DyNA9/tP/F+TAX+yGzoT8/JkpwOQMm+z8/KZfk/UG7bV76/vAGcc++bdznUBcB3ZnaTcy5SfzQHGgEMd859ad7lXcMAnHNP+D/eEoHp5g3etwDvTGpuAtd/XmX7AevxfiTE4P1YzOk94BCOIcLNOTfF/1F6AfCO3837PbwkWBczuxfvexTvJ7XySrDl5iO8y5L+xvtx5PxtLb99/Ud4P8iuzzI9t+O21gS3zUL2ZXD5vG/Wug0Z51yKmTXFS8pfCdyOd9yTn8BlzboeipF3exAox/29mfUlj7p3zi0BXjKzV4CN/vHaw8BE59wlZlYb7/g4q7zKZF3v7/jLcSVwQ26xFEXmDVJ8Cl6SPA6vF0ies3AI9SRSlBTVMSEmACXTr6kCb1wGsh9YfAfc6p8FwLwRscvineG70rxrBBPI/azX/oB5T7LM19LWB1bgNbw1/c/HvPEgivmfcU365+L1bsgp0fAdcIffaGNmDYJcB9HoMuBt59yxzrnazrlaeGe/NgFdzRsbojpeBh689VnVP4OMmRU3s9MKI/AospeDX6fLgfp+/dQCmuZS7kfgMv9MB+ZdG39sAcVd5Jl3N5hYIAnv7NEG/2CyDZDTegqmTAa/l9YqM7vY/7ySZlYGbx90g3njsWBmR6XXUVHin1H7GG88mXTL8ZII4F1GkdOZurw8BTzpH3DjnyG/Hq97+aEKbBta4401tC3L9E54lyOA96O4mt9joiTeAMl51ed2vLNl+NOPA5Y6557HO5t65mHEHk4V8brcg5fwB8DMjnfOzXPOPYnXpf5kvEsKWpjZBQHlzjezM3J437zKVsTr2ZiG1zsgtzFrgj2GKFT+/nWDc+4V4DW8BFp74A/nXC2/nT0Wr7faxXg9C27wv0eYWZz/Vpm+U1l86s97FV5iAYLb13+Gt319l2V6bsdtB+Nyvz06HjgO71ihIN73sPn72YrOuXFAX7xjSch7HQcjt/Yg6/vmtr+fAlxi3pgf5YHOATFfkH6Minc2PhXv0pjAbfT6POLKr0y6N/HWCc65BfmULWr64fX6uYoDvZMCHXY9iRQ1RbInhJ9pvwR4zrxLIvbgHWx+nqXoq3hdxn/zd6Ab8RrLz/Ayz/PwxmCYnMtHjQbmmtlveNeRjjCv21sK3nVYPZ1z+8zsCv+10nhZzvZ4B6mjzOsxkQJc75zba9m7jT6MdwZvrh/jcvyDzCPQVXiD8wQag5c9XgXMx6uvGcBWf91fBjxvXnfmYnjrMtoar3BKw0sGHcw6/QUvWTQPr45+y6mQc+5PM7sPbxCqGGA/XrfdFQUWfdFT2rzu++Cd+ejunEs1r+vrWDObzYExI7IKpkxW1wEvm9lDeOv/cufc9+aNUD/N3z/twBubpSheKvMM3pnFdK8AX5jZTLwfRgd1xtM/C38UMNW83lnb8cbXOJzLvoYBb5jZXLxu6Ok/sB8EPvDbm8l44yPg/6h4CG+/t4zM9ZytPvGuF08xsz/wDupLAdea2X68y3keOozYw2kY8ImZrQam412/D9DX/5GVitcj5Ru/bb0Q75jgObx1MRdvrIBMnHO78yj7IjDGvG7TE8n9+xLsMURhaw0M8ut+B9ANGEr23oVj8MYc6OQn2mab2T68sZjuwfsejTKz3UCmXnLOuc1m9idwqnNupj8t3329fznBk5DtEqLcjtsOxj94dVIduMU5t8fMCuJ9D1bg/h28sSr+i7dPKoW3z08fUPdD4BUzu5Pce/rmJcf2wDmXZGa/mDe47TfOuUE57e+dc7+Z2Uf+vCuAwNuoXgc8a2a78I5nr/HbqafwLrXoT+beYoGCKYMf63oz+4vsx/JFSU51/jreuDZNnXPbzWwKcB/etggUWD2JFCnpA+OIRDQzK+e8cTnigZl4A5Oty28+EREREYlsfg+ceUBD59zWwo5HREKrSPaEkCPSV34vlBLAw0pAiIiIiBR95o3t8jreODBKQIgcAdQTQkRERERERETCoqgOTCkiIiIiIiIiRYySECIiIiIiIiISFkpCiIiIiIiIiEhYKAkhIiIiIiIiImGhJISIiIiIiIiIhIWSECIiIiIiIiISFv8Phuw5prMHK88AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1440x1224 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 17))\n",
    "sns.heatmap(dataset.corr(), annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-cursor",
   "metadata": {
    "papermill": {
     "duration": 0.066187,
     "end_time": "2021-06-08T09:24:08.667396",
     "exception": false,
     "start_time": "2021-06-08T09:24:08.601209",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**From the information we've learned about our dataset, we have to deal with the following challenges:**\n",
    "\n",
    "* We need to transform all categorical attributes into numerical so that models can mostly work only with numerical inputs.\n",
    "* The target variable \"Exited\" is highly unbalanced, it needs to be balanced in order to be able to implement various machine learning models with fair results.\n",
    "* There is no multicolinearity present in data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-homeless",
   "metadata": {
    "papermill": {
     "duration": 0.06551,
     "end_time": "2021-06-08T09:24:08.799161",
     "exception": false,
     "start_time": "2021-06-08T09:24:08.733651",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Some Countplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3401a1dd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset['Gender'].value_counts()\n",
    "dataset['Geography'].value_counts()\n",
    "\n",
    "sns.countplot(data= dataset, x = 'Exited')\n",
    "y = dataset['Exited'].value_counts()\n",
    "plt.yticks(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de5cce9",
   "metadata": {},
   "source": [
    "#### There are 79 % customer churnout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bb5515c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data= dataset, x = 'Gender')\n",
    "y = dataset['Gender'].value_counts()\n",
    "plt.yticks(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efe1df3",
   "metadata": {},
   "source": [
    "#### There are 54.57% Males and 45.43% females"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ce0e13e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data= dataset, x = 'Geography')\n",
    "y = dataset['Geography'].value_counts()\n",
    "plt.yticks(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e760f4ed",
   "metadata": {
    "papermill": {
     "duration": 0.070588,
     "end_time": "2021-06-08T09:24:10.413705",
     "exception": false,
     "start_time": "2021-06-08T09:24:10.343117",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### About 50.14% customers are from France, 25.09% from Spain and 24.77% from germany"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfied-notebook",
   "metadata": {
    "papermill": {
     "duration": 0.094291,
     "end_time": "2021-06-08T09:24:34.277757",
     "exception": false,
     "start_time": "2021-06-08T09:24:34.183466",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**We have already come to some conclusions regarding features:**\n",
    "\n",
    "* Geography attribute shows that in Germany, one third of all clients decided to leave the bank.\n",
    "* Gender attribute shows that 1/4 of female clients tend to choose another bank as to 1/5 of male clients.\n",
    "* Results of tenure attribute seems to be similarly low in first and tenth year and similarly high between second and ninth year.\n",
    "* NumOfProducts attribute shows us that vast majority of clients owns one or two products and clients with more than 3 products do not leave the bank whereas almost 1/3 of clients with only one product left the bank.\n",
    "* HasCrCard attribute has similar results of target variable for both owners of the credit card and not-owners (3/4 to 1/4 distribution for target variable in this attrbiute HasCrCard).\n",
    "* For attribute IsActiveMember only every fifth active member left the company whereas more than 1/4 of non-active clients left the company. We are unable to tell what exactly this attribute means since it was not explained in the dataset description.\n",
    "* Age attribute tells us that clients who are older tend to leave the bank more often than their younger parts.\n",
    "* Since results of target variable for CreditScore and EstimatedSalary are very similar to each other, it is impossible based on this chart to tell, which customer will likely churn and which not.\n",
    "* Clients with higher balance on their bank accounts tend to leave the bank more often."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polished-wallace",
   "metadata": {
    "papermill": {
     "duration": 0.112768,
     "end_time": "2021-06-08T09:24:38.071846",
     "exception": false,
     "start_time": "2021-06-08T09:24:37.959078",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Transformation of categorical attributes**\n",
    "\n",
    "📌  First of all, let's transform categorical attributes into numerical using OneHotEncoder (.get_dummies ()) function in order to be able to provide these attributes as input for machine learning models. You may wonder why I've chosen OneHotEncoder while I could've used LabelEncoder as well. The reason lies in the nature of the attributes I am working with. Since both Geography and Gender have only few categories (Spain, France, Germany; Male, Female) and the order of these categories does not matter, it is more appropriate to use OneHotEncoder function. If there would be a lot of categories inside every attribute and we would decide to use OneHotEncoder, we would have to face curse-dimensionality problem and deal with it appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8af21a07",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42       2       0.00              1          1   \n",
       "1          608   41       1   83807.86              1          0   \n",
       "2          502   42       8  159660.80              3          1   \n",
       "3          699   39       1       0.00              2          0   \n",
       "4          850   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0               1        101348.88       1                 1   \n",
       "1               1        112542.58       0                 0   \n",
       "2               0        113931.57       1                 1   \n",
       "3               0         93826.63       0                 1   \n",
       "4               1         79084.10       0                 0   \n",
       "\n",
       "   Geography_Germany  Geography_Spain  Gender_Female  Gender_Male  \n",
       "0                  0                0              1            0  \n",
       "1                  0                1              1            0  \n",
       "2                  0                0              1            0  \n",
       "3                  0                0              1            0  \n",
       "4                  0                1              1            0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encoding categorical attributes using .get_dummies() function\n",
    "dataset = pd.get_dummies(data = dataset, columns = ['Geography', 'Gender'])\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549e3b77",
   "metadata": {},
   "source": [
    "# Balancing the target variable**\n",
    "\n",
    "📌 All done, now we can advance to the imbalanced target variable we have to deal with. We will use oversampling strategy using the RandomOverSampler class, thus we will generate same numbers of rows for the value 1 of target variable Exited, therefore we will get the same number of rows for both values of target variable. If we would not dealt with the imbalanced target variable, machine learning models would then prefer value 0 over 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c20fbe3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = dataset.drop('Exited',axis=1)\n",
    "Y = dataset['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c956928",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4a9c456",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d329672c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44dfdd3f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "\n",
    "X_train =  ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af6ef0f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000, 13)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "052bde4e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 13)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c9b91e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5590\n",
       "1    1410\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b0f471",
   "metadata": {},
   "source": [
    "Here we see that data in Y_train are unbalanced because we train more of 0 sample as compare to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c6565a",
   "metadata": {},
   "source": [
    "# RandomOverSampler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6474a83e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7000, 13), (7000,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_train1, Y_train1 = ros.fit_resample(X_train,Y_train)\n",
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a42a24af",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2373\n",
       "1     627\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce09a6da",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_test1, Y_test1 = ros.fit_resample(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3cd63c1d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2373\n",
       "1    2373\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "464f78f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create Model Function\n",
    "def create_model(model):\n",
    "    model.fit(X_train1,Y_train1)\n",
    "    Y_pred = model.predict(X_test1)\n",
    "    \n",
    "    print(classification_report(Y_test1, Y_pred))\n",
    "    \n",
    "    print(confusion_matrix(Y_test1,Y_pred))\n",
    "    return model\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd913a9",
   "metadata": {},
   "source": [
    "We base evaluation of ML classification models on performance measurement technique, confusion matrix. With this method, we can compute useful metrics to evaluate our models, such as accuracy, precision, recall and F-score.\n",
    "* **Accuracy**: Is the fraction of predictions our model got right.\n",
    "\n",
    "$$ Accuracy = \\frac {Number_of Correct Predictions} { {Total Number_of Predictions} } = \\frac {TP+FN} { {TP+FP+TN+FN} } $$\n",
    "\n",
    "* **Precision**: It is a ratio of **correct positive predictions to the total predicted positives**. In other words, of all the positive classes predicted, what percentage is truly positive.\n",
    "\n",
    "$$ Precision (P) = \\frac {TP} { {TP+FP} } $$\n",
    "\n",
    "* **Recall/Sensitivity**: The ratio of **correct positive predictions to the total positives examples**.\n",
    "\n",
    "$$ Recall (R) = \\frac {TP} { {TP+FN} } $$\n",
    "\n",
    "* **F-Score**: Weighted average score of the recall and precision.\n",
    "\n",
    "$$ F-Score = \\frac {2PR} { {(P+R)} } $$\n",
    "\n",
    "**Interpretation of Confusion matrix in our context:**\n",
    "* TP = client exited the company as predicted\n",
    "* FP = client was predicted to exit but stayed instead\n",
    "* TN = client stayed as predicted\n",
    "* FN = client was predicted to stay but exited instead (worst scenario)\n",
    "\n",
    "**Based on the importance of FN value in our case, we will pay special attention to recall metric than precision.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b7c016",
   "metadata": {},
   "source": [
    "# 1- Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30e5007a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.73      0.71      2373\n",
      "           1       0.72      0.67      0.69      2373\n",
      "\n",
      "    accuracy                           0.70      4746\n",
      "   macro avg       0.70      0.70      0.70      4746\n",
      "weighted avg       0.70      0.70      0.70      4746\n",
      "\n",
      "[[1740  633]\n",
      " [ 775 1598]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(random_state=1)\n",
    "lr = create_model(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6190b103",
   "metadata": {},
   "source": [
    "# 2- Decision Tree Classifier with Gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f797f6a8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.88      0.74      2373\n",
      "           1       0.80      0.49      0.61      2373\n",
      "\n",
      "    accuracy                           0.69      4746\n",
      "   macro avg       0.72      0.69      0.67      4746\n",
      "weighted avg       0.72      0.69      0.67      4746\n",
      "\n",
      "[[2087  286]\n",
      " [1208 1165]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=1)\n",
    "dt = create_model(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f502e79",
   "metadata": {},
   "source": [
    "**Decision Tree**\n",
    "\n",
    "We will go step by step by all possible parameters of Decision Tree function:\n",
    "* criterion : This parameter works as attribute selection measure. Default parameter is \"gini\" (for Gini index) and the other possibility is \"entropy\" for the information gain.\n",
    "\n",
    "* splitter : This parameter allows us to choose the split strategy. Default parameter is \"best\" (for best split) and the other possibility is \"random” to choose the best random split.\n",
    "\n",
    "* max_depth : The maximum depth of the tree. If None, then nodes are expanded until all the leaves contain less than min_samples_split samples. The higher value of maximum depth causes overfitting, and a lower value causes underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7694d553",
   "metadata": {},
   "source": [
    "# 2.1 Decision Tree Classifier : Pruning Technique : max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8dfa8067",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth :  1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72      2373\n",
      "           1       0.73      0.67      0.70      2373\n",
      "\n",
      "    accuracy                           0.71      4746\n",
      "   macro avg       0.71      0.71      0.71      4746\n",
      "weighted avg       0.71      0.71      0.71      4746\n",
      "\n",
      "[[1792  581]\n",
      " [ 792 1581]]\n",
      "max depth :  2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74      2373\n",
      "           1       0.74      0.71      0.72      2373\n",
      "\n",
      "    accuracy                           0.73      4746\n",
      "   macro avg       0.73      0.73      0.73      4746\n",
      "weighted avg       0.73      0.73      0.73      4746\n",
      "\n",
      "[[1783  590]\n",
      " [ 693 1680]]\n",
      "max depth :  3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74      2373\n",
      "           1       0.74      0.71      0.72      2373\n",
      "\n",
      "    accuracy                           0.73      4746\n",
      "   macro avg       0.73      0.73      0.73      4746\n",
      "weighted avg       0.73      0.73      0.73      4746\n",
      "\n",
      "[[1783  590]\n",
      " [ 693 1680]]\n",
      "max depth :  4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.76      2373\n",
      "           1       0.76      0.75      0.76      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1811  562]\n",
      " [ 590 1783]]\n",
      "max depth :  5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.76      2373\n",
      "           1       0.77      0.76      0.76      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1822  551]\n",
      " [ 570 1803]]\n",
      "max depth :  6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77      2373\n",
      "           1       0.78      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1867  506]\n",
      " [ 616 1757]]\n",
      "max depth :  7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.75      0.76      2373\n",
      "           1       0.75      0.77      0.76      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1773  600]\n",
      " [ 537 1836]]\n",
      "max depth :  8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.78      0.76      2373\n",
      "           1       0.77      0.72      0.74      2373\n",
      "\n",
      "    accuracy                           0.75      4746\n",
      "   macro avg       0.75      0.75      0.75      4746\n",
      "weighted avg       0.75      0.75      0.75      4746\n",
      "\n",
      "[[1859  514]\n",
      " [ 670 1703]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,9): #start=1 stop=9-1=8 step=+1\n",
    "    dt1=DecisionTreeClassifier(random_state=1,max_depth=i) #bydefault gini\n",
    "    print(\"max depth : \",i)\n",
    "    #call function \n",
    "    dt1=create_model(dt1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5042f2d",
   "metadata": {},
   "source": [
    "#### Here we see that depth 5 gives good recall. So we take max depth 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f08fb5b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.76      2373\n",
      "           1       0.77      0.76      0.76      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1822  551]\n",
      " [ 570 1803]]\n"
     ]
    }
   ],
   "source": [
    "dt1 = DecisionTreeClassifier(random_state=1, max_depth=5)\n",
    "\n",
    "dt1 =create_model(dt1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58420ef1",
   "metadata": {},
   "source": [
    "# 2.2 Decision Tree Classifier : Pruning Technique :min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "772efbbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min smaple leaf:  45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.80      0.77      2373\n",
      "           1       0.78      0.72      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1902  471]\n",
      " [ 658 1715]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.80      0.77      2373\n",
      "           1       0.78      0.72      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1896  477]\n",
      " [ 669 1704]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.81      0.77      2373\n",
      "           1       0.79      0.71      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1914  459]\n",
      " [ 684 1689]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.81      0.77      2373\n",
      "           1       0.79      0.71      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1918  455]\n",
      " [ 693 1680]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.81      0.77      2373\n",
      "           1       0.79      0.70      0.74      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1922  451]\n",
      " [ 707 1666]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.81      0.77      2373\n",
      "           1       0.79      0.70      0.74      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1922  451]\n",
      " [ 707 1666]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.81      0.77      2373\n",
      "           1       0.79      0.70      0.74      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1925  448]\n",
      " [ 706 1667]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.81      0.77      2373\n",
      "           1       0.79      0.71      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1926  447]\n",
      " [ 690 1683]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.81      0.77      2373\n",
      "           1       0.79      0.71      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1925  448]\n",
      " [ 683 1690]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.81      0.77      2373\n",
      "           1       0.79      0.72      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1914  459]\n",
      " [ 667 1706]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.78      2373\n",
      "           1       0.79      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1924  449]\n",
      " [ 641 1732]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.78      2373\n",
      "           1       0.79      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1924  449]\n",
      " [ 643 1730]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.78      2373\n",
      "           1       0.79      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1924  449]\n",
      " [ 643 1730]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.78      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1928  445]\n",
      " [ 637 1736]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.78      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1928  445]\n",
      " [ 637 1736]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.78      2373\n",
      "           1       0.79      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1907  466]\n",
      " [ 624 1749]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.78      2373\n",
      "           1       0.79      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1907  466]\n",
      " [ 624 1749]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.78      2373\n",
      "           1       0.79      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1907  466]\n",
      " [ 624 1749]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.78      2373\n",
      "           1       0.79      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1907  466]\n",
      " [ 624 1749]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.78      2373\n",
      "           1       0.79      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1908  465]\n",
      " [ 631 1742]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2373\n",
      "           1       0.80      0.72      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1934  439]\n",
      " [ 657 1716]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2373\n",
      "           1       0.80      0.72      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1934  439]\n",
      " [ 657 1716]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2373\n",
      "           1       0.80      0.72      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1934  439]\n",
      " [ 657 1716]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.81      0.78      2373\n",
      "           1       0.79      0.72      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.76      4746\n",
      "weighted avg       0.77      0.76      0.76      4746\n",
      "\n",
      "[[1931  442]\n",
      " [ 675 1698]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.81      0.78      2373\n",
      "           1       0.79      0.72      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.76      4746\n",
      "weighted avg       0.77      0.76      0.76      4746\n",
      "\n",
      "[[1931  442]\n",
      " [ 675 1698]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.82      0.78      2373\n",
      "           1       0.79      0.71      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.76      4746\n",
      "weighted avg       0.77      0.76      0.76      4746\n",
      "\n",
      "[[1937  436]\n",
      " [ 686 1687]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.80      0.77      2373\n",
      "           1       0.79      0.72      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1910  463]\n",
      " [ 669 1704]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.77      2373\n",
      "           1       0.78      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1890  483]\n",
      " [ 639 1734]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.80      0.77      2373\n",
      "           1       0.78      0.72      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1903  470]\n",
      " [ 671 1702]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77      2373\n",
      "           1       0.78      0.73      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1881  492]\n",
      " [ 640 1733]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.79      0.77      2373\n",
      "           1       0.78      0.73      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1879  494]\n",
      " [ 648 1725]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.79      0.77      2373\n",
      "           1       0.78      0.73      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1879  494]\n",
      " [ 648 1725]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77      2373\n",
      "           1       0.78      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1866  507]\n",
      " [ 625 1748]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77      2373\n",
      "           1       0.78      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1866  507]\n",
      " [ 625 1748]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77      2373\n",
      "           1       0.78      0.73      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1872  501]\n",
      " [ 634 1739]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77      2373\n",
      "           1       0.78      0.73      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1872  501]\n",
      " [ 634 1739]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77      2373\n",
      "           1       0.78      0.73      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1872  501]\n",
      " [ 634 1739]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77      2373\n",
      "           1       0.78      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1878  495]\n",
      " [ 628 1745]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.77      2373\n",
      "           1       0.78      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1887  486]\n",
      " [ 626 1747]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.77      2373\n",
      "           1       0.78      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1888  485]\n",
      " [ 626 1747]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77      2373\n",
      "           1       0.78      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.76      4746\n",
      "weighted avg       0.77      0.76      0.76      4746\n",
      "\n",
      "[[1873  500]\n",
      " [ 617 1756]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77      2373\n",
      "           1       0.78      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1877  496]\n",
      " [ 615 1758]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.77      2373\n",
      "           1       0.77      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1855  518]\n",
      " [ 611 1762]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.77      2373\n",
      "           1       0.77      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1855  518]\n",
      " [ 611 1762]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77      2373\n",
      "           1       0.78      0.73      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1875  498]\n",
      " [ 632 1741]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76      2373\n",
      "           1       0.77      0.74      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1850  523]\n",
      " [ 617 1756]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76      2373\n",
      "           1       0.77      0.74      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1850  523]\n",
      " [ 617 1756]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76      2373\n",
      "           1       0.77      0.74      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1854  519]\n",
      " [ 625 1748]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76      2373\n",
      "           1       0.77      0.74      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1854  519]\n",
      " [ 625 1748]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76      2373\n",
      "           1       0.77      0.74      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1853  520]\n",
      " [ 625 1748]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77      2373\n",
      "           1       0.78      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1875  498]\n",
      " [ 625 1748]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77      2373\n",
      "           1       0.78      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1875  498]\n",
      " [ 625 1748]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77      2373\n",
      "           1       0.78      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1875  498]\n",
      " [ 625 1748]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77      2373\n",
      "           1       0.78      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1875  498]\n",
      " [ 625 1748]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77      2373\n",
      "           1       0.78      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1875  498]\n",
      " [ 625 1748]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77      2373\n",
      "           1       0.78      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1874  499]\n",
      " [ 625 1748]]\n",
      "<------------------------------------------------------>\n"
     ]
    }
   ],
   "source": [
    "for i in range(45,101,1):\n",
    "    df2 = DecisionTreeClassifier(random_state=1, min_samples_leaf=i)\n",
    "    print(\"min smaple leaf: \", i)\n",
    "    \n",
    "    df2 = create_model(df2)\n",
    "    print(\"<------------------------------------------------------>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6dec7064",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76      2373\n",
      "           1       0.77      0.74      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1850  523]\n",
      " [ 617 1756]]\n"
     ]
    }
   ],
   "source": [
    "df2 = DecisionTreeClassifier(random_state=1, min_samples_leaf=90)\n",
    "\n",
    "df2 = create_model(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee701df3",
   "metadata": {},
   "source": [
    "# 3 Decision Tree Classifier with Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "da08ed3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.87      0.74      2373\n",
      "           1       0.80      0.51      0.62      2373\n",
      "\n",
      "    accuracy                           0.69      4746\n",
      "   macro avg       0.72      0.69      0.68      4746\n",
      "weighted avg       0.72      0.69      0.68      4746\n",
      "\n",
      "[[2068  305]\n",
      " [1169 1204]]\n"
     ]
    }
   ],
   "source": [
    "dt_entropy = DecisionTreeClassifier(random_state=1, criterion='entropy')   \n",
    "\n",
    "# Criterion should be entropy if you want to calculate with Entropy other wise by default it take Gini Index\n",
    "\n",
    "dt_entropy = create_model(dt_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd93f60",
   "metadata": {},
   "source": [
    "# 3.1 Decision Tree Classifier with Entropy : max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "63507bce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth :  1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72      2373\n",
      "           1       0.73      0.67      0.70      2373\n",
      "\n",
      "    accuracy                           0.71      4746\n",
      "   macro avg       0.71      0.71      0.71      4746\n",
      "weighted avg       0.71      0.71      0.71      4746\n",
      "\n",
      "[[1792  581]\n",
      " [ 792 1581]]\n",
      "max depth :  2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74      2373\n",
      "           1       0.74      0.71      0.72      2373\n",
      "\n",
      "    accuracy                           0.73      4746\n",
      "   macro avg       0.73      0.73      0.73      4746\n",
      "weighted avg       0.73      0.73      0.73      4746\n",
      "\n",
      "[[1783  590]\n",
      " [ 693 1680]]\n",
      "max depth :  3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74      2373\n",
      "           1       0.74      0.71      0.72      2373\n",
      "\n",
      "    accuracy                           0.73      4746\n",
      "   macro avg       0.73      0.73      0.73      4746\n",
      "weighted avg       0.73      0.73      0.73      4746\n",
      "\n",
      "[[1783  590]\n",
      " [ 693 1680]]\n",
      "max depth :  4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.76      2373\n",
      "           1       0.76      0.75      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1812  561]\n",
      " [ 595 1778]]\n",
      "max depth :  5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77      2373\n",
      "           1       0.78      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1867  506]\n",
      " [ 616 1757]]\n",
      "max depth :  6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.79      0.77      2373\n",
      "           1       0.78      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1886  487]\n",
      " [ 610 1763]]\n",
      "max depth :  7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76      2373\n",
      "           1       0.77      0.74      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1845  528]\n",
      " [ 626 1747]]\n",
      "max depth :  8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76      2373\n",
      "           1       0.77      0.71      0.74      2373\n",
      "\n",
      "    accuracy                           0.75      4746\n",
      "   macro avg       0.75      0.75      0.75      4746\n",
      "weighted avg       0.75      0.75      0.75      4746\n",
      "\n",
      "[[1873  500]\n",
      " [ 696 1677]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,9): #start=1 stop=9-1=8 step=+1\n",
    "    dt_entropy1=DecisionTreeClassifier(random_state=1,max_depth=i,criterion='entropy') #bydefault gini\n",
    "    print(\"max depth : \",i)\n",
    "    #call function \n",
    "    dt_entropy1=create_model(dt_entropy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c31bb61a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.76      2373\n",
      "           1       0.76      0.75      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1812  561]\n",
      " [ 595 1778]]\n"
     ]
    }
   ],
   "source": [
    "# Above we see that we get good recall at 4\n",
    "dt_entropy1=DecisionTreeClassifier(random_state=1,max_depth=4,criterion='entropy') #bydefault gini\n",
    "\n",
    "dt_entropy1=create_model(dt_entropy1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9074feff",
   "metadata": {},
   "source": [
    "# 3.2 Decision Tree Classifier with Entropy : min_sample_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "105f32d0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min smaple leaf:  45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.80      0.77      2373\n",
      "           1       0.78      0.72      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1892  481]\n",
      " [ 655 1718]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.80      0.77      2373\n",
      "           1       0.78      0.72      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1889  484]\n",
      " [ 668 1705]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.80      0.77      2373\n",
      "           1       0.78      0.72      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1888  485]\n",
      " [ 671 1702]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.80      0.77      2373\n",
      "           1       0.78      0.72      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1899  474]\n",
      " [ 676 1697]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.80      0.77      2373\n",
      "           1       0.78      0.72      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1899  474]\n",
      " [ 663 1710]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.80      0.77      2373\n",
      "           1       0.78      0.72      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1901  472]\n",
      " [ 663 1710]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.80      0.77      2373\n",
      "           1       0.78      0.72      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1900  473]\n",
      " [ 663 1710]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.77      2373\n",
      "           1       0.79      0.73      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.76      4746\n",
      "weighted avg       0.77      0.76      0.76      4746\n",
      "\n",
      "[[1902  471]\n",
      " [ 650 1723]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.77      2373\n",
      "           1       0.79      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.76      4746\n",
      "weighted avg       0.77      0.76      0.76      4746\n",
      "\n",
      "[[1900  473]\n",
      " [ 643 1730]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.78      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1929  444]\n",
      " [ 651 1722]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.78      0.77      0.77      4746\n",
      "weighted avg       0.78      0.77      0.77      4746\n",
      "\n",
      "[[1944  429]\n",
      " [ 645 1728]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.78      0.77      0.77      4746\n",
      "weighted avg       0.78      0.77      0.77      4746\n",
      "\n",
      "[[1944  429]\n",
      " [ 647 1726]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.78      0.77      0.77      4746\n",
      "weighted avg       0.78      0.77      0.77      4746\n",
      "\n",
      "[[1944  429]\n",
      " [ 647 1726]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.78      0.77      0.77      4746\n",
      "weighted avg       0.78      0.77      0.77      4746\n",
      "\n",
      "[[1954  419]\n",
      " [ 652 1721]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.78      0.77      0.77      4746\n",
      "weighted avg       0.78      0.77      0.77      4746\n",
      "\n",
      "[[1954  419]\n",
      " [ 652 1721]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.78      0.77      0.77      4746\n",
      "weighted avg       0.78      0.77      0.77      4746\n",
      "\n",
      "[[1937  436]\n",
      " [ 639 1734]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.78      0.77      0.77      4746\n",
      "weighted avg       0.78      0.77      0.77      4746\n",
      "\n",
      "[[1937  436]\n",
      " [ 639 1734]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1936  437]\n",
      " [ 642 1731]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.78      2373\n",
      "           1       0.79      0.74      0.77      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.78      0.77      0.77      4746\n",
      "weighted avg       0.78      0.77      0.77      4746\n",
      "\n",
      "[[1921  452]\n",
      " [ 622 1751]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.78      2373\n",
      "           1       0.79      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1922  451]\n",
      " [ 629 1744]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.78      0.77      0.77      4746\n",
      "weighted avg       0.78      0.77      0.77      4746\n",
      "\n",
      "[[1949  424]\n",
      " [ 646 1727]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.78      0.77      0.77      4746\n",
      "weighted avg       0.78      0.77      0.77      4746\n",
      "\n",
      "[[1949  424]\n",
      " [ 646 1727]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.78      0.77      0.77      4746\n",
      "weighted avg       0.78      0.77      0.77      4746\n",
      "\n",
      "[[1949  424]\n",
      " [ 646 1727]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2373\n",
      "           1       0.80      0.72      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1946  427]\n",
      " [ 664 1709]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2373\n",
      "           1       0.80      0.72      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1946  427]\n",
      " [ 664 1709]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2373\n",
      "           1       0.80      0.72      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1946  427]\n",
      " [ 664 1709]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.78      2373\n",
      "           1       0.79      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1919  454]\n",
      " [ 647 1726]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.78      2373\n",
      "           1       0.79      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1899  474]\n",
      " [ 617 1756]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.78      2373\n",
      "           1       0.79      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1912  461]\n",
      " [ 649 1724]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.77      2373\n",
      "           1       0.78      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1890  483]\n",
      " [ 618 1755]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.77      2373\n",
      "           1       0.78      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1890  483]\n",
      " [ 628 1745]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.77      2373\n",
      "           1       0.78      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1888  485]\n",
      " [ 626 1747]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.77      2373\n",
      "           1       0.78      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1888  485]\n",
      " [ 626 1747]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.77      2373\n",
      "           1       0.78      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1888  485]\n",
      " [ 626 1747]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.77      2373\n",
      "           1       0.78      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1889  484]\n",
      " [ 626 1747]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.77      2373\n",
      "           1       0.78      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1889  484]\n",
      " [ 626 1747]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.77      2373\n",
      "           1       0.78      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1889  484]\n",
      " [ 626 1747]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.81      0.77      2373\n",
      "           1       0.79      0.72      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.76      4746\n",
      "weighted avg       0.77      0.76      0.76      4746\n",
      "\n",
      "[[1916  457]\n",
      " [ 667 1706]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.81      0.78      2373\n",
      "           1       0.79      0.72      0.75      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.76      4746\n",
      "weighted avg       0.77      0.77      0.76      4746\n",
      "\n",
      "[[1925  448]\n",
      " [ 665 1708]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.81      0.78      2373\n",
      "           1       0.79      0.72      0.75      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1926  447]\n",
      " [ 665 1708]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.81      0.77      2373\n",
      "           1       0.79      0.72      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.76      4746\n",
      "weighted avg       0.77      0.76      0.76      4746\n",
      "\n",
      "[[1911  462]\n",
      " [ 656 1717]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.77      2373\n",
      "           1       0.79      0.72      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1915  458]\n",
      " [ 654 1719]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.80      0.77      2373\n",
      "           1       0.78      0.73      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1893  480]\n",
      " [ 650 1723]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.80      0.77      2373\n",
      "           1       0.78      0.73      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1893  480]\n",
      " [ 650 1723]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.77      2373\n",
      "           1       0.78      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1896  477]\n",
      " [ 633 1740]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77      2373\n",
      "           1       0.78      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1871  502]\n",
      " [ 618 1755]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76      2373\n",
      "           1       0.77      0.75      0.76      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1840  533]\n",
      " [ 599 1774]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.77      2373\n",
      "           1       0.77      0.75      0.76      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1849  524]\n",
      " [ 605 1768]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77      2373\n",
      "           1       0.78      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1870  503]\n",
      " [ 624 1749]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77      2373\n",
      "           1       0.78      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1869  504]\n",
      " [ 624 1749]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.77      2373\n",
      "           1       0.78      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1891  482]\n",
      " [ 624 1749]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.77      2373\n",
      "           1       0.78      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1891  482]\n",
      " [ 624 1749]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.77      2373\n",
      "           1       0.78      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1891  482]\n",
      " [ 624 1749]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.77      2373\n",
      "           1       0.78      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1891  482]\n",
      " [ 624 1749]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.79      0.77      2373\n",
      "           1       0.78      0.75      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1870  503]\n",
      " [ 605 1768]]\n",
      "<------------------------------------------------------>\n",
      "min smaple leaf:  100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.79      0.77      2373\n",
      "           1       0.78      0.75      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1869  504]\n",
      " [ 605 1768]]\n",
      "<------------------------------------------------------>\n"
     ]
    }
   ],
   "source": [
    "for i in range(45,101,1):\n",
    "    df2 = DecisionTreeClassifier(random_state=1, min_samples_leaf=i,criterion='entropy')\n",
    "    print(\"min smaple leaf: \", i)\n",
    "    \n",
    "    df2 = create_model(df2)\n",
    "    print(\"<------------------------------------------------------>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f8f3a8bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76      2373\n",
      "           1       0.77      0.75      0.76      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1840  533]\n",
      " [ 599 1774]]\n"
     ]
    }
   ],
   "source": [
    "df2 = DecisionTreeClassifier(random_state=1, min_samples_leaf=91,criterion='entropy')\n",
    "\n",
    "df2 = create_model(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c7751c",
   "metadata": {},
   "source": [
    "# 4. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "12ad51bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e07ff42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.94      0.78      2373\n",
      "           1       0.90      0.53      0.66      2373\n",
      "\n",
      "    accuracy                           0.73      4746\n",
      "   macro avg       0.78      0.73      0.72      4746\n",
      "weighted avg       0.78      0.73      0.72      4746\n",
      "\n",
      "[[2228  145]\n",
      " [1127 1246]]\n"
     ]
    }
   ],
   "source": [
    "rfc =RandomForestClassifier(random_state=1)\n",
    "rfc = create_model(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8bcdfe6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max_depth:  1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74      2373\n",
      "           1       0.75      0.70      0.73      2373\n",
      "\n",
      "    accuracy                           0.73      4746\n",
      "   macro avg       0.73      0.73      0.73      4746\n",
      "weighted avg       0.73      0.73      0.73      4746\n",
      "\n",
      "[[1811  562]\n",
      " [ 703 1670]]\n",
      "Max_depth:  2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.81      0.77      2373\n",
      "           1       0.78      0.70      0.74      2373\n",
      "\n",
      "    accuracy                           0.75      4746\n",
      "   macro avg       0.76      0.75      0.75      4746\n",
      "weighted avg       0.76      0.75      0.75      4746\n",
      "\n",
      "[[1912  461]\n",
      " [ 704 1669]]\n",
      "Max_depth:  3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.78      2373\n",
      "           1       0.79      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1915  458]\n",
      " [ 641 1732]]\n",
      "Max_depth:  4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.78      2373\n",
      "           1       0.79      0.72      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1920  453]\n",
      " [ 657 1716]]\n",
      "Max_depth:  5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.81      0.78      2373\n",
      "           1       0.79      0.72      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.76      4746\n",
      "weighted avg       0.77      0.76      0.76      4746\n",
      "\n",
      "[[1929  444]\n",
      " [ 675 1698]]\n",
      "Max_depth:  6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.83      0.78      2373\n",
      "           1       0.81      0.71      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1970  403]\n",
      " [ 687 1686]]\n",
      "Max_depth:  7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.85      0.79      2373\n",
      "           1       0.82      0.70      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.78      0.77      0.77      4746\n",
      "weighted avg       0.78      0.77      0.77      4746\n",
      "\n",
      "[[2013  360]\n",
      " [ 711 1662]]\n",
      "Max_depth:  8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.85      0.78      2373\n",
      "           1       0.82      0.69      0.75      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[2012  361]\n",
      " [ 743 1630]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,9):\n",
    "    rfc1 = RandomForestClassifier(random_state=1, max_depth=i)\n",
    "    print(\"Max_depth: \", i)\n",
    "    \n",
    "    rfc1  = create_model(rfc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "42045dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.78      2373\n",
      "           1       0.79      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1915  458]\n",
      " [ 641 1732]]\n"
     ]
    }
   ],
   "source": [
    "rfc1 = RandomForestClassifier(random_state=1, max_depth=3)\n",
    "    \n",
    "rfc1  = create_model(rfc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfb029b",
   "metadata": {},
   "source": [
    "# 5. AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1d3c7ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "384e729f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Decision Stump:  1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72      2373\n",
      "           1       0.73      0.67      0.70      2373\n",
      "\n",
      "    accuracy                           0.71      4746\n",
      "   macro avg       0.71      0.71      0.71      4746\n",
      "weighted avg       0.71      0.71      0.71      4746\n",
      "\n",
      "[[1792  581]\n",
      " [ 792 1581]]\n",
      "No of Decision Stump:  2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74      2373\n",
      "           1       0.74      0.71      0.72      2373\n",
      "\n",
      "    accuracy                           0.73      4746\n",
      "   macro avg       0.73      0.73      0.73      4746\n",
      "weighted avg       0.73      0.73      0.73      4746\n",
      "\n",
      "[[1783  590]\n",
      " [ 693 1680]]\n",
      "No of Decision Stump:  3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.88      0.77      2373\n",
      "           1       0.84      0.60      0.70      2373\n",
      "\n",
      "    accuracy                           0.74      4746\n",
      "   macro avg       0.76      0.74      0.74      4746\n",
      "weighted avg       0.76      0.74      0.74      4746\n",
      "\n",
      "[[2096  277]\n",
      " [ 949 1424]]\n",
      "No of Decision Stump:  4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.67      0.71      2373\n",
      "           1       0.71      0.78      0.74      2373\n",
      "\n",
      "    accuracy                           0.73      4746\n",
      "   macro avg       0.73      0.73      0.73      4746\n",
      "weighted avg       0.73      0.73      0.73      4746\n",
      "\n",
      "[[1597  776]\n",
      " [ 513 1860]]\n",
      "No of Decision Stump:  5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.80      0.77      2373\n",
      "           1       0.78      0.71      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1901  472]\n",
      " [ 678 1695]]\n",
      "No of Decision Stump:  6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.75      2373\n",
      "           1       0.75      0.76      0.75      2373\n",
      "\n",
      "    accuracy                           0.75      4746\n",
      "   macro avg       0.75      0.75      0.75      4746\n",
      "weighted avg       0.75      0.75      0.75      4746\n",
      "\n",
      "[[1771  602]\n",
      " [ 574 1799]]\n",
      "No of Decision Stump:  7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76      2373\n",
      "           1       0.76      0.76      0.76      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1807  566]\n",
      " [ 574 1799]]\n",
      "No of Decision Stump:  8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.78      0.77      2373\n",
      "           1       0.77      0.75      0.76      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1840  533]\n",
      " [ 585 1788]]\n",
      "No of Decision Stump:  9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.78      0.77      2373\n",
      "           1       0.77      0.75      0.76      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1841  532]\n",
      " [ 594 1779]]\n",
      "No of Decision Stump:  10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.79      0.77      2373\n",
      "           1       0.78      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1882  491]\n",
      " [ 607 1766]]\n",
      "No of Decision Stump:  11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77      2373\n",
      "           1       0.78      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1877  496]\n",
      " [ 614 1759]]\n",
      "No of Decision Stump:  12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.79      0.77      2373\n",
      "           1       0.78      0.75      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1866  507]\n",
      " [ 600 1773]]\n",
      "No of Decision Stump:  13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.78      0.77      2373\n",
      "           1       0.78      0.75      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1860  513]\n",
      " [ 589 1784]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,14):\n",
    "    ada = AdaBoostClassifier(n_estimators=i, random_state=1)\n",
    "    \n",
    "    print(\"No of Decision Stump: \", i)\n",
    "    \n",
    "    ada = create_model(ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1da5b0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.67      0.71      2373\n",
      "           1       0.71      0.78      0.74      2373\n",
      "\n",
      "    accuracy                           0.73      4746\n",
      "   macro avg       0.73      0.73      0.73      4746\n",
      "weighted avg       0.73      0.73      0.73      4746\n",
      "\n",
      "[[1597  776]\n",
      " [ 513 1860]]\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(n_estimators=4, random_state=1)\n",
    "\n",
    "\n",
    "ada = create_model(ada)\n",
    "# n_estimators means how many decision stump, decision stump deend on the no of input.... here input = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d820a7",
   "metadata": {},
   "source": [
    "# 5. Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b1ed2302",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a39778c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esimators:  10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.82      0.77      2373\n",
      "           1       0.79      0.70      0.74      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1938  435]\n",
      " [ 718 1655]]\n",
      "Esimators:  11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76      2373\n",
      "           1       0.76      0.75      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1824  549]\n",
      " [ 603 1770]]\n",
      "Esimators:  12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76      2373\n",
      "           1       0.76      0.74      0.75      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1831  542]\n",
      " [ 609 1764]]\n",
      "Esimators:  13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76      2373\n",
      "           1       0.76      0.75      0.76      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1820  553]\n",
      " [ 594 1779]]\n",
      "Esimators:  14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76      2373\n",
      "           1       0.76      0.75      0.76      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1825  548]\n",
      " [ 599 1774]]\n",
      "Esimators:  15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76      2373\n",
      "           1       0.77      0.75      0.76      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1836  537]\n",
      " [ 601 1772]]\n",
      "Esimators:  16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.77      2373\n",
      "           1       0.78      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1893  480]\n",
      " [ 621 1752]]\n",
      "Esimators:  17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.79      0.77      2373\n",
      "           1       0.78      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1885  488]\n",
      " [ 609 1764]]\n",
      "Esimators:  18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.80      0.78      2373\n",
      "           1       0.79      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1891  482]\n",
      " [ 607 1766]]\n",
      "Esimators:  19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.78      2373\n",
      "           1       0.79      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1911  462]\n",
      " [ 627 1746]]\n",
      "Esimators:  20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.78      2373\n",
      "           1       0.79      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1901  472]\n",
      " [ 618 1755]]\n",
      "Esimators:  21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.78      2373\n",
      "           1       0.79      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1923  450]\n",
      " [ 640 1733]]\n",
      "Esimators:  22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.78      2373\n",
      "           1       0.79      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1924  449]\n",
      " [ 644 1729]]\n",
      "Esimators:  23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.78      2373\n",
      "           1       0.79      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1920  453]\n",
      " [ 637 1736]]\n",
      "Esimators:  24\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.78      2373\n",
      "           1       0.79      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1924  449]\n",
      " [ 633 1740]]\n",
      "Esimators:  25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1935  438]\n",
      " [ 642 1731]]\n",
      "Esimators:  26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.78      0.77      0.77      4746\n",
      "weighted avg       0.78      0.77      0.77      4746\n",
      "\n",
      "[[1938  435]\n",
      " [ 641 1732]]\n",
      "Esimators:  27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.78      0.77      0.77      4746\n",
      "weighted avg       0.78      0.77      0.77      4746\n",
      "\n",
      "[[1950  423]\n",
      " [ 647 1726]]\n",
      "Esimators:  28\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.78      0.77      0.77      4746\n",
      "weighted avg       0.78      0.77      0.77      4746\n",
      "\n",
      "[[1944  429]\n",
      " [ 641 1732]]\n",
      "Esimators:  29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.78      0.77      0.77      4746\n",
      "weighted avg       0.78      0.77      0.77      4746\n",
      "\n",
      "[[1940  433]\n",
      " [ 637 1736]]\n",
      "Esimators:  30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.78      0.77      0.77      4746\n",
      "weighted avg       0.78      0.77      0.77      4746\n",
      "\n",
      "[[1943  430]\n",
      " [ 643 1730]]\n",
      "Esimators:  31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1943  430]\n",
      " [ 649 1724]]\n",
      "Esimators:  32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1937  436]\n",
      " [ 646 1727]]\n",
      "Esimators:  33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.78      2373\n",
      "           1       0.80      0.74      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1938  435]\n",
      " [ 627 1746]]\n",
      "Esimators:  34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.78      2373\n",
      "           1       0.80      0.74      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1933  440]\n",
      " [ 625 1748]]\n",
      "Esimators:  35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.78      2373\n",
      "           1       0.80      0.74      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1927  446]\n",
      " [ 618 1755]]\n",
      "Esimators:  36\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.78      2373\n",
      "           1       0.80      0.74      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1934  439]\n",
      " [ 625 1748]]\n",
      "Esimators:  37\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.78      2373\n",
      "           1       0.80      0.74      0.77      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.78      0.77      0.77      4746\n",
      "weighted avg       0.78      0.77      0.77      4746\n",
      "\n",
      "[[1925  448]\n",
      " [ 625 1748]]\n",
      "Esimators:  38\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.78      2373\n",
      "           1       0.80      0.74      0.77      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.78      0.77      0.77      4746\n",
      "weighted avg       0.78      0.77      0.77      4746\n",
      "\n",
      "[[1930  443]\n",
      " [ 627 1746]]\n",
      "Esimators:  39\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.78      2373\n",
      "           1       0.79      0.74      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1918  455]\n",
      " [ 624 1749]]\n",
      "Esimators:  40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79      2373\n",
      "           1       0.80      0.74      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1944  429]\n",
      " [ 622 1751]]\n",
      "Esimators:  41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79      2373\n",
      "           1       0.80      0.74      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1938  435]\n",
      " [ 615 1758]]\n",
      "Esimators:  42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79      2373\n",
      "           1       0.80      0.74      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1936  437]\n",
      " [ 615 1758]]\n",
      "Esimators:  43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.79      2373\n",
      "           1       0.80      0.74      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1933  440]\n",
      " [ 615 1758]]\n",
      "Esimators:  44\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79      2373\n",
      "           1       0.80      0.74      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1941  432]\n",
      " [ 615 1758]]\n",
      "Esimators:  45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79      2373\n",
      "           1       0.80      0.74      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1947  426]\n",
      " [ 615 1758]]\n",
      "Esimators:  46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79      2373\n",
      "           1       0.80      0.74      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1941  432]\n",
      " [ 615 1758]]\n",
      "Esimators:  47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79      2373\n",
      "           1       0.80      0.74      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1941  432]\n",
      " [ 615 1758]]\n",
      "Esimators:  48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79      2373\n",
      "           1       0.80      0.74      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1946  427]\n",
      " [ 625 1748]]\n",
      "Esimators:  49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79      2373\n",
      "           1       0.80      0.73      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1945  428]\n",
      " [ 634 1739]]\n",
      "Esimators:  50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79      2373\n",
      "           1       0.80      0.74      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1941  432]\n",
      " [ 628 1745]]\n",
      "Esimators:  51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79      2373\n",
      "           1       0.80      0.74      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1945  428]\n",
      " [ 628 1745]]\n",
      "Esimators:  52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79      2373\n",
      "           1       0.80      0.74      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1944  429]\n",
      " [ 618 1755]]\n",
      "Esimators:  53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79      2373\n",
      "           1       0.80      0.74      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1947  426]\n",
      " [ 624 1749]]\n",
      "Esimators:  54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79      2373\n",
      "           1       0.80      0.74      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1946  427]\n",
      " [ 626 1747]]\n",
      "Esimators:  55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.78      0.77      0.77      4746\n",
      "weighted avg       0.78      0.77      0.77      4746\n",
      "\n",
      "[[1951  422]\n",
      " [ 649 1724]]\n",
      "Esimators:  56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79      2373\n",
      "           1       0.80      0.73      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1946  427]\n",
      " [ 633 1740]]\n",
      "Esimators:  57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.77      4746\n",
      "weighted avg       0.78      0.78      0.77      4746\n",
      "\n",
      "[[1950  423]\n",
      " [ 644 1729]]\n",
      "Esimators:  58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79      2373\n",
      "           1       0.80      0.73      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1948  425]\n",
      " [ 635 1738]]\n",
      "Esimators:  59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.78      0.77      0.77      4746\n",
      "weighted avg       0.78      0.77      0.77      4746\n",
      "\n",
      "[[1947  426]\n",
      " [ 642 1731]]\n",
      "Esimators:  60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1951  422]\n",
      " [ 642 1731]]\n",
      "Esimators:  61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.77      4746\n",
      "weighted avg       0.78      0.78      0.77      4746\n",
      "\n",
      "[[1951  422]\n",
      " [ 644 1729]]\n",
      "Esimators:  62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.77      4746\n",
      "weighted avg       0.78      0.78      0.77      4746\n",
      "\n",
      "[[1951  422]\n",
      " [ 644 1729]]\n",
      "Esimators:  63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.78      0.77      0.77      4746\n",
      "weighted avg       0.78      0.77      0.77      4746\n",
      "\n",
      "[[1949  424]\n",
      " [ 644 1729]]\n",
      "Esimators:  64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.78      0.77      0.77      4746\n",
      "weighted avg       0.78      0.77      0.77      4746\n",
      "\n",
      "[[1949  424]\n",
      " [ 644 1729]]\n",
      "Esimators:  65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.77      4746\n",
      "weighted avg       0.78      0.78      0.77      4746\n",
      "\n",
      "[[1950  423]\n",
      " [ 644 1729]]\n",
      "Esimators:  66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.77      4746\n",
      "weighted avg       0.78      0.78      0.77      4746\n",
      "\n",
      "[[1951  422]\n",
      " [ 644 1729]]\n",
      "Esimators:  67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.77      4746\n",
      "weighted avg       0.78      0.78      0.77      4746\n",
      "\n",
      "[[1953  420]\n",
      " [ 646 1727]]\n",
      "Esimators:  68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.78      0.77      0.77      4746\n",
      "weighted avg       0.78      0.77      0.77      4746\n",
      "\n",
      "[[1947  426]\n",
      " [ 646 1727]]\n",
      "Esimators:  69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.77      4746\n",
      "weighted avg       0.78      0.78      0.77      4746\n",
      "\n",
      "[[1949  424]\n",
      " [ 643 1730]]\n",
      "Esimators:  70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79      2373\n",
      "           1       0.80      0.73      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1951  422]\n",
      " [ 637 1736]]\n",
      "Esimators:  71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79      2373\n",
      "           1       0.80      0.73      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1952  421]\n",
      " [ 641 1732]]\n",
      "Esimators:  72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.77      4746\n",
      "weighted avg       0.78      0.78      0.77      4746\n",
      "\n",
      "[[1949  424]\n",
      " [ 643 1730]]\n",
      "Esimators:  73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.78      0.77      0.77      4746\n",
      "weighted avg       0.78      0.77      0.77      4746\n",
      "\n",
      "[[1946  427]\n",
      " [ 643 1730]]\n",
      "Esimators:  74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.78      0.77      0.77      4746\n",
      "weighted avg       0.78      0.77      0.77      4746\n",
      "\n",
      "[[1943  430]\n",
      " [ 639 1734]]\n",
      "Esimators:  75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79      2373\n",
      "           1       0.80      0.73      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1946  427]\n",
      " [ 637 1736]]\n",
      "Esimators:  76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.77      4746\n",
      "weighted avg       0.78      0.78      0.77      4746\n",
      "\n",
      "[[1946  427]\n",
      " [ 639 1734]]\n",
      "Esimators:  77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79      2373\n",
      "           1       0.80      0.73      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1947  426]\n",
      " [ 639 1734]]\n",
      "Esimators:  78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79      2373\n",
      "           1       0.80      0.73      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1948  425]\n",
      " [ 639 1734]]\n",
      "Esimators:  79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79      2373\n",
      "           1       0.80      0.73      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1948  425]\n",
      " [ 639 1734]]\n",
      "Esimators:  80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79      2373\n",
      "           1       0.80      0.73      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1948  425]\n",
      " [ 639 1734]]\n",
      "Esimators:  81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79      2373\n",
      "           1       0.80      0.73      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1947  426]\n",
      " [ 639 1734]]\n",
      "Esimators:  82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79      2373\n",
      "           1       0.80      0.73      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1948  425]\n",
      " [ 631 1742]]\n",
      "Esimators:  83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79      2373\n",
      "           1       0.80      0.73      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1948  425]\n",
      " [ 631 1742]]\n",
      "Esimators:  84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79      2373\n",
      "           1       0.80      0.73      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1949  424]\n",
      " [ 631 1742]]\n",
      "Esimators:  85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79      2373\n",
      "           1       0.80      0.73      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1943  430]\n",
      " [ 633 1740]]\n",
      "Esimators:  86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2373\n",
      "           1       0.80      0.73      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.77      4746\n",
      "weighted avg       0.78      0.78      0.77      4746\n",
      "\n",
      "[[1944  429]\n",
      " [ 637 1736]]\n",
      "Esimators:  87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79      2373\n",
      "           1       0.80      0.73      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1946  427]\n",
      " [ 633 1740]]\n",
      "Esimators:  88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79      2373\n",
      "           1       0.80      0.73      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1945  428]\n",
      " [ 633 1740]]\n",
      "Esimators:  89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2373\n",
      "           1       0.80      0.73      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.77      4746\n",
      "weighted avg       0.78      0.78      0.77      4746\n",
      "\n",
      "[[1941  432]\n",
      " [ 635 1738]]\n",
      "Esimators:  90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2373\n",
      "           1       0.80      0.73      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.77      4746\n",
      "weighted avg       0.78      0.78      0.77      4746\n",
      "\n",
      "[[1941  432]\n",
      " [ 635 1738]]\n",
      "Esimators:  91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79      2373\n",
      "           1       0.80      0.73      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1944  429]\n",
      " [ 635 1738]]\n",
      "Esimators:  92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79      2373\n",
      "           1       0.80      0.73      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1945  428]\n",
      " [ 630 1743]]\n",
      "Esimators:  93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79      2373\n",
      "           1       0.80      0.73      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1945  428]\n",
      " [ 635 1738]]\n",
      "Esimators:  94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79      2373\n",
      "           1       0.80      0.73      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1944  429]\n",
      " [ 635 1738]]\n",
      "Esimators:  95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.78      0.77      0.77      4746\n",
      "weighted avg       0.78      0.77      0.77      4746\n",
      "\n",
      "[[1944  429]\n",
      " [ 640 1733]]\n",
      "Esimators:  96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79      2373\n",
      "           1       0.80      0.73      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1946  427]\n",
      " [ 636 1737]]\n",
      "Esimators:  97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.77      4746\n",
      "weighted avg       0.78      0.78      0.77      4746\n",
      "\n",
      "[[1946  427]\n",
      " [ 640 1733]]\n",
      "Esimators:  98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2373\n",
      "           1       0.80      0.73      0.76      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.77      4746\n",
      "weighted avg       0.78      0.78      0.77      4746\n",
      "\n",
      "[[1946  427]\n",
      " [ 640 1733]]\n",
      "Esimators:  99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79      2373\n",
      "           1       0.80      0.73      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1946  427]\n",
      " [ 634 1739]]\n",
      "Esimators:  100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79      2373\n",
      "           1       0.80      0.73      0.77      2373\n",
      "\n",
      "    accuracy                           0.78      4746\n",
      "   macro avg       0.78      0.78      0.78      4746\n",
      "weighted avg       0.78      0.78      0.78      4746\n",
      "\n",
      "[[1946  427]\n",
      " [ 638 1735]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,101):\n",
    "    gbc = GradientBoostingClassifier(n_estimators=i, random_state=1)  # n_estimators >=10 and <=100\n",
    "    print(\"Esimators: \", i)\n",
    "    \n",
    "    gbc = create_model(gbc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f8b7621d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76      2373\n",
      "           1       0.77      0.75      0.76      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.76      0.76      0.76      4746\n",
      "weighted avg       0.76      0.76      0.76      4746\n",
      "\n",
      "[[1836  537]\n",
      " [ 601 1772]]\n"
     ]
    }
   ],
   "source": [
    "# here n_estimators 11 is perfect\n",
    "\n",
    "gbc = GradientBoostingClassifier(n_estimators=15, random_state=1)\n",
    "gbc = create_model(gbc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2761aaa3",
   "metadata": {},
   "source": [
    "# 6. XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "87ef7fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7baaca24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.83      0.78      2373\n",
      "           1       0.81      0.71      0.75      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.78      0.77      0.77      4746\n",
      "weighted avg       0.78      0.77      0.77      4746\n",
      "\n",
      "[[1980  393]\n",
      " [ 696 1677]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.83      0.79      2373\n",
      "           1       0.81      0.71      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.78      0.77      0.77      4746\n",
      "weighted avg       0.78      0.77      0.77      4746\n",
      "\n",
      "[[1980  393]\n",
      " [ 681 1692]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.83      0.79      2373\n",
      "           1       0.81      0.71      0.76      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.78      0.77      0.77      4746\n",
      "weighted avg       0.78      0.77      0.77      4746\n",
      "\n",
      "[[1979  394]\n",
      " [ 688 1685]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.84      0.78      2373\n",
      "           1       0.81      0.70      0.75      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1984  389]\n",
      " [ 702 1671]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.84      0.78      2373\n",
      "           1       0.81      0.70      0.75      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1985  388]\n",
      " [ 703 1670]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.84      0.78      2373\n",
      "           1       0.81      0.70      0.75      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1985  388]\n",
      " [ 709 1664]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.84      0.78      2373\n",
      "           1       0.81      0.70      0.75      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1989  384]\n",
      " [ 714 1659]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.84      0.78      2373\n",
      "           1       0.81      0.69      0.75      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1995  378]\n",
      " [ 727 1646]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.84      0.78      2373\n",
      "           1       0.81      0.70      0.75      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1992  381]\n",
      " [ 723 1650]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.84      0.78      2373\n",
      "           1       0.81      0.69      0.75      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.76      4746\n",
      "weighted avg       0.77      0.77      0.76      4746\n",
      "\n",
      "[[1996  377]\n",
      " [ 738 1635]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.84      0.78      2373\n",
      "           1       0.81      0.69      0.74      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.76      4746\n",
      "weighted avg       0.77      0.76      0.76      4746\n",
      "\n",
      "[[1994  379]\n",
      " [ 746 1627]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.84      0.78      2373\n",
      "           1       0.81      0.68      0.74      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.76      4746\n",
      "weighted avg       0.77      0.76      0.76      4746\n",
      "\n",
      "[[1997  376]\n",
      " [ 759 1614]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.84      0.78      2373\n",
      "           1       0.81      0.68      0.74      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.76      4746\n",
      "weighted avg       0.77      0.76      0.76      4746\n",
      "\n",
      "[[1997  376]\n",
      " [ 750 1623]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.84      0.78      2373\n",
      "           1       0.81      0.69      0.74      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.76      4746\n",
      "weighted avg       0.77      0.76      0.76      4746\n",
      "\n",
      "[[1998  375]\n",
      " [ 744 1629]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.84      0.78      2373\n",
      "           1       0.82      0.69      0.75      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[2002  371]\n",
      " [ 731 1642]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.84      0.78      2373\n",
      "           1       0.82      0.69      0.75      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[2002  371]\n",
      " [ 731 1642]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.84      0.78      2373\n",
      "           1       0.81      0.69      0.75      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.76      4746\n",
      "weighted avg       0.77      0.77      0.76      4746\n",
      "\n",
      "[[1992  381]\n",
      " [ 733 1640]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.84      0.78      2373\n",
      "           1       0.81      0.69      0.75      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.76      4746\n",
      "weighted avg       0.77      0.77      0.76      4746\n",
      "\n",
      "[[1997  376]\n",
      " [ 735 1638]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.84      0.78      2373\n",
      "           1       0.81      0.69      0.75      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.76      4746\n",
      "weighted avg       0.77      0.77      0.76      4746\n",
      "\n",
      "[[1996  377]\n",
      " [ 733 1640]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.84      0.78      2373\n",
      "           1       0.81      0.69      0.74      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.76      4746\n",
      "weighted avg       0.77      0.76      0.76      4746\n",
      "\n",
      "[[1995  378]\n",
      " [ 747 1626]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.84      0.78      2373\n",
      "           1       0.81      0.68      0.74      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.76      4746\n",
      "weighted avg       0.77      0.76      0.76      4746\n",
      "\n",
      "[[1994  379]\n",
      " [ 749 1624]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.84      0.78      2373\n",
      "           1       0.81      0.68      0.74      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.76      4746\n",
      "weighted avg       0.77      0.76      0.76      4746\n",
      "\n",
      "[[1993  380]\n",
      " [ 749 1624]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.84      0.78      2373\n",
      "           1       0.81      0.68      0.74      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.76      4746\n",
      "weighted avg       0.77      0.76      0.76      4746\n",
      "\n",
      "[[1998  375]\n",
      " [ 748 1625]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.84      0.78      2373\n",
      "           1       0.81      0.68      0.74      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.76      4746\n",
      "weighted avg       0.77      0.76      0.76      4746\n",
      "\n",
      "[[2002  371]\n",
      " [ 749 1624]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.84      0.78      2373\n",
      "           1       0.81      0.68      0.74      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.76      4746\n",
      "weighted avg       0.77      0.76      0.76      4746\n",
      "\n",
      "[[2005  368]\n",
      " [ 763 1610]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.85      0.78      2373\n",
      "           1       0.82      0.68      0.74      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.76      4746\n",
      "weighted avg       0.77      0.76      0.76      4746\n",
      "\n",
      "[[2013  360]\n",
      " [ 764 1609]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.85      0.78      2373\n",
      "           1       0.82      0.68      0.74      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.76      4746\n",
      "weighted avg       0.77      0.76      0.76      4746\n",
      "\n",
      "[[2013  360]\n",
      " [ 764 1609]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.85      0.78      2373\n",
      "           1       0.82      0.68      0.74      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.76      4746\n",
      "weighted avg       0.77      0.76      0.76      4746\n",
      "\n",
      "[[2013  360]\n",
      " [ 767 1606]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.85      0.78      2373\n",
      "           1       0.82      0.68      0.74      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.76      4746\n",
      "weighted avg       0.77      0.76      0.76      4746\n",
      "\n",
      "[[2015  358]\n",
      " [ 761 1612]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.85      0.78      2373\n",
      "           1       0.82      0.68      0.74      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.76      4746\n",
      "weighted avg       0.77      0.76      0.76      4746\n",
      "\n",
      "[[2018  355]\n",
      " [ 763 1610]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.85      0.78      2373\n",
      "           1       0.82      0.68      0.74      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.76      4746\n",
      "weighted avg       0.77      0.77      0.76      4746\n",
      "\n",
      "[[2023  350]\n",
      " [ 760 1613]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.85      0.78      2373\n",
      "           1       0.82      0.67      0.74      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.76      4746\n",
      "weighted avg       0.77      0.76      0.76      4746\n",
      "\n",
      "[[2023  350]\n",
      " [ 782 1591]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.85      0.78      2373\n",
      "           1       0.82      0.67      0.74      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.76      4746\n",
      "weighted avg       0.77      0.76      0.76      4746\n",
      "\n",
      "[[2023  350]\n",
      " [ 779 1594]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.86      0.78      2373\n",
      "           1       0.83      0.67      0.74      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.76      4746\n",
      "weighted avg       0.77      0.76      0.76      4746\n",
      "\n",
      "[[2039  334]\n",
      " [ 789 1584]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.86      0.78      2373\n",
      "           1       0.82      0.67      0.74      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.76      4746\n",
      "weighted avg       0.77      0.76      0.76      4746\n",
      "\n",
      "[[2030  343]\n",
      " [ 778 1595]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.86      0.78      2373\n",
      "           1       0.82      0.67      0.74      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.76      4746\n",
      "weighted avg       0.77      0.76      0.76      4746\n",
      "\n",
      "[[2036  337]\n",
      " [ 792 1581]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.86      0.78      2373\n",
      "           1       0.82      0.66      0.74      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.76      4746\n",
      "weighted avg       0.77      0.76      0.76      4746\n",
      "\n",
      "[[2035  338]\n",
      " [ 797 1576]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.86      0.78      2373\n",
      "           1       0.82      0.66      0.74      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.76      4746\n",
      "weighted avg       0.77      0.76      0.76      4746\n",
      "\n",
      "[[2038  335]\n",
      " [ 795 1578]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.86      0.78      2373\n",
      "           1       0.82      0.66      0.74      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.76      4746\n",
      "weighted avg       0.77      0.76      0.76      4746\n",
      "\n",
      "[[2039  334]\n",
      " [ 799 1574]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.86      0.78      2373\n",
      "           1       0.83      0.66      0.73      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.76      4746\n",
      "weighted avg       0.77      0.76      0.76      4746\n",
      "\n",
      "[[2041  332]\n",
      " [ 807 1566]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.86      0.78      2373\n",
      "           1       0.83      0.66      0.73      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.76      4746\n",
      "weighted avg       0.77      0.76      0.76      4746\n",
      "\n",
      "[[2041  332]\n",
      " [ 804 1569]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.86      0.78      2373\n",
      "           1       0.83      0.66      0.73      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.76      4746\n",
      "weighted avg       0.77      0.76      0.76      4746\n",
      "\n",
      "[[2047  326]\n",
      " [ 808 1565]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.86      0.78      2373\n",
      "           1       0.83      0.66      0.73      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.76      4746\n",
      "weighted avg       0.77      0.76      0.76      4746\n",
      "\n",
      "[[2047  326]\n",
      " [ 808 1565]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.86      0.78      2373\n",
      "           1       0.83      0.66      0.74      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.76      4746\n",
      "weighted avg       0.77      0.76      0.76      4746\n",
      "\n",
      "[[2045  328]\n",
      " [ 796 1577]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.86      0.78      2373\n",
      "           1       0.83      0.66      0.73      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.76      4746\n",
      "weighted avg       0.77      0.76      0.76      4746\n",
      "\n",
      "[[2045  328]\n",
      " [ 806 1567]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.86      0.78      2373\n",
      "           1       0.83      0.65      0.73      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.75      4746\n",
      "weighted avg       0.77      0.76      0.75      4746\n",
      "\n",
      "[[2048  325]\n",
      " [ 830 1543]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.87      0.78      2373\n",
      "           1       0.83      0.65      0.73      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.76      4746\n",
      "weighted avg       0.77      0.76      0.76      4746\n",
      "\n",
      "[[2055  318]\n",
      " [ 830 1543]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.87      0.78      2373\n",
      "           1       0.83      0.65      0.73      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.75      4746\n",
      "weighted avg       0.77      0.76      0.75      4746\n",
      "\n",
      "[[2055  318]\n",
      " [ 834 1539]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.87      0.78      2373\n",
      "           1       0.83      0.65      0.73      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.75      4746\n",
      "weighted avg       0.77      0.76      0.75      4746\n",
      "\n",
      "[[2055  318]\n",
      " [ 841 1532]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.87      0.78      2373\n",
      "           1       0.83      0.64      0.72      2373\n",
      "\n",
      "    accuracy                           0.76      4746\n",
      "   macro avg       0.77      0.76      0.75      4746\n",
      "weighted avg       0.77      0.76      0.75      4746\n",
      "\n",
      "[[2056  317]\n",
      " [ 845 1528]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.87      0.78      2373\n",
      "           1       0.83      0.64      0.72      2373\n",
      "\n",
      "    accuracy                           0.75      4746\n",
      "   macro avg       0.77      0.75      0.75      4746\n",
      "weighted avg       0.77      0.75      0.75      4746\n",
      "\n",
      "[[2058  315]\n",
      " [ 854 1519]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.87      0.78      2373\n",
      "           1       0.83      0.64      0.72      2373\n",
      "\n",
      "    accuracy                           0.75      4746\n",
      "   macro avg       0.77      0.75      0.75      4746\n",
      "weighted avg       0.77      0.75      0.75      4746\n",
      "\n",
      "[[2058  315]\n",
      " [ 864 1509]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.87      0.78      2373\n",
      "           1       0.83      0.63      0.72      2373\n",
      "\n",
      "    accuracy                           0.75      4746\n",
      "   macro avg       0.77      0.75      0.75      4746\n",
      "weighted avg       0.77      0.75      0.75      4746\n",
      "\n",
      "[[2064  309]\n",
      " [ 870 1503]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.87      0.78      2373\n",
      "           1       0.83      0.63      0.72      2373\n",
      "\n",
      "    accuracy                           0.75      4746\n",
      "   macro avg       0.77      0.75      0.75      4746\n",
      "weighted avg       0.77      0.75      0.75      4746\n",
      "\n",
      "[[2065  308]\n",
      " [ 874 1499]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.87      0.78      2373\n",
      "           1       0.83      0.63      0.72      2373\n",
      "\n",
      "    accuracy                           0.75      4746\n",
      "   macro avg       0.77      0.75      0.75      4746\n",
      "weighted avg       0.77      0.75      0.75      4746\n",
      "\n",
      "[[2069  304]\n",
      " [ 867 1506]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.87      0.78      2373\n",
      "           1       0.83      0.63      0.72      2373\n",
      "\n",
      "    accuracy                           0.75      4746\n",
      "   macro avg       0.77      0.75      0.75      4746\n",
      "weighted avg       0.77      0.75      0.75      4746\n",
      "\n",
      "[[2071  302]\n",
      " [ 871 1502]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.87      0.78      2373\n",
      "           1       0.83      0.62      0.71      2373\n",
      "\n",
      "    accuracy                           0.75      4746\n",
      "   macro avg       0.77      0.75      0.74      4746\n",
      "weighted avg       0.77      0.75      0.74      4746\n",
      "\n",
      "[[2071  302]\n",
      " [ 890 1483]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.87      0.78      2373\n",
      "           1       0.83      0.63      0.71      2373\n",
      "\n",
      "    accuracy                           0.75      4746\n",
      "   macro avg       0.77      0.75      0.75      4746\n",
      "weighted avg       0.77      0.75      0.75      4746\n",
      "\n",
      "[[2072  301]\n",
      " [ 887 1486]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.87      0.78      2373\n",
      "           1       0.83      0.62      0.71      2373\n",
      "\n",
      "    accuracy                           0.75      4746\n",
      "   macro avg       0.76      0.75      0.74      4746\n",
      "weighted avg       0.76      0.75      0.74      4746\n",
      "\n",
      "[[2070  303]\n",
      " [ 890 1483]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.87      0.78      2373\n",
      "           1       0.83      0.62      0.71      2373\n",
      "\n",
      "    accuracy                           0.75      4746\n",
      "   macro avg       0.77      0.75      0.75      4746\n",
      "weighted avg       0.77      0.75      0.75      4746\n",
      "\n",
      "[[2072  301]\n",
      " [ 890 1483]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.88      0.78      2373\n",
      "           1       0.83      0.62      0.71      2373\n",
      "\n",
      "    accuracy                           0.75      4746\n",
      "   macro avg       0.77      0.75      0.74      4746\n",
      "weighted avg       0.77      0.75      0.74      4746\n",
      "\n",
      "[[2078  295]\n",
      " [ 902 1471]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.87      0.78      2373\n",
      "           1       0.83      0.63      0.71      2373\n",
      "\n",
      "    accuracy                           0.75      4746\n",
      "   macro avg       0.77      0.75      0.75      4746\n",
      "weighted avg       0.77      0.75      0.75      4746\n",
      "\n",
      "[[2074  299]\n",
      " [ 887 1486]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.87      0.78      2373\n",
      "           1       0.83      0.63      0.72      2373\n",
      "\n",
      "    accuracy                           0.75      4746\n",
      "   macro avg       0.77      0.75      0.75      4746\n",
      "weighted avg       0.77      0.75      0.75      4746\n",
      "\n",
      "[[2074  299]\n",
      " [ 880 1493]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.87      0.78      2373\n",
      "           1       0.83      0.62      0.71      2373\n",
      "\n",
      "    accuracy                           0.75      4746\n",
      "   macro avg       0.77      0.75      0.74      4746\n",
      "weighted avg       0.77      0.75      0.74      4746\n",
      "\n",
      "[[2076  297]\n",
      " [ 896 1477]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.88      0.77      2373\n",
      "           1       0.83      0.61      0.71      2373\n",
      "\n",
      "    accuracy                           0.74      4746\n",
      "   macro avg       0.76      0.74      0.74      4746\n",
      "weighted avg       0.76      0.74      0.74      4746\n",
      "\n",
      "[[2079  294]\n",
      " [ 917 1456]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.88      0.77      2373\n",
      "           1       0.83      0.61      0.70      2373\n",
      "\n",
      "    accuracy                           0.74      4746\n",
      "   macro avg       0.76      0.74      0.74      4746\n",
      "weighted avg       0.76      0.74      0.74      4746\n",
      "\n",
      "[[2081  292]\n",
      " [ 928 1445]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.88      0.77      2373\n",
      "           1       0.83      0.61      0.70      2373\n",
      "\n",
      "    accuracy                           0.74      4746\n",
      "   macro avg       0.76      0.74      0.74      4746\n",
      "weighted avg       0.76      0.74      0.74      4746\n",
      "\n",
      "[[2078  295]\n",
      " [ 927 1446]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.88      0.77      2373\n",
      "           1       0.83      0.61      0.71      2373\n",
      "\n",
      "    accuracy                           0.74      4746\n",
      "   macro avg       0.76      0.74      0.74      4746\n",
      "weighted avg       0.76      0.74      0.74      4746\n",
      "\n",
      "[[2081  292]\n",
      " [ 920 1453]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.88      0.77      2373\n",
      "           1       0.83      0.61      0.71      2373\n",
      "\n",
      "    accuracy                           0.74      4746\n",
      "   macro avg       0.76      0.74      0.74      4746\n",
      "weighted avg       0.76      0.74      0.74      4746\n",
      "\n",
      "[[2081  292]\n",
      " [ 922 1451]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.88      0.77      2373\n",
      "           1       0.83      0.61      0.71      2373\n",
      "\n",
      "    accuracy                           0.74      4746\n",
      "   macro avg       0.76      0.74      0.74      4746\n",
      "weighted avg       0.76      0.74      0.74      4746\n",
      "\n",
      "[[2081  292]\n",
      " [ 922 1451]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.88      0.77      2373\n",
      "           1       0.83      0.61      0.70      2373\n",
      "\n",
      "    accuracy                           0.74      4746\n",
      "   macro avg       0.76      0.74      0.74      4746\n",
      "weighted avg       0.76      0.74      0.74      4746\n",
      "\n",
      "[[2081  292]\n",
      " [ 923 1450]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.88      0.78      2373\n",
      "           1       0.83      0.61      0.71      2373\n",
      "\n",
      "    accuracy                           0.75      4746\n",
      "   macro avg       0.76      0.75      0.74      4746\n",
      "weighted avg       0.76      0.75      0.74      4746\n",
      "\n",
      "[[2084  289]\n",
      " [ 921 1452]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.88      0.78      2373\n",
      "           1       0.84      0.61      0.71      2373\n",
      "\n",
      "    accuracy                           0.75      4746\n",
      "   macro avg       0.76      0.75      0.74      4746\n",
      "weighted avg       0.76      0.75      0.74      4746\n",
      "\n",
      "[[2087  286]\n",
      " [ 921 1452]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.88      0.78      2373\n",
      "           1       0.83      0.61      0.71      2373\n",
      "\n",
      "    accuracy                           0.75      4746\n",
      "   macro avg       0.76      0.75      0.74      4746\n",
      "weighted avg       0.76      0.75      0.74      4746\n",
      "\n",
      "[[2085  288]\n",
      " [ 920 1453]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.88      0.78      2373\n",
      "           1       0.83      0.61      0.71      2373\n",
      "\n",
      "    accuracy                           0.75      4746\n",
      "   macro avg       0.76      0.75      0.74      4746\n",
      "weighted avg       0.76      0.75      0.74      4746\n",
      "\n",
      "[[2084  289]\n",
      " [ 921 1452]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.88      0.78      2373\n",
      "           1       0.84      0.61      0.71      2373\n",
      "\n",
      "    accuracy                           0.75      4746\n",
      "   macro avg       0.77      0.75      0.74      4746\n",
      "weighted avg       0.77      0.75      0.74      4746\n",
      "\n",
      "[[2091  282]\n",
      " [ 924 1449]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.88      0.78      2373\n",
      "           1       0.84      0.61      0.70      2373\n",
      "\n",
      "    accuracy                           0.74      4746\n",
      "   macro avg       0.76      0.74      0.74      4746\n",
      "weighted avg       0.76      0.74      0.74      4746\n",
      "\n",
      "[[2094  279]\n",
      " [ 933 1440]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.88      0.78      2373\n",
      "           1       0.84      0.61      0.70      2373\n",
      "\n",
      "    accuracy                           0.74      4746\n",
      "   macro avg       0.76      0.74      0.74      4746\n",
      "weighted avg       0.76      0.74      0.74      4746\n",
      "\n",
      "[[2094  279]\n",
      " [ 933 1440]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.88      0.78      2373\n",
      "           1       0.84      0.61      0.70      2373\n",
      "\n",
      "    accuracy                           0.74      4746\n",
      "   macro avg       0.77      0.74      0.74      4746\n",
      "weighted avg       0.77      0.74      0.74      4746\n",
      "\n",
      "[[2096  277]\n",
      " [ 934 1439]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.88      0.78      2373\n",
      "           1       0.84      0.61      0.70      2373\n",
      "\n",
      "    accuracy                           0.74      4746\n",
      "   macro avg       0.77      0.74      0.74      4746\n",
      "weighted avg       0.77      0.74      0.74      4746\n",
      "\n",
      "[[2098  275]\n",
      " [ 936 1437]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.88      0.78      2373\n",
      "           1       0.84      0.60      0.70      2373\n",
      "\n",
      "    accuracy                           0.74      4746\n",
      "   macro avg       0.77      0.74      0.74      4746\n",
      "weighted avg       0.77      0.74      0.74      4746\n",
      "\n",
      "[[2100  273]\n",
      " [ 940 1433]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.88      0.78      2373\n",
      "           1       0.84      0.60      0.70      2373\n",
      "\n",
      "    accuracy                           0.74      4746\n",
      "   macro avg       0.77      0.74      0.74      4746\n",
      "weighted avg       0.77      0.74      0.74      4746\n",
      "\n",
      "[[2100  273]\n",
      " [ 938 1435]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.88      0.78      2373\n",
      "           1       0.84      0.61      0.70      2373\n",
      "\n",
      "    accuracy                           0.75      4746\n",
      "   macro avg       0.77      0.75      0.74      4746\n",
      "weighted avg       0.77      0.75      0.74      4746\n",
      "\n",
      "[[2099  274]\n",
      " [ 934 1439]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.88      0.78      2373\n",
      "           1       0.84      0.61      0.70      2373\n",
      "\n",
      "    accuracy                           0.75      4746\n",
      "   macro avg       0.77      0.75      0.74      4746\n",
      "weighted avg       0.77      0.75      0.74      4746\n",
      "\n",
      "[[2100  273]\n",
      " [ 934 1439]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.89      0.78      2373\n",
      "           1       0.84      0.61      0.71      2373\n",
      "\n",
      "    accuracy                           0.75      4746\n",
      "   macro avg       0.77      0.75      0.74      4746\n",
      "weighted avg       0.77      0.75      0.74      4746\n",
      "\n",
      "[[2102  271]\n",
      " [ 930 1443]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.89      0.78      2373\n",
      "           1       0.84      0.61      0.71      2373\n",
      "\n",
      "    accuracy                           0.75      4746\n",
      "   macro avg       0.77      0.75      0.74      4746\n",
      "weighted avg       0.77      0.75      0.74      4746\n",
      "\n",
      "[[2102  271]\n",
      " [ 922 1451]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.89      0.78      2373\n",
      "           1       0.84      0.61      0.71      2373\n",
      "\n",
      "    accuracy                           0.75      4746\n",
      "   macro avg       0.77      0.75      0.74      4746\n",
      "weighted avg       0.77      0.75      0.74      4746\n",
      "\n",
      "[[2101  272]\n",
      " [ 922 1451]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.88      0.78      2373\n",
      "           1       0.84      0.61      0.71      2373\n",
      "\n",
      "    accuracy                           0.75      4746\n",
      "   macro avg       0.77      0.75      0.74      4746\n",
      "weighted avg       0.77      0.75      0.74      4746\n",
      "\n",
      "[[2100  273]\n",
      " [ 922 1451]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.89      0.78      2373\n",
      "           1       0.84      0.61      0.71      2373\n",
      "\n",
      "    accuracy                           0.75      4746\n",
      "   macro avg       0.77      0.75      0.74      4746\n",
      "weighted avg       0.77      0.75      0.74      4746\n",
      "\n",
      "[[2101  272]\n",
      " [ 923 1450]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.89      0.78      2373\n",
      "           1       0.84      0.61      0.71      2373\n",
      "\n",
      "    accuracy                           0.75      4746\n",
      "   macro avg       0.77      0.75      0.74      4746\n",
      "weighted avg       0.77      0.75      0.74      4746\n",
      "\n",
      "[[2101  272]\n",
      " [ 921 1452]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,100):\n",
    "    xgc = XGBClassifier(n_estimators= i,reg_alpha =1, random_state =1)\n",
    "    \n",
    "    xgc = create_model(xgc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "449945a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.83      0.78      2373\n",
      "           1       0.81      0.71      0.75      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.78      0.77      0.77      4746\n",
      "weighted avg       0.78      0.77      0.77      4746\n",
      "\n",
      "[[1980  393]\n",
      " [ 696 1677]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'reg_alpha mean regularization and alpa means lambda means hyperparameter \\nif re_aplpha  =1 , 1 means True means autometic handel outlier and overfitting\\n'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgc = XGBClassifier(n_estimators= 10,reg_alpha =1, random_state =1)\n",
    "\n",
    "xgc = create_model(xgc)\n",
    "\n",
    "'''reg_alpha mean regularization and alpa means lambda means hyperparameter \n",
    "if re_aplpha  =1 , 1 means True means autometic handel outlier and overfitting\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae714b63",
   "metadata": {},
   "source": [
    "# 7. Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5f397e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "16c5626b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.74      0.71      2373\n",
      "           1       0.72      0.68      0.70      2373\n",
      "\n",
      "    accuracy                           0.71      4746\n",
      "   macro avg       0.71      0.71      0.71      4746\n",
      "weighted avg       0.71      0.71      0.71      4746\n",
      "\n",
      "[[1746  627]\n",
      " [ 770 1603]]\n"
     ]
    }
   ],
   "source": [
    "svc = LinearSVC(random_state=1)\n",
    "\n",
    "svc = create_model(svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e0e0771e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2d90a538",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_svc = SVC(random_state=1,kernel='poly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2803e046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.81      0.78      2373\n",
      "           1       0.79      0.72      0.75      2373\n",
      "\n",
      "    accuracy                           0.77      4746\n",
      "   macro avg       0.77      0.77      0.77      4746\n",
      "weighted avg       0.77      0.77      0.77      4746\n",
      "\n",
      "[[1928  445]\n",
      " [ 665 1708]]\n"
     ]
    }
   ],
   "source": [
    "poly_svc = create_model(poly_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ac6bde1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_svc = SVC(random_state=1, kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cd406221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.81      0.77      2373\n",
      "           1       0.79      0.70      0.74      2373\n",
      "\n",
      "    accuracy                           0.75      4746\n",
      "   macro avg       0.76      0.75      0.75      4746\n",
      "weighted avg       0.76      0.75      0.75      4746\n",
      "\n",
      "[[1919  454]\n",
      " [ 715 1658]]\n"
     ]
    }
   ],
   "source": [
    "r_svc = create_model(r_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e363ca83",
   "metadata": {},
   "source": [
    "# Results evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb85fe0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#model's accuracy evaluation in barplot\n",
    "'''olympic_medals_palette = ['#BBA14F','#BBC2CC', '#D37731', '#B87333', '#B87333']\n",
    "olympic_medals_edge_colors = ['#BD9A3B','#AEC3D1', '#D66D20', '#B87333', '#B87333']\n",
    "sns.set(rc={'axes.facecolor':'#ECECEC'}) #background color of plot\n",
    "'''\n",
    "plt.figure(figsize = (25,15))\n",
    "ax = sns.barplot(x = ['Logistic Regression', 'Decision Tree with Gini', 'Decision Tree with Entropy', 'Random Forest',\n",
    "                     'Ada Boost', 'Gradient Boost', 'XGB Boost', 'Linear SVC', 'Poly SVC'], y = [67,76,75,73,78,75,71,72,68])\n",
    "plt.title(label = \"Comparison of model's accuracies\", fontsize = 15, fontweight = 'bold', fontname = 'Helvetica', ha = 'center')\n",
    "ax.bar_label(ax.containers[0], label_type = 'edge', fontsize = 12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a390bfd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 107.184479,
   "end_time": "2021-06-08T09:25:34.583628",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-08T09:23:47.399149",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
